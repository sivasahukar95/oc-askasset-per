id,title,author,description,typeId,fileName,source,assetURL,documentationURL,likeCount,dislikeCount,isArchived,isDraft,isUseCase,createdTimestamp,updatedTimestamp,userId,keyCloakUserId,firstName,lastName,categoryId,categoryName,type
bdvlfuxcvc,Test multiple prompts against WatsonX.AI FLAN UL2 model ,Deepak Rangarao,"NOTE: This should be used in conjunction with the WGET to download files task. Upload a zip file to box/any location with multiple text files and 1 text file for the test data to use, each having a prompt you want to test. Now invoke this task as a 2nd step to read each of the prompt files and execute the prompt against the chosen model and display a F1  score compared to test dataset.",1,bdvlfuxcvc.py,local,,https://www.ibm.com,0,0,0,0,0,1692867691000,1709736863577,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,1,watsonx.ai,python
budgsskjow,Get list of services installed in CP4D,Rajesh,Get list of services installed in CP4D,4,budgsskjow.sh,,,,0,0,0,0,0,1688692449000,1688692449000,3,20d54209-025a-478e-99c5-5a1db4dd1089,,,5,CP4D,bash
dfmkjrmwuc,S3 List bucket contents,DEEPAK RANGARAO,"Uses the AWS CLI and the connection details to any S3 compliant object store to display list of objects in the bucket. 
DEPENDENCIES=You need to execute the S3 install AWS CLI task before this task of listing the objects in the bucket",4,dfmkjrmwuc.sh,local,,,0,0,0,0,0,1698695456000,1709736600463,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,bash
egrysskfep,Cleanup your CP4D Instance,Girish Padmanabhan,This asset would clean up your Cloud Pak for Data instance from the specified Open Shift cluster. This would include  all the resources associated with the operator and instance namespaces,4,egrysskfep.sh,,,,0,0,0,0,0,1689031056000,1689031056000,331,1f0045c3-f9ad-4151-9c43-4e1f160bdf3e,,,5,CP4D,bash
enfonhvblc,Prompting IBM and Open Source models with WatsonX.AI,Deepak Rangarao,"Prompting Open Source FLAN model with WatsonX.AI, supported model ids: ibm/mpt-7b-instruct2, google/flan-ul2, eleutherai/gpt-neox-20b, google/flan-t5-xxl, bigscience/mt0-xxl",1,enfonhvblc.py,local,,,0,0,0,0,0,1691391733000,1710923091995,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,1,watsonx.ai,python
fstnmmugha,Merge large number of files using Dask,DEEPAK RANGARAO,"Merge large number of files using Dask. I ran the following code snippet
df = dd.read_csv('s3://'+BUCKET_NAME+'/*.csv', storage_options=s3_options)
",1,fstnmmugha.py,local,,,0,0,0,0,0,1697644038000,1709736743962,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,python
hktcgwxlci,S3 upload files to object store,DEEPAK RANGARAO,"S3 upload files to object store, this involves getting the files from its original location to the local directory and then uploading to S3 using the AWS CLI.
Downloading data files to the local directory can be done using one of the other tasks around WGET etc. 
Dependencies= Task to install AWS CLI+Task to download data files to local directory",4,hktcgwxlci.sh,local,,,0,1,0,0,0,1698696893000,1709736634903,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,bash
huwsmgcvcs,Load data to mysql,Deepak Rangarao,"Load data to mysql, required parameters include
1) Input data file
2) MySQL connection string
3) New table to be created/appended",1,huwsmgcvcs.py,local,,,0,0,0,0,0,1692844567000,1709736726550,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,4,Data Generation,python
jpwikatqzb,Access WatsonX.Data using Apache Spark,Deepak Rangarao,"Access WatsonX.Data using Apache Spark, you will provide details to connect to the WatsonX.Data instance which will automatically update the spark config and you should be able to interactively use either PySpark or spark-sql to connect to and query WatsonX.Data. ",2,jpwikatqzb.py,local,,,0,0,0,0,0,1692897137000,1709736828786,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,pyspark
kdfzmbllnj,Get CRM information using Stepzen,Deepak Rangarao,Get CRM information using Stepzen,1,kdfzmbllnj.py,local,,,0,0,0,0,0,1691393217000,1709736706582,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,python
kwhkajvjfg,Download file using WGET,Deepak Rangarao,"Download file using WGET, check to see if it is a zip file and unzip if needed.",4,kwhkajvjfg.sh,local,,,0,0,0,0,0,1692868037000,1709736814958,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,bash
kxybylxlaa,Get Openshift node status,Deepak Rangarao,Get Openshift node status and save results to a file in the data directory. This task requires 1 parameter the oc login for the openshift cluster.,4,kxybylxlaa.sh,local,,,0,0,0,0,0,1692839112000,1709736717963,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,6,Openshift,bash
mpcpoxdvhh,Streamlit to display csv file,DEEPAK RANGARAO,Streamlit to display csv file,1,mpcpoxdvhh.py,local,,,2,0,0,0,0,1699038854000,1709736856531,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,python
nkzanjmnbg,S3 Install AWS CLI,DEEPAK RANGARAO,"Task to install the AWS CLI, this CLI can be used to connect to any S3 compliant object store including IBM Cloud Object Store. Currently has one dummy parameter which you can ignore, this could potentially be used for specifying the install location at a later date.",4,nkzanjmnbg.sh,local,,,1,0,0,0,0,1698686787000,1709736546172,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,bash
oeksnwcnck,View and search files in a folder,Deepak Rangarao,View and search files in a folder called logs. One input parameter to identify file pattern (Ex: *.log will pick all files with an extension .log). ,1,oeksnwcnck.py,local,,,0,0,0,0,0,1692839112000,1709736808303,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,6,Openshift,python
okivtsewst,Check OCP pods,Khanh,Check OCP pods,4,okivtsewst.sh,,,,0,0,0,0,0,1692963554000,1692963554000,5,964de1f2-e0ec-4f7e-8834-3b9e5ae1af2c,,,6,Openshift,bash
podztkfggi,Faker based customer data generation,Sarah Esmail,Faker based customer data generation,1,podztkfggi.py,,,,0,0,0,0,0,1692880966000,1692880966000,6,362e377f-e90c-4f84-9c42-4329ff58ce59,,,4,Data Generation,python
qhjiwzkkoi,Summary statistics of dataset,Deepak Rangarao,"Summary statistics of dataset, requires the following input parameters
1) Connection string
2) Table name",1,qhjiwzkkoi.py,local,,,0,0,0,0,0,1692875122000,1709736822258,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,4,Data Generation,python
spktzkjzze,Deploy Streamlit app v4,catherine.cao@ibm.com,test 4,4,spktzkjzze.sh,local,,,1,0,0,0,0,1698336733000,1698336733000,7,e62e1431-588f-483b-a115-1f70fa79a136,,,1,watsonx.ai,bash
vxciaoktmj,Generate sample customer data,Deepak Rangarao,Using Python Faker module to generate sample customer data,1,vxciaoktmj.py,local,,,0,0,0,0,0,1692844597000,1709736734870,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,4,Data Generation,python
xrdcrdigpz,Fake customer data,DEEPAK RANGARAO,Fake customer data,1,xrdcrdigpz.py,local,,,0,0,0,0,0,1696003304000,1709736837709,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,python
zoznkkxufe,Load WatsonX Data from Local File,DEEPAK RANGARAO,Load WatsonX Data from Local File,2,zoznkkxufe.py,local,,,0,0,0,0,0,1697650489000,1709736848804,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,pyspark
nitokamczz,CP4D Test Framework,GIRISH PADMANABHAN,Asset to test different aspects of a CP4D instance,4,testCP4D.sh,git,https://github.ibm.com/pgirish/lakehouse-api-e2e-tests,,0,0,0,0,0,1701090585380,1701090585380,331,1f0045c3-f9ad-4151-9c43-4e1f160bdf3e,,,5,CP4D,bash
iphgftvmqg,Get Openshift Cluster Node Status,Nupur Negi,"Check the status of cluster nodes until all nodes are in the 'Ready' state, displays the status of nodes and waits for a maximum of 60 seconds before timing out.",4,iphgftvmqg.sh,local,,,0,0,0,0,0,1690540781000,1701424047483,4,d788009d-6048-4b3e-bdfc-ed1b42f745df,,,6,Openshift,bash
ayuiefgkyw,watsonxdata_v2_api,Maritta Stephen,This asset allows to integrate and test the WatsonX_Data v2 API. The capability is limited to saas . Will expand to other environments.,4,testmain.sh,git,https://github.ibm.com/Maritta-Stephen/lakehouse-api-e2e-tests,,0,0,0,0,0,1701215945704,1701215945704,13,cfdc6077-4207-4a57-a0a2-aa319c25a6d7,,,2,watsonx.data,bash
rdnvlvkacm,example asset,Krishnadas N,test.api,4,mainexmple.sh,git,https://github.ibm.com/Krishnadas-N/lakehouse-api-e2e-tests/blob/848ce47a10b724f0d8af17883a88f1670937c6db/usecases/CP4D/BucketCatalogQuery.sh,,0,0,0,0,0,1706519488862,1706519488862,34,7349b4e7-180b-43e2-8d34-1c95dd41e27f,,,2,watsonx.data,bash
uhslypjyyn,Deploy streamlit application from git repo,DEEPAK RANGARAO,Point to any existing streamlit application stored in a git repository and it will deploy and execute the streamlit app.,4,uhslypjyyn.sh,local,,,0,0,0,0,0,1706591182163,1709736774686,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,1,watsonx.ai,bash
jrzuofuwuw,sampleasset,Krishnadas N,api sample,4,samplemain.sh,git,https://github.ibm.com/Krishnadas-N/lakehouse-api-e2e-tests,,0,0,0,0,0,1706610974834,1706610974834,34,7349b4e7-180b-43e2-8d34-1c95dd41e27f,,,2,watsonx.data,bash
ixzvtfduvo,CSV Viewer,Nupur Negi,Converts a CSV file into a table format to be displayed on the terminal.,4,ixzvtfduvo.sh,local,,,0,0,0,0,0,1706697303122,1706701194634,4,d788009d-6048-4b3e-bdfc-ed1b42f745df,,,7,FactSheet,bash
cmltlgoifu,Test multiple prompts against WatsonX.AI FLAN UL2 model using multiprocessing,Nupur Negi,"NOTE: This should be used in conjunction with the WGET to download files task. Upload a zip file to box/any location with multiple text files and 1 text file for the test data to use, each having a prompt you want to test. Now invoke this task as a 2nd step to read each of the prompt files and execute the prompt against the chosen model and display a F1  score compared to test dataset.",1,cmltlgoifu.py,local,,,0,0,0,0,0,1706767361192,1706769052620,4,d788009d-6048-4b3e-bdfc-ed1b42f745df,,,2,watsonx.data,python
pnfhcdderd,Watsonx.data_API,Maritta Stephen,This asset executes watsonx.data API,4,testmain.sh,git,https://github.ibm.com/Maritta-Stephen/lakehouse-api-e2e-tests,,0,0,0,0,0,1706778980932,1706778980932,13,cfdc6077-4207-4a57-a0a2-aa319c25a6d7,,,2,watsonx.data,bash
mhputzqmda,OCP and CP4D healthcheck tools,Rajesh Boda,OCP and CP4D healthcheck tools,4,executetasks.sh,git,https://github.com/bodarajeshkumar/cpdtools,,0,0,0,0,0,1707197366828,1708064706114,3,20d54209-025a-478e-99c5-5a1db4dd1089,,,5,CP4D,bash
wesopqejen,List contents of object storage bucket,Rajesh Boda,List contents of object storage bucket,6,,,,,0,0,0,0,1,1707305040067,1707305040067,3,20d54209-025a-478e-99c5-5a1db4dd1089,,,13,Use-case,useCase
evesbdorqg,Test multiple prompts against WatsonX.AI FLAN UL2 model,Nupur Negi,Test multiple prompts against WatsonX.AI FLAN UL2 model,6,,,,,0,0,0,0,1,1707306209984,1707306209984,4,d788009d-6048-4b3e-bdfc-ed1b42f745df,,,13,Use-case,useCase
kycghjxmhl,Upload Snowflake Data to COS,Pooja Holkar,"Using this asset we will be able to establish a connection to Snowflake using provided credentials. Execute a SQL query within Snowflake to select and fetch data from a table. Write the retrieved data from Snowflake into a CSV file and upload it to the desired bucket within IBM COS.
",1,kycghjxmhl.py,local,,,0,0,0,0,0,1707464184777,1707480963319,35,b75aa5ba-5eb0-43a7-823b-de194eacb83f,,,2,watsonx.data,python
befuhfjqge,CP4D GET All Users,DEEPAK RANGARAO,Cloud pak for data GET list of all users using the TOKEN generated with the Get CP4D Token task,1,befuhfjqge.py,local,,,0,0,0,0,0,1707850620616,1709736869485,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,python
fzjegfohfw,API Generate CP4D token,DEEPAK RANGARAO,Using REST API Generate CP4D token using the user name and API key.,4,fzjegfohfw.sh,local,,,0,0,0,0,0,1707892787569,1708390325851,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,bash
dwsfanlukm,Test AMS case,Ann Mary Luke,Test AMS case,4,testMain.sh,git,https://github.ibm.com/Ann-Mary-Luke/lakehouse-api-e2e-tests,,0,0,0,0,0,1707909889089,1707909889089,12,8788e98b-9670-4dad-8799-e8e9616f31d6,,,2,watsonx.data,bash
thzjxflzuq,API Create CP4D project,DEEPAK RANGARAO,Using Rest API create CP4D project by providing CP4D URL and project name. The token is generated by a separate task.,1,thzjxflzuq.py,local,,,0,0,0,0,0,1707925961759,1709736888353,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,python
ouqqywwzce,CPDCTL Create CP4D project and Import data assets,DEEPAK RANGARAO,Create CP4D project and Import data assets using the cpdctl tool.,4,ouqqywwzce.sh,local,,,0,0,0,0,0,1708022886323,1709736878375,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,bash
mqruldtkdn,CP4D project setup,DEEPAK RANGARAO,"Basic CP4D project setup, this includes generating the authentication token, creating a project and listing all users in the platform.",6,,,,,0,0,0,0,1,1708061560054,1708061560054,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,13,Use-case,useCase
ubrvpldfsr,CPD Healthcheck List,Suyash Gupte,"Select from list of health check tasks for your CP4D Openshift cluster. This task must be used along with ""OCP and CP4D healthcheck tools"" task.",3,server.js,git,https://github.com/SuyashGupte/cpd-healthcheck-ui,,0,0,0,0,0,1708064024399,1708064463722,10,c2cefc75-64f0-43ee-8019-7f1768b9a52a,,,5,CP4D,javascript
bzxktoumjw,OCP and CP4D healthchecks,Rajesh Boda,Select for list of health check tasks for your CP4D Openshift cluster and run the task to know the status,6,,,,,0,0,0,0,1,1708064199085,1708064199085,3,20d54209-025a-478e-99c5-5a1db4dd1089,,,13,Use-case,useCase
xjgjseydbf,API Perform MDI,DEEPAK RANGARAO,Using the REST API perform Metadata Import,1,xjgjseydbf.py,local,,,0,0,0,0,0,1708400972416,1708565892602,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,python
lanebkndpg,Customer Problem Journey,Snehal Pansare,"This asset is capable of extracting sentiments, tone, age, urgency of the complaint, it can summarise, identifies root cause, suggest investigation and resolution steps. It also identifies if customer is connecting for the first. All this information helps Customer Care agent to speed up Complaint resolution.",1,lanebkndpg.py,local,,,0,0,0,0,0,1708427786060,1708492465721,38,0d66e84f-b941-44ce-9e1b-d57c12c02380,,,1,watsonx.ai,python
dyiuifdaog,test single param,GIRISH PADMANABHAN,test single param,4,dyiuifdaog.sh,local,,,0,0,0,0,0,1708436148856,1708437018885,331,1f0045c3-f9ad-4151-9c43-4e1f160bdf3e,,,2,watsonx.data,bash
gzsgehnkir,CPDCTL CP4D Project Export to zip,DEEPAK RANGARAO,Using CP4D REST API Export all project assets to zip file,4,gzsgehnkir.sh,local,,,0,0,0,0,0,1708500869720,1709736927994,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,bash
oppeeyfhom,CPDCTL CP4D Project Import,DEEPAK RANGARAO,CPDCTL CP4D Project Import,4,oppeeyfhom.sh,local,,,0,0,0,0,0,1708504823031,1709736915781,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,bash
fduepnmlul,Clone private Git repository,DEEPAK RANGARAO,"Clone private Git repository, you need to provide the git repo url and the security token.",4,fduepnmlul.sh,local,,,0,0,0,0,0,1708554028398,1708556214106,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,bash
gnrymxhpqs,API Perform MDE,DEEPAK RANGARAO,"Using REST API perform metadata enrichment, this will do data profiling, data quality analysis and business term mapping.",1,gnrymxhpqs.py,local,,,0,0,0,0,0,1708565572530,1708566199032,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,9,WKC,python
thkmiuykxv,Starting with the Data Governance journey,DEEPAK RANGARAO,"Data governance first steps involves creating a project, connecting to data sources and extracting metadata and further enriching metadata with data quality metrics, business term mapping and data profiling information.",6,,,,https://github.com/drangar/usecases/blob/main/governance.md,0,0,0,0,1,1708566294318,1708570639088,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,13,Use-case,useCase
hitbqjwpue,Ansible screen scrape website,DEEPAK RANGARAO,Ansible screen scrape website,5,hitbqjwpue.yml,local,,,0,0,0,0,0,1708582400283,1709736903583,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,ansible
nskparnfsg,Ansible Clone Git repo and unzip file,DEEPAK RANGARAO,Ansible Clone Git repo and unzip file,5,nskparnfsg.yml,local,,,0,0,0,0,0,1708591342707,1709736685921,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,ansible
djnyvugyop,Universal data loader,DEEPAK RANGARAO,Universal data loader that is able to handle loading data stored in different file types.,2,djnyvugyop.py,local,,,0,0,0,0,0,1708591535005,1709736671855,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,pyspark
esakavznyd,Universal data loader,DEEPAK RANGARAO,Universal data loader is where you dont know what type of data file exists in a directory but you want to use apache spark to determine the file type and then appropriately do the load to the selected destination. Here we are only illustrating the use of Apache Spark and the determination of file type not the actual data load execution.,6,,,,,0,0,0,0,1,1708649568992,1708649568992,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,13,Use-case,useCase
hqgtnddzcl,CLI Handler - Maven,GIRISH PADMANABHAN,This will install Maven and configure it to be used within the workspace,4,hqgtnddzcl.sh,local,,,0,0,0,0,0,1708680518584,1708683366594,331,1f0045c3-f9ad-4151-9c43-4e1f160bdf3e,,,14,OIC,bash
yieyqjrgvu,Bash Handler,Rajesh Boda,This script accepts a message and store it in a config.json file. It also appends a message to a log file.,4,yieyqjrgvu.sh,local,,,0,0,0,0,0,1708680566925,1708680566925,3,20d54209-025a-478e-99c5-5a1db4dd1089,,,14,OIC,bash
qyiijculpr,Python Handler,Nupur Negi,NOTE: Need the bash handler to append the message to the log file.,1,qyiijculpr.py,local,,,0,0,0,0,0,1708680574221,1708680625325,4,d788009d-6048-4b3e-bdfc-ed1b42f745df,,,14,OIC,python
kvlfjdnogm,Java Handler,Rajesh Boda,This application reads config.json and appends the message the log file. It uses Maven to compile the application and run.,4,execute.sh,git,https://github.com/bodarajeshkumar/java-handler,,0,0,0,0,0,1708680774497,1708680959081,3,20d54209-025a-478e-99c5-5a1db4dd1089,,,14,OIC,bash
blgquiaxux,Logfile viewer,Rajesh Boda,View the logfile in UI,3,server.js,git,https://github.com/bodarajeshkumar/logfile-viewer,,0,0,0,0,0,1708680850767,1708680850767,3,20d54209-025a-478e-99c5-5a1db4dd1089,,,14,OIC,javascript
tvxubqavly,Hybrid Integration,Suyash Gupte,"This use case showcases the integration of multiple types of Tasks  including Bash, Python, Java and Javascript.",6,,,,,0,0,0,0,1,1708682483928,1708682483928,10,c2cefc75-64f0-43ee-8019-7f1768b9a52a,,,13,Use-case,useCase
ulravqvkye,API CP4D Create User,DEEPAK RANGARAO,API CP4D create user,1,ulravqvkye.py,local,,,0,0,0,0,0,1708956467503,1709736659721,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,5,CP4D,python
acirrdzbfp,PythonTrial,RASHMI KHANNA,my trial,1,acirrdzbfp.py,local,,,1,0,0,0,0,1709148793782,1709148793782,49,af6f4b60-7f5c-4ad9-9ce2-359f24afc154,,,14,OIC,python
anhqfgceky,Metadata Import and Enrichment,Joseph Kozhaya,Use case to illustrate how to apply metadata import and enrichment using Cloud Pak for Data. These are key steps/components in overall data governance solution enabled with Cloud Pak for Data.,6,,,,https://github.com/joe4k/usecases/blob/main/governance.md,0,0,0,0,1,1709691513074,1709691513074,32,7c160920-0d81-4e42-a607-c7bbfb8fe7d7,,,13,Use-case,useCase
dictsjlwlb,3rd party Demo PGA prediction streamlit application,DEEPAK RANGARAO,3rd party Demo PGA prediction streamlit application from https://github.com/andyuttley/PGAapp.git,1,pga_app.py,git,https://github.com/andyuttley/PGAapp.git,,0,0,0,0,0,1709751304861,1713532679397,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,1,watsonx.ai,python
ocuanlvzbb,Simulation - Source Masters data from watsonx.data,DEEPAK RANGARAO,Simulation - Source Masters data from watsonx.data,1,ocuanlvzbb.py,local,,,0,1,0,0,0,1709752033180,1709752033180,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,python
dknqpkwzjn,Simulation - train machine learning model using watsonx.ai,DEEPAK RANGARAO,Simulation - train machine learning model using watsonx.ai,1,dknqpkwzjn.py,local,,,0,0,0,0,0,1709752136941,1709752136941,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,1,watsonx.ai,python
aggooofhav,Predict Masters winner,DEEPAK RANGARAO,"Source data from a variety of data sources using watsonx.data, train ML/AI models using watsonx.ai and then build custom application to operationalize the ML/AI and predict the winner for Masters ! ",6,,,,,0,0,0,0,1,1709752279597,1709752279597,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,13,Use-case,useCase
kxepxnvkmi,Healthcare asset,Syeda Ameena Begum,"This solution turns complex medical reports into concise actionable summaries. And to further enhance user assistance we have integrated watsonx assistant powered chatbot which is tailored to assist different user personas like medical practitioners, patient, or be it a medical student in addressing their queries based on specific report.",1,kxepxnvkmi.py,local,,,0,0,0,0,0,1709802809364,1709806951467,48,fa21e126-7f26-40dd-a730-43c41c62a28a,,,1,watsonx.ai,python
cyuthxhlho,Do simple summary statistics,DEEPAK RANGARAO,"Do summary statistics on randomly generated data, if there is a specific dataset you want to use you can make a file of data available in the /data/my_data_file.csv",1,cyuthxhlho.py,local,,,0,0,0,0,0,1710292252568,1710299119276,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,python
ahhazfrkbd,do simple Summary statistics Test3,Avinash Kumar Singh,do simple Summary statistics Test3,1,ahhazfrkbd.py,local,,,0,0,0,0,0,1710376426439,1710376618501,54,87721afb-8a12-4dd5-932e-b0ef917b3a24,,,2,watsonx.data,python
novkruyxbm,Do Simple summary statistics,Ramananjali Mounica Golkonda,Summary stats on sample data,1,novkruyxbm.py,local,,,0,0,0,0,0,1710394987215,1710396971436,55,d46ed019-2d10-4d15-805e-773bb612f210,,,2,watsonx.data,python
skyqocvisv,WWPN Converter,Tsvetislav Ivanov,Add or remove colons from a WWPN,1,skyqocvisv.py,local,,,0,0,0,0,0,1711047528700,1711047868741,59,0786f6df-bbeb-4d6c-82a7-9fafc4588541,,,14,OIC,python
vwvrdwwapw,Script to do something,DEEPAK RANGARAO,Script to do something,1,vwvrdwwapw.py,local,,,0,0,0,0,0,1711745474187,1716926420639,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,2,watsonx.data,python
kfoqptbaqd,RAG Q&A Testing App,Sailendu Patra,Automated way of testing & evaluating RAG Pipeline using ground truth data,1,Archive/app.py,local,,,0,0,0,0,0,1712137584155,1712145107907,71,a7a36722-1fdc-49b6-860a-9b716f3a3dc7,,,13,Use-case,python
cotnbwzkrl,Automating Python Script Logging: Saving Logs to AWS S3,Rishabh Raj,"In this task, you'll be setting up a logging system for a Python script to track its execution and any relevant events. The logs generated by the script will be stored in an Amazon S3 bucket, providing a centralized location for monitoring and analysis. By implementing this solution, you'll enhance the script's traceability and make it easier to troubleshoot issues or track its performance over time.",1,cotnbwzkrl.py,local,,,0,0,0,0,0,1712142830380,1712228213453,74,039a9991-665f-473c-9e97-c61285f8cfb6,,,13,Use-case,python
hovtjinbgm,Automated Data Extraction: Extracting data from WatsonX.data  to AWS S3 using Presto,Diwakar Kumar,"This task involves developing a streamlined process for extracting data from the WatsonX.data and securely saving it in Amazon Web Services (AWS) Simple Storage Service (S3). The process will entail setting up efficient data extraction mechanisms from the WatsonX.data, ensuring that all relevant data is accurately captured. Subsequently, the extracted data will be transferred and stored within AWS S3.",1,hovtjinbgm.py,local,,,0,0,0,0,0,1712145613693,1712174201968,389,52a214e7-b813-4ec9-a083-f1b191b33f0a,,,2,watsonx.data,python
ikpomvmciw,Contextual Compression,Sourav Verma,"The idea is that instead of immediately returning retrieved documents as-is, you can compress them using the context of the given query, so that only the relevant information is returned. “Compressing” here refers to both compressing the contents of an individual document and filtering out documents wholesale.

Input: Context (str/file path) and a query (str) related to the context. To Use default setting, use empty string: '' for both the fields.

for more details, please refer to this git repo: https://github.ibm.com/Sourav-Verma/Contextual-Compression",1,ikpomvmciw.py,local,,,0,0,0,0,0,1712148122503,1717483716914,69,9747f2e1-d79d-48fb-809d-911095ab28e4,,,1,watsonx.ai,python
odefverczd,Insurance claim summarisation-,Richa Chander,"his notebook contains steps and code to demonstrate inferencing of prompts generated in Prompt Lab in watsonx.ai. It introduces Python API commands for authentication using API key and prompt inferencing using WML API.

Notebook goals
The learning goals of this notebook are:

Defining a Python function for obtaining credentials from the IBM Cloud personal API key
Defining parameters of the Model object
Using the Model object to generate response using the defined model id, parameters and the prompt input",1,odefverczd.py,local,,,0,0,0,0,0,1712215864354,1712216245198,76,e1fe551a-6384-410b-a1d9-17aee8274b5c,,,1,watsonx.ai,python
ndhumezecj,Asynchronous API calls with asyncio,Vignesh Babu,"Description: Implements the AsyncIO library for asynchronous programming, handling tasks with a more complex setup.
Pros: Delivers comparable response timings to Concurrent.futures, showcasing its efficiency in asynchronous operations.
Cons: Configuration is mildly more complicated, requiring a deeper understanding of asynchronous programming.
",1,ndhumezecj.py,local,,,0,0,0,0,0,1712219438457,1712222791590,77,f84b28e4-8661-45f2-8169-5a592be7b2a5,,,1,watsonx.ai,python
tyhilmubvi,Asynchronous API calls with concurrent.futures,Diwakar Kumar,"Description: Utilizes the Concurrent.futures module to manage a pool of threads, facilitating non-blocking API calls.
Pros: Offers the fastest response times with a straightforward configuration process.
Cons: Basic, but highly effective for the tasks at hand.",1,tyhilmubvi.py,local,,,0,0,0,0,0,1712223357780,1712223357780,389,52a214e7-b813-4ec9-a083-f1b191b33f0a,,,1,watsonx.ai,python
yjpecokzpg,Document Summarization using Mixtral Model with Auto Streamlit UI,Pinkal Patel,It is document summarization using mixtral model. Document is product manual or testing manual of product. UI is developed on Streamlit. Three inputs is required: 1. IBM_CLOUD_URL 2. PROJECT_ID (i.e. Watsonx.ai project id) 3. API_KEY (i.e. IBM Cloud API Key),1,yjpecokzpg.py,local,,,1,0,0,0,0,1712231883053,1712302115431,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,1,watsonx.ai,python
lncoupwjdo,Transcript Summarization using granite chat v2,Sunaina Saxena,This asset uses streamlit UI to upload a pdf document and then displays its summary on th UI which is generated using LLM call to granite chat v2,1,lncoupwjdo.py,local,,,0,0,0,0,0,1712734651628,1720434381621,79,a471ccaa-ef42-4134-bbdd-e28fc1a29ff1,,,1,watsonx.ai,python
lkobskysmy,Excel file processing.,Anitha M,Accepts an excel file as an input and outputs 2 separate csv file depending upon current and future key words,1,lkobskysmy.py,local,,,0,0,0,0,0,1712745211924,1712745211924,78,92caa69a-ce1b-43e4-aa0b-12e116a2d6e4,,,1,watsonx.ai,python
vvglgvhhea,Translator,Anitha M,A translator that accepts sentences in English and translates it into French and vie versa also,1,vvglgvhhea.py,local,,,0,0,0,0,0,1712747358611,1712747358611,78,92caa69a-ce1b-43e4-aa0b-12e116a2d6e4,,,1,watsonx.ai,python
fhcapmmmdn,JSON file processor,Anitha M,"The program accepts the JSON file as an input and removes nesting, in short flattens it",1,fhcapmmmdn.py,local,,,0,0,0,0,0,1712748244044,1712748244044,78,92caa69a-ce1b-43e4-aa0b-12e116a2d6e4,,,13,Use-case,python
vujaefqghw,Structured data analysis with KnowledgeGraph & LLamaIndex QueryEngine,Vignesh Babu,"How It Works
Data Loading and Preprocessing: The script starts by loading the structured data from a CSV file and preprocessing it for analysis.
LLM Preparation: It initializes an LLM model from IBM Watson Machine Learning, configuring it with specific generation parameters.
Embedding Generation: Using a pre-trained model from Hugging Face, it generates embeddings for the input data to be used in the knowledge graph.
Knowledge Graph Index Construction: If no existing index is found, the script builds a new Knowledge Graph Index from the structured data and embeddings.
Querying: Users can input queries based on the dataset, which are then answered using the constructed Knowledge Graph Index.",1,query_engine.py,git,https://github.ibm.com/Vignesh-R-Babu/Knowledge_Graph-based-llama_Index-query_engine,,0,0,0,0,0,1712753466912,1712753466912,77,f84b28e4-8661-45f2-8169-5a592be7b2a5,,,1,watsonx.ai,python
tcienbbknj,Watsonx AI workshop,DEEPAK RANGARAO,Watsonx AI workshop,1,sample_llm_ui_demo.py,git,https://github.com/drangar/watsonx_ai_workshop.git,,0,0,0,0,0,1713043294584,1713151194000,1,0aba5202-b452-440f-9ad2-0eec80a6f9e8,,,1,watsonx.ai,python
xdzcqqthng,Transfer data from Wx.data to external RDBMS,Rishabh Raj,In this asset we are transferring the data from a AWS S3 bucket linked on Wx.data to a locally hosted hosted SQLlite DB.,1,xdzcqqthng.py,local,,,0,0,0,0,0,1713164706048,1713164706048,74,039a9991-665f-473c-9e97-c61285f8cfb6,,,2,watsonx.data,python
yezohepnzl,Even Gary Can Upload,Gary Crupi,Copying Deepak's statistic gathering ingenuity.,1,yezohepnzl.py,local,,,1,0,0,0,0,1713196358522,1713903492426,87,2d9c7028-d7ea-4900-8295-97e2b54023ac,,,2,watsonx.data,python
ntgngsmcwt,Zoom meeting transcript cleaning,Sunaina Saxena,"Zoom meeting transcripts contain timestamps and other irrelevent text which is not important for further processing of the transcript data. Hence, we can remove that using given python script ",1,ntgngsmcwt.py,local,,,0,0,0,0,0,1713275433803,1716285518743,79,a471ccaa-ef42-4134-bbdd-e28fc1a29ff1,,,13,Use-case,python
yiichnobfz,Download directory from IBM cloud object storage to local by python program,Yaswanth Vudumula,"Download any directory content including sub directories from IBM cloud object storage to local by python program . This code can be used to download latest vectordb from IBM cloud object storage (cos)  to local / WS for further development. In our case one team member extracted required text , tables , fields , meta data (filename , page number)  from given PDFs and created different versions of vector db and uploaded to cos . I experimented tuned questions/ prompts with these latest vector dbs to achieve high accuracy.",1,yiichnobfz.py,local,,,0,0,0,0,0,1713276330573,1713335098982,91,dd3bf439-0685-49f2-a8d7-89e01704bde7,,,13,Use-case,python
btctepzroe,Clean Json output given by LLM ,Yaswanth Vudumula,"This function will clean incorrect or invalid JSON data given by LLM and create valid JSON. this is handling missing comma , misplaced comma , null value treatment , missing single quote or double quote , deduplicating comma & quotes , missing colon  , removing new line characters etc.
sample input : ['{""key1"":""7,"" ""key2"": 4""}' , '{""key1"": 68  ""key2"": 76}']",1,btctepzroe.py,local,,,0,0,0,0,0,1713279563405,1713331862193,91,dd3bf439-0685-49f2-a8d7-89e01704bde7,,,13,Use-case,python
vcqupduzrr,summarisation ,Sachu Jose Binoy,summuriztion from multiple summaries,1,vcqupduzrr.py,local,,,0,0,0,0,0,1713347077225,1716472479148,100,17734420-6f2e-47a5-b498-cdc365c4cbbd,,,1,watsonx.ai,python
yjfzbnaddk,Knowledge graph creation from triplets,Albin Thomas,"This is an asset to create a Knowledge graph from triplets in a json file. Triplets are a combination of subject, predicate and object. A triplet contains relationships between entities.




Neo4j_uri - This is the Uri for where neo4j is hosted

Neo4j_username and Neo4j_pwd = These are required to authenticate and connect to Neo4j

Database - This is the database name in Neo4j

File Path - This is the file path of the triplets file which is uploaded on Box. Get the download url by inspecting element and finding it on network section when you click download on the file on Box.",1,Vector-index/create_kg_from_triple.py,local,,,0,0,0,0,0,1713348653181,1719493762058,93,f4996ee5-1717-41e3-a915-739e494320bc,,,13,Use-case,python
ivqypmqads,Download file and compute statistics,Albin Thomas,This is just a test use case ,6,,,,,0,0,0,0,1,1713420503593,1713420503593,93,f4996ee5-1717-41e3-a915-739e494320bc,,,13,Use-case,useCase
ycertexopf,Create Sample LDAP Server,RASHMI KHANNA,Create sample openldap,4,ycertexopf.sh,local,,,0,0,0,0,0,1713460964566,1713858006794,49,af6f4b60-7f5c-4ad9-9ce2-359f24afc154,,,14,OIC,bash
hckyjvzqjn,Extract Table from PDF ,Ashwini Gadag,This asset will extract table content from pdf using Camelot library,1,hckyjvzqjn.py,local,,,0,0,0,0,0,1713518755992,1713518755992,339,9c7eeceb-35dd-454a-a248-d377cda68dcb,,,13,Use-case,python
tsicbdwzyc,Create OpenLdap Server,RASHMI KHANNA,"Create OpenLdap Server

Inputs:
ldap_domain: the ldap domain, default is `ibm.com`
ldap_password: admin password",4,setup-ldap.sh,git,https://github.ibm.com/rashmi-khanna/assethub-ldapserver,,0,0,0,0,0,1713858218492,1713858218492,49,af6f4b60-7f5c-4ad9-9ce2-359f24afc154,,,14,OIC,bash
vuedeodxdm,Parent Document Retriever using Elasticsearch as Vector Store for Child Chunks and Local Filestore as Docstore for Parent Chunks,Abhijeet Gorai,"The code has a ContextRetriever class which leverages the Parent Document Retriever, employing Elasticsearch as a Vector Store for Child Chunks and utilizing a Local Filestore as the Docstore for Parent Chunks.
There is also option for metadata filter while retrieving relevant chunks.
The function get_relevant_docs_with_similarity gives relevant documents along with similarity scores.",1,vuedeodxdm.py,local,,,0,0,0,0,0,1713858800042,1713858800042,333,d6be855f-9ff8-4ad3-a044-d35fadf47980,,,1,watsonx.ai,python
szvhglrhsq,Whisper transcript for Bank customer voice,Pratham Payra,this script will is give the text from speech,1,szvhglrhsq.py,local,,,0,0,0,0,0,1713865226815,1713865226815,110,f3a59545-4ed2-4613-8c10-16e25d375ac4,,,13,Use-case,python
kdalcznvkf,Topic Modelling using BertTopic,Ruhin Shaikh,"Using Berttopics to get insights about the data/documents being passed. The document to upload should be a csv file and should have ""TITLE"" and ""ABSTRACT"" columns ",1,kdalcznvkf.py,local,,,0,0,0,0,0,1713880672171,1719820540001,122,a3f396d5-dc83-4058-a600-1a1412a0dfdf,,,1,watsonx.ai,python
otjaeczspc,Text Preprocessing,Ankit Mahajan,"This Python code preprocesses text data in a CSV file by converting text to lowercase, removing numbers and punctuation, tokenizing the text into words, removing stopwords, and saving the preprocessed data back to a new CSV file.

Make sure to replace 'your_dataset.csv' with your CSV file's path and 'text' with the column name containing the text data. Install pandas and nltk libraries before running the code using pip install pandas nltk.",1,otjaeczspc.py,local,,,0,0,0,0,0,1713932036060,1713932036060,123,49374290-6c68-4d96-a71a-52c097803762,,,13,Use-case,python
lcjyaggzmn,Parallel Prompting and Cache on BAM APIs,Prasangi Bhaskar Tarun,"In this script, I have specified several features of BAM:

1. Generating Embeddings (with cache and parallel processing)
2. Chatting with LLM
3. Execution of prompts (with parallel prompting)",1,,git,https://github.ibm.com/Prasangi-Bhaskar-Tarun/BAM-APIs,,0,0,0,0,0,1713935553096,1713935553096,88,7c2cc3db-9183-44bd-85e7-a3345d4e0d0d,,,1,watsonx.ai,python
nqjbqifnqp,Code Generation,Ankitha Patel,Querying Pandas Dataframe,1,nqjbqifnqp.py,local,,,0,0,0,0,0,1713948551131,1713948551131,105,49b69ba7-76d1-43de-851d-4f6b4ce8df08,,,1,watsonx.ai,python
sbifjvoppr,Word explanation using LLM,Ankit Mahajan,This code defines a function generate_summary that takes a word as input and generates a summary about that word using the LLM LangChain model. The summary is then printed to the console. Adjust the max_length parameter to control the length of the generated summary.,1,sbifjvoppr.py,local,,,0,0,0,0,0,1713949699848,1713949699848,123,49374290-6c68-4d96-a71a-52c097803762,,,13,Use-case,python
dernwkveeg,Evaluating json output generated from prompt,Prerna Prem,"Evaluated json output generated from prompt using RougeL,F1 and exact match",1,json_output_verify.py,git,https://github.ibm.com/Prerna-Prem/json_output_verification.git,,0,0,0,0,0,1713952001773,1713952001773,353,1f9cc2a7-6dab-4a10-819d-2e7b489c0784,,,13,Use-case,python
kouesnbjbp,Ansible Playbooks for Automated Certificate Renewals,Ruman Shaikh,"Ansible playbooks written in yml file using Watsonx Code Assistant for Ansible Lightspeed, to automate the process of certificate renewal on z/os servers.",5,kouesnbjbp.yml,local,,,0,0,0,0,0,1713956979226,1713956979226,131,5378f5bf-dca3-4ed6-bcf1-c8b7d58f0f23,,,13,Use-case,ansible
kypkujigoy,selenium - webscraping,Dhanalaxmi Akenapally,web scraping using selenium. Chromedriver manager is installed using script itself. There is no need to install diver manually. ,1,kypkujigoy.py,local,,,0,0,0,0,0,1714376374598,1714377013539,133,034d2e3a-0749-4b51-b033-c7ffdf1b77e4,,,13,Use-case,python
qojrslkrqi,Weaviate wrapper for V4 Client,Pradumn Mishra,This is a wrapper for weaviate vector db for the latest version  (v4) of their python client.,1,weaviate_wrapper.py,git,https://github.ibm.com/Pradumn-Mishra/weaviate_wrapper_new,,0,0,0,0,0,1714466500834,1714466500834,81,17af19e4-be8a-4fb0-8f5e-06efc20e4659,,,13,Use-case,python
umpqlrtlqp,OIC Muti Asset Usecase,GIRISH PADMANABHAN,OIC Muti Asset Usecase Updated,6,,,,https://www.ibm.com/,0,0,0,0,1,1714735022308,1721379591178,331,1f0045c3-f9ad-4151-9c43-4e1f160bdf3e,,,13,Use-case,useCase
cagpynneui,Product Description Generation and Governance,Soumyajit Bera,This Project is related to product description generation using discovery OCR and also Governing the responses from watsonx.ai,1,,git,https://github.ibm.com/Soumyajit-Bera/HenrySchein-Nationals,,0,0,0,0,0,1714984927750,1714984927750,349,8a5ede2a-2e2a-4f3c-a3de-48a9190f37be,,,3,watsonx.governance,python
dtmcyguntu,RAG using Wx.Discovery and Neural Seek,Praneeth Bugata,"This asset will assist in ingesting documents into Wx.Discovery, configuring Wx.Discovery and Wx.AI with NeuralSeek",1,,git,https://github.ibm.com/Praneeth-Bugata/RAG-using-WX.Discovery-and-NeuralSeek.git,,0,0,0,0,0,1715063533671,1715063533671,165,dd68eb23-c797-4551-85e1-f35302e48960,,,13,Use-case,python
prchthimid,PDF Image Information Extractor with Boundary Box,Praneeth Bugata,"This asset facilitates the extraction of information from images within PDF documents, including their boundary boxes, using OCR-IOCR technology.",1,,git,https://github.ibm.com/Praneeth-Bugata/Boundary-Box-Info-using-OCR-IOCR.git,,0,0,0,0,0,1715064751577,1715064751577,165,dd68eb23-c797-4551-85e1-f35302e48960,,,13,Use-case,python
ysojowebav,GraphDB QnA - NLQ to Cypher ,Rishabh Chakrabarti,This asset provides a containerized API for graph related QnA using LangChain,4,ysojowebav.sh,local,,,0,0,0,0,0,1715066468437,1715147221273,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,1,watsonx.ai,bash
mijdsomeyg,WatsonX Discovery - Data Ingestion,Vishwajith C R,"Load data into WatsonX discovery fast, Build different embeddings with multiple indices",1,model_definition\ &\ data_ingestion/wx_deploy_custom_model.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Capability-Building-Wx-Discovery/tree/main/model_definition%20%26%20data_ingestion,,4,0,0,0,0,1715075306441,1715075306441,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,2,watsonx.data,python
mrbygzgkny,Java Code Minification,harikrishnan venkatesh,python script to minify java code so it takes up lesser tokens ,1,mrbygzgkny.py,local,,,2,0,0,0,0,1715151302628,1715151941444,350,8c14e6b0-879b-49f0-b937-4f7c507f0ae8,,,1,watsonx.ai,python
utbslefaqd,CUSTOM RAG TRIAD METRICS INTO Wx.governance,Dileep Vadlamudi,"Publishing RAG TRIAD Metrics like Context Relevancy , Answer Relevancy, Faithfulness and other Quality Metrics like Rouge, SARI,Meteor etc., to Openscale in Watsonx.governance",1,,git,https://github.ibm.com/Dileep-Vadlamudi1/RAG_TRIAD_WX_GOV/blob/main/GPT%20RAG%20Model%20-%20Monitoring%20-%20TRIAD%20-%202-2.ipynb,,2,0,0,0,0,1715158240747,1715158240747,168,f295cffd-bebb-47db-8b61-f467d89399c2,,,3,watsonx.governance,python
nbeoqmynut,RAG Fusion with Parent Child chunking using watsonx.ai and Langchain,Pradumn Mishra,"Implementation for an advanced RAG Technique - RAG Fusion alongwith an advanced chunking mechanism - The Parent Child Chunking.
References :
https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1
",1,rag_fusion/dummy.py,git,https://github.ibm.com/Pradumn-Mishra/RAG-Fusion-with-Parent-Child-Chunking-Watsonx.ai-Langchain,,0,0,0,0,0,1715233479838,1715233479838,81,17af19e4-be8a-4fb0-8f5e-06efc20e4659,,,13,Use-case,python
qjrskhnmvu,VRC Media SQL Query generator,"Karthik Vullam, Sriparna Banerjee, Akshay Kalane","Implemented a system that can identify relevant relational tables and columns in database from natural English/Japanese sentences.It converts the natural language sentences to SQL, and execute them, utilising gen AI and LangChain.
",1,frontend.py,git,https://github.ibm.com/client-engineering-japan/vrc-media,,0,0,0,0,0,1715253628540,1715253628540,177,eeb64982-6e57-4789-8522-725436a3323b,,,1,watsonx.ai,python
ovuzvunumi,Natural Language Query to SQL Generator,"Karthik Vullam, Sriparna Banerjee, Akshay Kalane","Tool to convert, user question written in NATURAL LANGUAGE to SQL QUERY.

This tool uses, power of AI and LLM models, to generate a query from the understanding of the database.",1,frontend.py,git,https://github.ibm.com/client-engineering-japan/vrc-media,,1,0,0,0,0,1715257369141,1715257369141,179,c64addff-2143-4cb4-912e-8184b440d7bf,,,1,watsonx.ai,python
dcovukpqkd,JAVA code getter and setter extractor,Shahzad Malik,"Extracts all Getter and Setter from the entire Java Code , Eliminates all comments , commented and unused functions from code .
Provides raw data of code . 

Input : - ( Copy Paste entire java code in assethub UI )

Output :- the output variable is df .
df      :-   Provides dataframe of Variables and function name in which it is used

",1,dcovukpqkd.py,local,,,0,0,0,0,0,1715263456195,1718887773855,99,525714b7-f6dc-46d2-8b03-eb2e0c8d62b5,,,13,Use-case,python
arkbnubelk,Java code seperation from Standard and Non-standard data types.,Shahzad Malik,"Provides datatypes and variable names used in java other than standard datatypes such as 'byte', 'short', 'int', 'long', 'float', 'double', 'char', 'boolean', 'String' .
and classify all variables based on the custom datatype .",1,arkbnubelk.py,local,,,0,0,0,0,0,1715263875649,1716814524522,99,525714b7-f6dc-46d2-8b03-eb2e0c8d62b5,,,13,Use-case,python
xhgtqcyzfr,Summary use case,Diwakar Kumar,This is a use case,6,,,,,0,0,0,0,1,1715312825672,1715312825672,389,52a214e7-b813-4ec9-a083-f1b191b33f0a,,,13,Use-case,useCase
hcljyfpksp,Multi Model Image Text To Text Code Engine,Owais Ahmad,Deployed Moondream Multi Model on Code Engine. All the asset regarding that is preset here. ,1,hcljyfpksp.py,local,,,0,0,0,0,0,1715318732841,1715321500134,182,9a113075-da8c-407e-ab81-7373bf2ed707,,,1,watsonx.ai,python
ozluuoqjbd,QnA RAG: Watsonx.ai and Watson Discovery RAG using Flask,Ayush Daya,"Using watsonx.ai and Watson Discovery, created a Flask based application for QnA",1,https://github.ibm.com/Ayush-Daya/wx-rag-service/blob/main/app.py,git,https://github.ibm.com/Ayush-Daya/wx-rag-service.git,,0,0,0,0,0,1715320790976,1715320790976,183,e5ac4ff0-67e2-41c9-b97b-35235f4f222c,,,1,watsonx.ai,python
hrlonfvenp,Code Engine Deployment Guide,Ayush Daya,Steps for deploying an application on Code Engine using github repository,1,,git,https://github.ibm.com/Ayush-Daya/code-engine-deployment.git,,0,0,0,0,0,1715321216370,1715321216370,183,e5ac4ff0-67e2-41c9-b97b-35235f4f222c,,,13,Use-case,python
yayjgirybx,Semantic similarity classification using watsonx.ai,Ayush Daya,Used watsonx.ai to classify whether two statements are semantically similar to each other,1,,git,https://github.ibm.com/Ayush-Daya/semantic-similairity-classification.git,,0,0,0,0,0,1715321811178,1715321811178,183,e5ac4ff0-67e2-41c9-b97b-35235f4f222c,,,1,watsonx.ai,python
hgzacsvycw,Using Watson Discovery through python API,Dhanalaxmi Akenapally,"This script is used to create project , list projects present , create collections , list all the collections present , adding documents like pdfs to the watsonx using python. You can also watson discovery search  for the uploaded documents.  prerequisites : watson discovery credentials like  apikey and url.",1,hgzacsvycw.py,local,,,0,0,0,0,0,1715321896925,1715321896925,133,034d2e3a-0749-4b51-b033-c7ffdf1b77e4,,,12,Watson,python
zhkycnosuj,React ChatBot,Mohit Nilkute,"An easy to integrate and completely customisable ChatBot UI with required functionalities which only takes a handler function as an input to handle the message response.

Instructions:
Step 1: Export this Asset first of all.
You will see the complete react package in the asset with the ChatApp Component and an example page where we are using the ChatApp component.

Step 2:  Run these commands in terminal to install dependencies and start the react application.
```
npm i
npm install react-chatbot-kit
npm start
``` 
OR Directly run the bash.sh file  
``` 
bash bash.sh
 ```

Step 3: Try querying the chat-bot with some questions in the input section of chat-bot.
For now, it will only reply with the question itself, as mentioned in the handler function in the chat page. You can change this function as per your needs, to handle the response as you like.",4,bash.sh,git,https://github.ibm.com/Mohit-Nilkute/chat-app.git,,0,0,0,0,0,1715327187965,1715327187965,73,dd23b642-9d29-4ea2-b6e7-6f16f4c2fb92,,,13,Use-case,bash
qcuzjdvigr,iLAB yaml file automation for knowledge base creation,Diptanshu Gautam,The code will create the yaml qna file which is required for knowledge base creation for fine tuning llms in instruct lab,1,qcuzjdvigr.py,local,,,0,0,0,0,0,1715585525134,1715585525134,187,5dbe3932-c73f-4a34-bc70-a77a871596a0,,,4,Data Generation,python
fwukmgvlcr,File extraction from a nested file system,Diptanshu Gautam,Extracting the list of all specific files (with a particular extension) from a nested file system,1,fwukmgvlcr.py,local,,,0,0,0,0,0,1715586072014,1715586072014,187,5dbe3932-c73f-4a34-bc70-a77a871596a0,,,13,Use-case,python
nisrtxtflp,Key Value extraction for complicated dictionary,Diptanshu Gautam,The code aims to simplify search process in a dictionary. It traverses through a nested dictionary and provides the path to the key and value of a given key. It is specifically useful while using Watson Discovery,1,nisrtxtflp.py,local,,,0,0,0,0,0,1715586961360,1715586961360,187,5dbe3932-c73f-4a34-bc70-a77a871596a0,,,1,watsonx.ai,python
ozmyppfuvn,Marketing Content Generation,Karthik Vullam,"CogniCraft is the Smart AI tool, designed to generate captivation catch-lines and advertisement content for social media platforms and posters.",1,app/modular.py,git,https://github.ibm.com/Karthik-Vullam/Marketing-Content-Generation-and-SMA,,0,0,0,0,0,1715588442130,1715588442130,179,c64addff-2143-4cb4-912e-8184b440d7bf,,,13,Use-case,python
wnzinmnhlb,XML to SQL generation,Mohammed Ali Shaik,This is an streamlit app which needs required environmental variables related to watsonx and an xml file which has ETL for informatica as input to run the app.,1,__MACOSX/._app.py,local,,,0,0,0,0,0,1715595446164,1717137913381,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,python
tmrnpvsdfk,Knowledge Graph with Structured Data,Pradumn Mishra,"A solution for creating Knowledge Graph Embeddings and visualization for tabular data.
Steps to setup
Download the files.
Navigate into the structure_data folder cd kg_structured
Create virtual environment using python -m venv env
Activate the virtual environment using source venv/bin/activate
Install dependencies using pip install -r requirements.txt
Create a .env file by following the conventions in .env-example file
In another terminal navigate into neo4j_module folder by running cd neo4j_module and then run the neo4j docker container using docker-compose up -d
In another terminal navigate into weaviate_module folder by running cd weaviate_module and then run the weaviate docker container using docker-compose up -d
First run the generate_ontology_structured.ipynb notebook in neo4j_module folder. You may change the dataset and also choose data cleaning steps accordingly. This notebook will create a knowledge graph for your data in neo4j.
Then run natural_language_to_cypher_vectordb.ipynb notebook to create possible natural language queries for the data. you will need to modify the queries according to your data.
Now run generate_embeddings.ipynb notebook to push those queries and cypher into weaviate.
Now you can use the cypher query obtained to query the graph using neo4j and use the results as context for RAG using LLM.
For graph visualisation we are using pyvis. Run Visualizations_pyvis.ipynb for graph html generation into html folder. You can open that in browser to see the graph. Modify the notebook according to your data.
",1,test.py,git,https://github.ibm.com/Pradumn-Mishra/Knowledge-Graph-with-Unstructured-Data,,0,0,0,0,0,1715598900594,1715598900594,81,17af19e4-be8a-4fb0-8f5e-06efc20e4659,,,13,Use-case,python
dhkabfejza,RAG Evaluation using Trulens,Abhijeet Gorai,"This asset facilitates the evaluation of a Retrieval-Augmented Generation (RAG) pipeline using the Trulens framework and Watsonx LLM. Leveraging the MS Marco dataset, this asset provides a comprehensive evaluation based on the RAG triad of metrics, ensuring robust assessment of the RAG pipeline's performance.

Key Features:
1. Evaluation Framework: Utilizes the Trulens framework for detailed evaluation, offering insights into the effectiveness and efficiency of the RAG pipeline.
2. Watsonx LLM Integration: Integrates Watsonx Large Language Model to enhance the evaluation process, providing state-of-the-art language understanding and generation capabilities.
3. User-Friendly Interface: Generates a Streamlit UI link upon running the code, allowing users to easily view and interact with the evaluation results.

How to Use:
1. Run the Code: Execute the provided code to initiate the evaluation process.
2. Access the Results: Upon completion, Trulens provides a link to a Streamlit UI.
3. View the Evaluation: Open the Streamlit link in your browser to view and analyze the evaluation results.",1,evaluation.py,git,https://github.ibm.com/Abhijeet-Gorai/rag-evaluation-trulens,,0,0,0,0,0,1715664024745,1715664024745,333,d6be855f-9ff8-4ad3-a044-d35fadf47980,,,1,watsonx.ai,python
xcjmiauacc,PDF Highlighter,"Mehul Joshi , Harikrishnan Venkatesh","The provided `PDFEditor` class offers three main functions for working with PDF files:

1. Highlight Fuzzy Text: 
   - `highlight_fuzzy_text_in_pdf` searches for text similar to a given string on a specified PDF page and highlights it, then saves the modified page to a new PDF.

2. Extract Single Page: 
   - `create_single_page_pdf` extracts a specified page from a PDF file and saves it as a new single-page PDF.

3. Convert PDF to Image: 
   - `convert_pdf_image` converts the first page of a PDF file into a JPEG image and saves it to an `output` directory.

These functions facilitate text searching, page extraction, and format conversion for PDF documents.",1,xcjmiauacc.py,local,,,0,0,0,0,0,1715665623246,1716544619192,186,e292202d-0d99-4ab1-82bc-34d06516f804,,,1,watsonx.ai,python
ehwrdkcdpj,"Creation of mandates, sub mandate and requirements",Deepak Nayak,"This repo contains the python script for creating mandate, sub mandate and requirements GRC object. And also how we can link 2 articles if they are related using href tag in IBM OpenPages.",1,IBMOpenpages.py,local,,,1,0,0,0,0,1715672012381,1715672012381,130,0cd3f594-4309-4acf-a8da-223923e96b30,,,3,watsonx.governance,python
qsifhsmavj,Run watson studio Job by python api,Yaswanth Vudumula,"Run watson studio Job by python api. so we can run Jobs from anywhere . first you need to create Job to your jupyter notebook in watson studio project. then use your ibm cloud api, project id , job name  as inputs. i commented few lines in code those will allow you to pass job specific environment variables. Document references : https://cloud.ibm.com/apidocs/watson-data-api-cpd#job-runs-create . you can explore many APIs in this website.",1,qsifhsmavj.py,local,,,0,0,0,0,0,1715674878503,1715680773075,91,dd3bf439-0685-49f2-a8d7-89e01704bde7,,,12,Watson,python
neytikcwtr,Watsonx Assistant Customization,Pankaj Balchandani,This repo includes Watsonx Assistant Customizations which could be used in multiple way to increase the functionality of assistant.,3,,git,https://github.ibm.com/Pankaj-Balchandani/WA_Customization,,0,0,0,0,0,1715678378270,1715678378270,193,437e7ade-aa63-4cfc-92f0-772ac97af207,,,12,Watson,javascript
oruwhjpkwv,Extract Text From Images ,Sourabh Jha,"Given a image containing text this code can extract text from it.
supported algorithm : easyocr,pytesseract",1,oruwhjpkwv.py,local,,,0,0,0,0,0,1715678751914,1715680646965,195,de5b5281-49fd-4f69-ae84-97d9c688e187,,,13,Use-case,python
kdgruiehaf,Entity Extraction and Comparison,Charana H U,Entity Extraction and Comparison using WatsonX Large Language Models,1,https://github.ibm.com/Client-Eng-EMEA-IN/db-schenker-entity-extraction/blob/main/src/entity_extraction/app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/db-schenker-entity-extraction,,0,0,0,0,0,1715678809496,1715678809496,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
vnzzghccof,RAG Chatbot automation using WebCrawling and Semantic Cache,Charana H U,"""RAG Chatbot automation using WebCrawling"" is chat bot, which is developed using Watsonx Assistant, Watson Discovery and Watson X.AI.
It also leverages semantic cacheing for faster response.",1,https://github.ibm.com/Charana-H-U/World_Of_Tanks/src/app.py,git,https://github.ibm.com/Charana-H-U/World_Of_Tanks,,0,0,0,0,0,1715679121936,1715679121936,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,13,Use-case,python
kmkgdzntlk,Converting excel data from 2D array to 1D array ,Priyanka Mohekar,This 1D array excel data can be passed to WatsonX Discovery post embedding for Keyword extraction.,1,,git,https://github.ibm.com/Priyanka-Mohekar/Atos-Procurement,,0,0,0,0,0,1715679579269,1715679579269,196,3e391705-f457-4fcc-8dc6-7a02834890b7,,,4,Data Generation,python
bxngxdlqym,Chat with CSV,Charana H U,"Chat with CSV: We created an streamlit application where you can upload your CSV file, and you can chat with the large language models in the context with the CSV file.",1,https://github.ibm.com/Charana-H-U/Chat_with_CSV/app.py,git,https://github.ibm.com/Charana-H-U/Chat_with_CSV,,0,0,0,0,0,1715679636765,1715679636765,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
wupfhkgems,CodeGen,Charana H U,This is a code generation prototype project that uses IBM Watson Language Model to generate HTML code based on natural language queries.,1,https://github.ibm.com/Charana-H-U/CodeGen/src/app.py,git,https://github.ibm.com/Charana-H-U/CodeGen,,0,0,0,0,0,1715679855099,1715679855099,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
asrztwysli,Fastapi _post_request,Dhanalaxmi Akenapally,A simple fastapi to deal with both json data and file type data ( when input schema contain both text data and files to be uploaded ) in post request.,1,asrztwysli.py,local,,,0,0,0,0,0,1715680098875,1715680098875,133,034d2e3a-0749-4b51-b033-c7ffdf1b77e4,,,13,Use-case,python
wuhpcakdgh,Embedding based Large Documents Classification,Charana H U,System that can classify the new multiple paged(10+ pages) document into the respective category based on the content of the document which will be compared with the existing documents in the system. So our approach is to converting the documents into embedding and storing those embedding and respective class label in Milvus. When we get a new document we convert it into embedding and search for the nearest embedding in Milvus and return the class label of the nearest embedding.,1,https://github.ibm.com/Client-Eng-EMEA-IN/archimed/src/app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/archimed,,0,0,0,0,0,1715681218740,1715681218740,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,13,Use-case,python
npflsjbiwn,Java Code Generation using Pseudocode ,Paarttipaabhalaji Manohar & Raveena Khan,"With the help of this asset you can generate the Java source code by comparing old pseudocode, old java code and new pseudocode.
",1,npflsjbiwn.py,local,,,0,0,0,0,0,1715681373595,1716545644476,189,87afe89a-d025-44ad-b82c-c176d78c58f8,,,1,watsonx.ai,python
lwcncgozcm,Indexing in WatsonX Discovery through python API post embedding,Priyanka Mohekar,This asset helps in creating the embeddings using SentenceTransformer and at the same time you can create the file in WatsonX Discovery (Elastic Search database) and do indexing.,1,,git,https://github.ibm.com/Priyanka-Mohekar/Embedding,,0,0,0,0,0,1715682123745,1715682123745,196,3e391705-f457-4fcc-8dc6-7a02834890b7,,,13,Use-case,python
duizimlaoz,Fast_api_post_request_optional_inputs,Dhanalaxmi Akenapally,Sample code when some fields are mandatory and some are optional . It also shows code for uploading multiple files at time ,1,duizimlaoz.py,local,,,0,0,0,0,0,1715683875634,1715755512940,133,034d2e3a-0749-4b51-b033-c7ffdf1b77e4,,,13,Use-case,python
mhmpdhtkvi,HR Solution,Sourabh Jha,"This project aims to streamline the process for Human Resource and have following features :
1. Resume Scoring : It can give each resume a score give a job description. We have the explainability factor for scores given.
2. Job Description Creation : Provided with keyword of a job it can create a customised Job Description
3. Question Generation for Screening : It can generate questions based on the Resume and JobDescription provided and it covers all round factors from technical to non-technical questions. ",1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/HR-Recruitment.git,,0,0,0,0,0,1715685028239,1715685028239,195,de5b5281-49fd-4f69-ae84-97d9c688e187,,,1,watsonx.ai,python
qomcmbhzet,"Read tables from DOCX files,Extract highlighted text and shading colours and write the extracted data into a CSV file",Sonali Kanungo,"This code reads tables present in docx files, extract any highlighted text positions and create a csv out of it.",1,qomcmbhzet.py,local,,,1,0,0,0,0,1715685304828,1715685304828,113,970402b4-12fd-4d68-95b0-a1fd5e6ff766,,,13,Use-case,python
vvkgqjtrfc,Read data from Mango DB,Sonali Kanungo,This code connects to Mango DB instance and read tables & create data frame from it.,1,vvkgqjtrfc.py,local,,,0,0,0,0,0,1715688579793,1715688579793,113,970402b4-12fd-4d68-95b0-a1fd5e6ff766,,,13,Use-case,python
adhnrwkicd,Table Extraction With DeepSearch,Sourabh Kumar,"Deepsearch is an open tool as well has enterprise edition and is IBM tool. It extracts tables and text pretty well and metains the table structure (multi-indexing etc.). Since we are to avoid open source libraries this can be a really good tool to use in your PoC. Currently in free version we don't have OCR enabled but can be provisioned with Enterprise edition. Below are the url's which you can refer to:
Deep Search Landing Page : https://ds4sd.github.io/
DeeSearch Tool Kit : https://github.com/DS4SD/deepsearch-toolkit

Steps to obtain credentials : 
1. got to https://ds4sd.github.io/ and click free access
2. Click on Toolkit/API (top right)
3. Copy login command and in .env file paste it. (inside .env : login_cmd='your login command')
4. generate new api key and copy it. (inside .env : deepsearch_api_key='your login command')
5. you need to get your project key (have included that in code)",1,adhnrwkicd.py,local,,,0,0,0,0,0,1715689962940,1715690038170,195,de5b5281-49fd-4f69-ae84-97d9c688e187,,,13,Use-case,python
kutsbnpmlo,GenAI app containarization & Deployment in Code Engine,Aravind Krishnan B,containarization app,1,src/00_rag_ibmcloud.py,local,,,0,0,0,0,0,1715690140340,1715690140340,155,75db13ed-ea72-4528-9ee6-6f4c027ce9d1,,,1,watsonx.ai,python
tbbradhird,Openshift deployment Application base,Aravind Krishnan B,GenAI application base to be deployed on Openshift CP4D,1,src/04_on_prem_cp4d_app.py,local,,,1,0,0,0,0,1715690297045,1715690297045,155,75db13ed-ea72-4528-9ee6-6f4c027ce9d1,,,1,watsonx.ai,python
isteqvovef,Context aware chatbot with RAG ,Aravind Krishnan B,Chatbot with context awareness and RAG functionality implemented using langchain.,1,src/03_rag_with_memory_chat_langchain.py,local,,,0,0,0,0,0,1715690401574,1715690401574,155,75db13ed-ea72-4528-9ee6-6f4c027ce9d1,,,1,watsonx.ai,python
gwhqgypnuc,Extract tables from PDF with MultiProcessing and Camelot,Aditya Mahakali,Extract tables from multiple PDFs to fully utilise available resources and get fast extractions.,1,table_extraction/Extract_tables_from_multiple_pdfs_camelot.py,git,https://github.ibm.com/Aditya-Mahakali/Assets_Aditya_Mahakali/tree/main/,,2,0,0,0,0,1715708140574,1715708140574,125,26a960b7-c9b7-4d0f-a3b4-7c90f7be87e2,,,1,watsonx.ai,python
jimjiiczre,Crawl a website given a base url,Aditya Mahakali,Extract all the unique pages of website with control over depth and number of pages,1,BFS_Crawler/bfs_crawler.py,git,https://github.ibm.com/Aditya-Mahakali/Assets_Aditya_Mahakali/blob/main/,,0,0,0,0,0,1715708686124,1715708686124,125,26a960b7-c9b7-4d0f-a3b4-7c90f7be87e2,,,1,watsonx.ai,python
vzhkjtwkdj,Ingest data to wxDiscovery with an ingestion pipeline,Aditya Mahakali,"Easily ingest data to wxDiscovery with an ingestion pipeline, this leverages wxDiscovery's cloud compute resources.
In case of genai use cases this will is useful for simpler chunking and embedding generation",1,WxDiscovery/ingest_documents_with_pipeline.py,git,https://github.ibm.com/Aditya-Mahakali/Assets_Aditya_Mahakali/blob/main,,0,0,0,0,0,1715709223626,1715709223626,125,26a960b7-c9b7-4d0f-a3b4-7c90f7be87e2,,,1,watsonx.ai,python
mcbpeogyqw,Dockerized python code sandbox,Aditya Mahakali,"Dockerized code sandbox for execution of python code in isolation for Agentic workflows.
Communicate with the container via a fast API, send python code commands and receive output.",1,code_sandbox/app.py,git,https://github.ibm.com/Aditya-Mahakali/Assets_Aditya_Mahakali/blob/main/,,0,0,0,0,0,1715709570457,1715709570457,125,26a960b7-c9b7-4d0f-a3b4-7c90f7be87e2,,,1,watsonx.ai,python
cqgewbvbkt,Self correcting SQL Queriy Generator and Execution Agent,Aditya Mahakali,"Natural Language to SQL Queriy generator and code executor on a connected Database.
Follows a self-reflection and correction mechanism until it is able to generate working SQL Queiy.
Using Postgres database, returns a data frame which is stored with unique uuid",1,Self_Correcting_SQL_Agent/SqlAgent.py,git,https://github.ibm.com/Aditya-Mahakali/Assets_Aditya_Mahakali/blob/main/,,2,0,0,0,0,1715709921934,1715709921934,125,26a960b7-c9b7-4d0f-a3b4-7c90f7be87e2,,,1,watsonx.ai,python
fgdnrmksca,"Custom RAG Evaluation, Traditonal Metrics + score, category and LLM Based remarks",Aditya Mahakali,"Custom RAG Evaluation, Traditonal Metrics + score, category and LLM Based remarks

Calculation of following metrics:
 ""remark"", ""category"", ""score"",""jaccard_similarity"",""cosine_similarity"",""levenshtein_distance"",""url_availabilty"",""url_MRR_rank""


",1,Custom_RAG_Evaluation/RAG_EVAL.py,git,https://github.ibm.com/Aditya-Mahakali/Assets_Aditya_Mahakali/tree/main,,2,0,0,0,0,1715710713554,1715710713554,125,26a960b7-c9b7-4d0f-a3b4-7c90f7be87e2,,,1,watsonx.ai,python
mwbauymntj,secure FastAPI usage asset for RAG use cases,Aditya Mahakali,Complete FastAPI asset with normal answer generation as well as streaming endpoint as well as supported classed for llm and retrieval,1,api.py,git,https://github.ibm.com/Aditya-Mahakali/Assets_Aditya_Mahakali/tree/main/fastapi_search_service_secure,,0,0,0,0,0,1715712096269,1715712096269,125,26a960b7-c9b7-4d0f-a3b4-7c90f7be87e2,,,1,watsonx.ai,python
kekywfgofv,RAG Playground,Shivam Patel,"An Intuitive Platform for Developing and Optimizing Retrieval Augmented Generation (RAG).

RAG Playground is a user-friendly Streamlit application designed to streamline the development, experimentation, and evaluation of Retrieval-Augmented Generation (RAG) models. This powerful tool empowers users to create end-to-end RAG pipelines, experiment with various components and parameters, and assess the performance of a RAG pipeline.",4,kekywfgofv.sh,local,,,0,0,0,0,0,1715750237319,1715770355181,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,1,watsonx.ai,bash
qtxqvwomgj,aws_ocr_pdf_to_text,Aanchal Goyal,"""aws_ocr_pdf_to_text.py"" is a Python script that utilizes AWS OCR (Optical Character Recognition) services to extract text from PDF documents. The script takes a PDF file as input and generates a text file containing the extracted text.

You need to pass the aws credentials inside the code to execute the file
# Set AWS credentials
aws_access_key_id = ''
aws_secret_access_key = ''
aws_region = ''

The code reads PDF documents from an ""input"" folder, extracts text using Textract, and saves the extracted text as individual text files in an ""output"" folder. ",1,qtxqvwomgj.py,local,,,0,0,0,0,0,1715750857406,1715750857406,159,f36e7cba-5268-4d92-9a45-070b764ac1fa,,,13,Use-case,python
cdgnvnrtcm,Function calling using LLMs,Mohith Charan R,"This Python code uses an AI model to automate the selection and invocation of computational tools based on user input. It generates prompts, sends them to an AI service, extracts the tool and arguments from the response, and calls the corresponding function to perform operations in the functions.",1,cdgnvnrtcm.py,local,,,0,0,0,0,0,1715752138622,1715752138622,204,59846178-b3ed-424c-bbb9-8687db62f2f2,,,1,watsonx.ai,python
pocjkcqhdz,Knowledge graph ontology extraction from unstructured text,Mohith Charan R,"This prompt instructs an AI assistant to create an ontology for a knowledge graph from provided text within a specified domain. The assistant is guided to identify classes, attributes, and relationships from the text and output the ontology schema in JSON format. ",1,pocjkcqhdz.py,local,,,0,0,0,0,0,1715752494441,1715752568961,204,59846178-b3ed-424c-bbb9-8687db62f2f2,,,1,watsonx.ai,python
ossbitpjai,Crafting Clear Instructions/Prompts  for LLMs,Mohith Charan R,"Develop detailed, task-specific prompts for an inexperienced AI assistant, guiding it to complete various tasks accurately and consistently. Use examples and XML tags to ensure clarity and structure in the instructions. The process is supported by a simple-to-use UI for easy setup and implementation.",1,ossbitpjai.py,local,,,0,0,0,0,0,1715753992248,1720517772499,204,59846178-b3ed-424c-bbb9-8687db62f2f2,,,1,watsonx.ai,python
ibkgmanxsu,Query Modification for advanced retrieval,Mohith Charan R,Modify complex queries with multiple intents into simpler queries to enhance retrieval in rag systems,1,ibkgmanxsu.py,local,,,0,0,0,0,0,1715755526310,1715755526310,204,59846178-b3ed-424c-bbb9-8687db62f2f2,,,1,watsonx.ai,python
ocblqacbrk,LLM_Model_Evaluation,Pallavi Pannu,"This script demonstrates how to evaluate the performance of two models, LLAMA-70B and Mistral, by computing performance metrics like Bert and ROUGE scores for their generated answers compared to reference answers. 
",1,ocblqacbrk.py,local,,,0,0,0,0,0,1715760436579,1715760608599,128,9dbc8b45-ec32-482b-a376-40a53bb5e9cf,,,1,watsonx.ai,python
ovxlfovigc,Email Automation with Orchestrate,Tannavi Snehal,The Open API Skills for making an Email Automation Flow starting from receiving an email in inbox to generating an email response based on some data present in the database.,1,app.py,git,https://github.ibm.com/Tannavi-Snehal/Email-Automation-Orchestrate.git,,0,0,0,0,0,1715766006472,1715766006472,208,8540709c-6c01-4769-afa8-d0984a1221fb,,,13,Use-case,python
mklkpkkqid,Data Ingestion from watson Discovery to WatsonX Discovery,Jani Basha S,Data Ingestion from watson Discovery to WatsonX Discovery,1,mklkpkkqid.py,local,,,0,0,0,0,0,1715767421460,1715767421460,132,ce7ca4ce-259d-412e-9593-9f543a5d3a4b,,,12,Watson,python
otevvvuwta,RAG BASE ASSET,RAKESH LINGUBARI,It is a boiler template for RAG base asset.,1,main.py,git,https://github.ibm.com/RAKESH-LINGUBARI/Asset-hub-RAG-base-asset,,0,0,0,0,0,1715767707361,1715767707361,447,725fb9bd-ba84-4e92-a9b2-b7e716ecd52c,,,1,watsonx.ai,python
acxgdmnrxa,Merge_Ansible_Script,Mohit Nilkute,"Merge two Ansible scripts with respect to their sections. 
Input : Two download-able URL's for the files to be Merged.
If not able to download from the URL, it will take it's own example and show the merging !
Try exporting this Asset for merging your own Scripts.",4,bash.sh,local,,,0,0,0,0,0,1715768852032,1716390547710,73,dd23b642-9d29-4ea2-b6e7-6f16f4c2fb92,,,13,Use-case,bash
hckzqcwcil,LLM Hyperparameter Tuning,Pallavi Pannu,"This script is designed to do the llm hyperparameter tuning with different temp, top_p, top_k and computes the metrics (Bert and Rouge scores) and it selects the best parameters with the highest average score.",1,hckzqcwcil.py,local,,,0,0,0,0,0,1715771884962,1715771884962,128,9dbc8b45-ec32-482b-a376-40a53bb5e9cf,,,1,watsonx.ai,python
xulzamsdkt,PDF Document Summarisation with Concurrent.Futures Method,Rituja Waghmore,"This script enables you to summarize the entire document efficiently using the concurrent.futures method for optimization. It accepts a file_path as input and generates the complete document summary.
Prepare your .env file  and it must contain the following 2 variables
GENAI_KEY=YOUR_BAM_API_KEY 
GENAI_API=https://bam-api.res.ibm.com ",1,xulzamsdkt.py,local,,,0,0,0,0,0,1715777258190,1717491162816,157,3681bca9-a3c9-415d-ab78-c4c28823784a,,,13,Use-case,python
rmclzvltof,JSON Hierarchy Visualization: Simplifying Complex Structures with Python,Rituja Waghmore,"The Python script accepts nested JSON as input and produces a clear, easy-to-understand flow, aiding comprehension of hierarchical levels. It reads a JSON file and saves the hierarchical flow visualization in a file named 'hierarchical_flow.txt'.
Sample Json structure:
{'Source':{
    'l1_key1':
            {
                'l2_key1':
                {
                    'l3_key1':[1,2,3]
                }
            },
    'l1_key2':
            {
                'l2_key2':[4,5,6]
            }
    
}}

Output:
Source
    ├── l1_key1
    │   └── l2_key1
    │       └── l3_key1
    └── l1_key2
        └── l2_key2",1,rmclzvltof.py,local,,,0,0,0,0,0,1715778067490,1715778067490,157,3681bca9-a3c9-415d-ab78-c4c28823784a,,,13,Use-case,python
bhqevbkmzt,RAG Explainability using source attribution,Sailendu Patra,RAG Explainability using source attribution,1,openscale_deploy/main.py,local,,,0,0,0,0,0,1715822898574,1715842960130,71,a7a36722-1fdc-49b6-860a-9b716f3a3dc7,,,3,watsonx.governance,python
wnraugueqz,Personalized Marketing Message Generation Integrated with Twilio,"Gopagoni Jyothika ,Devi Parvathy Nair, Vaibhav Simikeri","Generated custom marketing messages tailored to individual customers based on the customer data such as name, age ,income ,hobbies ,preferences and specific offers provided by the bank. These messages are dynamically crafted to resonate with each recipient, increasing engagement and integrated with Twilio's messaging platform to deliver these messages via SMS.",1,sms_gen_excel.py,git,https://github.ibm.com/Gopagoni-Jyothika/Marketing_message_generation.git,,0,0,0,0,0,1715843684454,1715843684454,211,721c0ff8-a7a5-4a5e-a46b-5fcc86579366,,,1,watsonx.ai,python
ldkvmxkpde,multithreaded_webscraping,Shilpa Hegde,"This code will perform web scraping of the html links present in the sitemap .xml file provided using multithreading approach and will create separate folders for each thread. For each thread it will create 2 text files, one with all the html links that have been scraped and the other one with the actual text content of 
those webpages based on the depth specified.Please note that this needs to be downloaded to be run.",1,multithreaded_webscraping.py,git,https://github.ibm.com/Shilpa-Hegde2/Multithreaded_webscraping.git,,1,0,0,0,0,1715849375844,1715849375844,223,1d4aa668-df2f-4127-b445-03d28fbe747e,,,4,Data Generation,python
eahffujlgh,Word by word document comparison,Piyush Aneja,"In scenarios where a meticulous comparison of two documents, word by word, is necessary, this asset proves invaluable. By inputting the text of two documents, this tool efficiently identifies disparities, including missing or additional text, while also pinpointing the precise word indices of discrepancies. Such functionality streamlines the process, ensuring comprehensive and accurate analysis.",1,eahffujlgh.py,local,,,0,0,0,0,0,1715851085862,1715858784669,226,49b6478c-9f13-47fe-84a4-dfd9ef6ba146,,,13,Use-case,python
abutbxcewh,Generate Temporary Pre-Signed URL,Nagaraju Kuruva,"Generate Pre singed url(temporary) for accessing documents/files which are uploaded in COS bucket.

Steps to execute the code (export for execution): 
1) Download the zip file and extract and import into visual studio(you can use other tool which supports python).
2) Create virtual environment for installing all dependencies.
    i) python3 -m venv env_name python3=3.11
    ii) source evn_name_location/bin/activate
   iii) pip3 install -r requirements.txt
3) Once environment setup is done then we can run below command to up the fast api server in your local.
     i) uvicorn PreSignedURLGenerator:app --reload 
4) Once above commands runs successfully then server will be up and you can go to browser and type below url lo check whether it is up or not.
 
http://localhost:8000/generate-url/?cos_access_key_id=""""&cos_secret_access_key=""""&cos_endpoint_url=""""&expiration=""""&key_name=""""&bucket_name=""""

Note : I have given empty string in sample url, you can replace empty string with actual values.
cos_access_key_id ---> COS access key id(you can find under service credentials of COS).
cos_secret_access_key ---> COS secret access key(you can find under service credentials of COS).
cos_endpoint_url --> COS bucket public end point url(you can find under bucket configuration section).
expiration --> how the your has to alive(it will be in seconds ex : 300 --> 5 mins)
key_name --> File/document name which your have uploaded in cos bucket(ex: test.pdf)
bucket_name --> COS bucket name.

--> if you want to jump into specific page number then add #page=page_number to generated pre singed url.
      Ex : presginedurl#page=3",1,PreSignedURLGenerator.py,local,,,0,0,0,0,0,1715854790262,1718203234718,427,1925ef83-e37c-4930-8b19-422e55ccdfe9,,,2,watsonx.data,python
orafonscof,PII detection Metric,Ramananjali Mounica Golkonda,This python code utilizes Watson NLP to detect PII in the input/output text provided. This is the same metric that is being used in watsonx.gov backend as well. This code can run in watson cloud notebooks.,1,orafonscof.py,local,,,0,0,0,0,0,1715855020138,1715855020138,55,d46ed019-2d10-4d15-805e-773bb612f210,,,12,Watson,python
afozhqjnaj,Selenium Project Discovery and Refactor Test Code,Pinkal Patel ; Piyush Saha,"In this project, Code analyzes the selenium test case java project as a whole folder and extracts the test file with its dependency. 
Input: Selenium Project
Output: Display table as test files with dependency and also stored into CSV file.",1,streamlit_UI_discovery_refactor.py,local,,,2,0,0,0,0,1715857564139,1715858941518,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,13,Use-case,python
sjmgoqmplh,Multi-Processing Call to WatsonX.AI,Pinkal Patel,"This code shows how to do multiple parallel calls to watsonx.ai as multiprocessing

.env file having the below content:
API_KEY=
IBM_CLOUD_URL=https://us-south.ml.cloud.ibm.com
PROJECT_ID=",1,multi_processing_watsonx_ai.py,local,,,1,0,0,0,0,1715860871932,1715860871932,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,1,watsonx.ai,python
rhlokkhuvd,RAG app using SingleStore,Ramananjali Mounica Golkonda,An easy to use and quick to run RAG application using SingleStore DB and langchain,1,RAG_using_SingleStore/4_SingleStore.py,git,https://github.ibm.com/mounica-golkonda/watsonx-reusable-assets.git,,0,0,0,0,0,1715861037974,1715861037974,55,d46ed019-2d10-4d15-805e-773bb612f210,,,13,Use-case,python
hdazuoxisb,QnA with Excel,Shivam Patel,"Perform question answering with an Excel or CSV file using Natural Language Query.

This solution uses SQL to query the tabular data in excel and provide natural language response.",1,hdazuoxisb.py,local,,,0,0,0,0,0,1715869911638,1718990110004,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,1,watsonx.ai,python
qmgarpwhml,SQL query generation and querying IBM DB2 ,Divya Jadon,"The code uses foundation model for generating SQL queries from natural language questions, queries uploaded data on IBM DB2 and produces results.",1,app_v6.py,git,https://github.ibm.com/Divya-Jadon/text_to_sql.git,README.md,1,0,0,0,0,1715871101472,1727804517827,490,d4c4614a-f103-4ea2-a6fe-bb8387475b43,,,1,watsonx.ai,python
exyjmagubr,Language Detector,Shivam Patel,"This is a flask app to detect language on the input text.

Route: {endpoint}/detect_language
Payload: {""text"": <input text>}",1,exyjmagubr.py,local,,,0,0,0,0,0,1715874966442,1715880039193,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,13,Use-case,python
wfakmyyxgf,Classification and Response Generation,"Janani S R, Amrita Rajput, Priti Mohapatra, Aravind Krishnan",Classification of reviews and automated Response Generation,1,src/app.py,local,,,0,0,0,0,0,1715913513210,1716215921176,225,39e0efcf-07a4-4a86-ae7d-6dd518fe938f,,,13,Use-case,python
lgykpbkfth,Highlighting words in pdf (traceability for entity-extraction),Piyush Aneja,"This asset demonstrates traceability for entity extraction (can be used for other use-cases as well), where words serve as entities. It highlights the entities in the input document for verification and traceability purposes.

Steps to use:
1)It needs to be exported for execution. 
2)Need to install pymupdf using  'pip3 install pymupdf' before running the python file.
3)Pass the path of your input directory, output directory and the filename.
4) Add the words that are to be highlighted in pdf in ""words_to_highlight"" variable
",1,lgykpbkfth.py,local,,,1,0,0,0,0,1715917121099,1715917121099,226,49b6478c-9f13-47fe-84a4-dfd9ef6ba146,,,13,Use-case,python
aehffxrkwh,Sample AssetHub Test ,Bharathi Chaudhury,Application to test asset hub,1,aehffxrkwh.py,local,,,0,0,0,0,0,1715928488745,1715928488745,477,393bd77f-9fb6-4448-a41b-4de228dfb0b9,,,1,watsonx.ai,python
rskaaltbgt,Call Center Transcript Summarizer,Anant Kumar,This asset demonstrates showcases watsonx's ability to clean and summarise transcript,1,https://github.ibm.com/Anant-Kumar3/OMRON_Pilot/blob/main/OMRON.py,git,https://github.ibm.com/Anant-Kumar3/OMRON_Pilot,,0,0,0,0,0,1715928685548,1715928685548,228,9576d2cd-8086-48e1-9478-7c0d6786790d,,,1,watsonx.ai,python
lcmbdniuho,VBA to Python,Tushar Tiwary,This asset demonstrate the conversion of VBA code to Python code using watsonx.ai and prompt engineering.,1,https://github.ibm.com/Tushar-Tiwary/Murata_VBA/blob/main/VBA-python.py,git,https://github.ibm.com/Tushar-Tiwary/Murata_VBA,,0,0,0,0,0,1715928750417,1715928750417,233,52f4dd94-8942-447a-806c-2d047692cdaa,,,1,watsonx.ai,python
pfdshnbvid,JD and HR Interview questions Generator ,Sohan M,"The proposed Job Description Structure emanates from IBM's analysis of GALP's current job description patterns based on the provided data. This entails a meticulous comparative study aligning with the industry benchmarks, augmented by the expert insights and recommendations of IBM's Talent Transformation specialists.",1,https://github.ibm.com/client-eng-northern-eu/GALP/blob/main/app.py,git,https://github.ibm.com/client-eng-northern-eu/GALP,,0,0,0,0,0,1715935684267,1715935684267,201,c9f23abb-24a2-49d9-8ee6-799a166850e1,,,1,watsonx.ai,python
efieppdtcx,Crawl Website Pages Excluding Hidden Elements with Selenium Library,Pinkal Patel,"Problem Statment: Problem Statement: While crawling a website page using Watson Discovery, all text is scraped, including hidden elements. This results in duplication and incorrect information being collected.
Solution: Crawl Page excluding hidden elements using Selenium Library.
Input: Webpage link
Output: credit_card_new.txt file having crawl data

Note: Run Below Code After Exporting on your local system because browser is not supported by AssestsHub for auto process.",1,efieppdtcx.py,local,,,1,0,0,0,0,1715941902047,1715945195666,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,13,Use-case,python
dfvwemsnwn,Selenium Script (Java) to Qualitia Artefact Conversion (JSON),Piyush Saha ; Pinkal Patel,"This assets is used to convert Selenium Scripts into Qualitia Artefacts (JSON files). 
Input: Selenium Object Files and Test Files
Output: Object and Testcase JSON files",1,streamlit_UI.py,local,,,0,0,0,0,0,1715942591083,1715943466989,229,c4f34492-373a-4899-a37c-4c73beeeb77f,,,13,Use-case,python
wcfdthaoao,Reactjs Application with Flask application to display local CSV data template,Rishabhjot Sandhu,"Reactjs Application with Flask application to display local CSV data and query endpoint for watsonx.ai. 
Contains two main endpoints:
/fetch_data --> To get the csv data from the application to display as a table. 
/query --> Simple API call to watsonx.ai that can be integrated with other functionalities for rag/ content generation etc. 
React application displays the csv data after fetching it from the api in a tabular format using carbon components. Also has an extra test page with routing. ",3,Frontend/src/App.js,git,https://github.ibm.com/Rishabhjot-Sandhu1/reactjs-flask-template,,0,0,0,0,0,1716152341486,1716152341486,134,81e811ce-823a-488f-82a3-95166e6fbd6e,,,13,Use-case,javascript
agvdiovupm,Generate OpenAPI Specs from a Postman Collection ,Rishabhjot Sandhu,"Generate OpenAPI Specs from a Postman Collection. This can be used for integration with wxO and wxA. 
You will need to create a collection (https://learning.postman.com/docs/getting-started/first-steps/creating-the-first-collection/). 
Your API key (https://learning.postman.com/docs/developer/postman-api/authentication/) and collection ID (https://global.discourse-cdn.com/getpostman/original/2X/9/92ec22ff0b369a63fd76f7efde4735fe5bf8570c.png).",1,agvdiovupm.py,local,,,0,0,0,0,0,1716172558490,1716172731374,134,81e811ce-823a-488f-82a3-95166e6fbd6e,,,13,Use-case,python
pyksehidsz,Comparison of Analyst Report With Financial Summary And Metrics,Pinkal Patel,"In this project, we can compare two analyst reports about one company and show a financial summary, pros, cons, and financial metrics. It is stored the document in ChromaDB
Input: Two Analyst reports Ex. BALM.pdf and Philips.pdf
Output: financial summary of two reports, pros, cons, and financial metrics",1,main.py,local,,,1,0,0,0,0,1716198059318,1716198059318,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,13,Use-case,python
hnebcrqacv,Custom Extension for Retrieving Source/File Name from Watson Discovery,Nagaraju Kuruva,"This custom extension help us to get the source/file name from Watson Discovery based on project id, collection id, document id.
We can integrate this extension with WatsonX assistance.

Note : I have added python Test file as it was not taking extension(json) file directly.",1,Test.py,local,,,0,0,0,0,0,1716199385303,1716199385303,427,1925ef83-e37c-4930-8b19-422e55ccdfe9,,,12,Watson,python
qkglkguovj,Watson nlp for classification,Pavan Purohit,we have used Watson-nlp for classifying the text into a different class,1,https://github.ibm.com/Client-Eng-EMEA-IN/dach-baystmuv-gewerbe/blob/main/code/final_review_watsonx_results.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/dach-baystmuv-gewerbe,,0,0,0,0,0,1716202031625,1716202031625,191,6fe87b2e-ea2c-4234-bfcf-7246fa25fa34,,,12,Watson,python
qlaqubgkcz,Itinerary generation using WatsonX.ai and Classical ML (Synthetic data),Sohan M,"The business objectives are to enable the service agent to
• Recommendation and Itinerary generation
• Customer-friendly assistant 
• Journey and Destination plans

Employing classical ML techniques to automate case classification
Leveraging generative AI for generating recommendations, enabling customers to create an interactive ecosystem




",1,,git,https://eu-de.git.cloud.ibm.com/clientengineering-lh/one-order-genai,,0,0,0,0,0,1716204597227,1716204597227,201,c9f23abb-24a2-49d9-8ee6-799a166850e1,,,13,Use-case,python
rggqpzpspt,Web Crawling using Selenium and BeautifulSoup,Shilpi Varshney,This asset is used to crawl the contents of multiple links stored in a text file and dump the extracted content to a json file.It also cleans the content having unicode data.,1,rggqpzpspt.py,local,,,0,0,0,0,0,1716208635089,1716208635089,181,456cfdc1-e400-4db8-9247-07f33244505d,,,13,Use-case,python
lycrpikbmp,RPA BluePrism Code generation using WatsonX.ai,Sohan M,"We have trained using a few shot prompting for the RPA Blue prism code generation using WatsonX.ai (StarCoder/Codellama).
Data is divided into multiple categories and then embedded using 'all-MiniLM-L12-v2', A similarity search is done on the query which maps to one of the categories and then passed to  Watsonx.ai to handle the code generation part.


",1,,git,https://github.ibm.com/Sohan-M1/Telefonica,,0,0,0,0,0,1716210899269,1716210899269,201,c9f23abb-24a2-49d9-8ee6-799a166850e1,,,1,watsonx.ai,python
cruzwpkcuh,Reranker ,Biren Patel,"Reranker that can be used for multiple purpose 
Ex.
1. in rag to rerank the retriever results
2. As a source attribution or to calculate source relevancy of llm output.
3. To find page numbers where llm output is present

Note: Please pass context as newline separated (\n) string",1,cruzwpkcuh.py,local,,,1,0,0,0,0,1716216655008,1716217814428,240,1bf377d6-d57f-49c3-ac96-b39862b4934d,,,13,Use-case,python
pportklpij,Semantic Comparison,Ravi Gopalakrishnan,"This semantic comparison functionalities will enable the developer to integrate the semantic comparison of given ground truth with inference obtained from models. Further, developer could utilise the highlight functionality to highlight the higher similar sentence present within given inference sentences. For using this asset you shall export it and then run it as Flask application.",1,semantic/src/flask_app.py,local,,,0,0,0,0,0,1716218698893,1716274717814,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,4,Data Generation,python
axcvqxbkcz,BAM LLM's Text Streaming,Charana H U,Streaming text code bloack for Large Language Models available in BAM,1,axcvqxbkcz.py,local,,,0,0,0,0,0,1716271683833,1716271683833,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
mlrfrfanto,cobol code documentation,Pavan Purohit,extracting the COBOL code and then documenting them using genai,1,,git,https://github.ibm.com/pavan-Purohit/cobol_poc,,0,0,0,0,0,1716271878433,1716271878433,191,6fe87b2e-ea2c-4234-bfcf-7246fa25fa34,,,1,watsonx.ai,python
qzobnayxlx,RAG Fusion using watsonx foundation models,Charana H U,"Comprehensive process to handle document processing, query generation, document retrieval, and question answering using the langchain package and a watsonx language model.",1,qzobnayxlx.py,local,,,0,0,0,0,0,1716273199454,1716273199454,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
qpedgqhtdj,Blogs Retriver Agent,Charana H U,Get the titles of blog posts relevant to specified keywords.,1,qpedgqhtdj.py,local,,,0,0,0,0,0,1716273487995,1716273487995,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
cbvtpdcbmd,Extracting Top Passages from Watson.Discovery and Watson.ai,Rahul Chavan,"The application utilizes documents which has  incident reports and precautionary measures. Users can upload data into Watsonx Discovery and search for specific incidents. Watsonx Discovery returns the most relevant incidents and precautions matching the user query. This information, along with the user query, is then sent to Watsonx.ai to fetch the top three precautions that the user needs to follow related to the incident. The application employs Watsonx Discovery and AI to create a RAG pipeline, where documents are uploaded to the discovery system, and the top passages, along with the user query.",1,app.py,git,https://github.ibm.com/client-engineering-japan/isuzu-backend.git,,0,0,0,0,0,1716280971778,1716280971778,234,8f06e80d-32d2-4114-958d-29bda13a953c,,,13,Use-case,python
bfltvjbnxc,Multi-Agent Using Autogen library with WatsonX.AI,Pinkal Patel,"Perform python code generation, testcase written, code reviewer, code documentation and code executor based on given problem statment. 
In this task, multiple agent is going to communicate with each other, verify task completion and report to admin.
In this usecase, I have used 7 Agents.
1. Admin: 
2. Planner: Who plan the whole tasks based on given problem statment.
3. Senior_Python_Engineer: 
4. Code_Executor: 
5. Code_Reviewer: 
6. Test_Cases_Writer: 
7. Code_Documentor: 

Step to Run:
Step 1: Run proxy_server.py  (command to run: python3 proxy_server.py --bearer_token {bam_apikey} --api_type bam --api_url https://bam-api.res.ibm.com/v2/text/generation)
Step 2: Run multi-agent.py

Note:
proxy_server.py file: Flask API to call Watsonx.AI Model. To use WatsonX.AI for llm model, one wrapper is written on top of this.
",1,multi-agent.py,local,,,1,0,0,0,0,1716283837336,1716284496893,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,13,Use-case,python
dkakkcnetw,Clickable PDF Source with page number for RAG use case,Shilpi Varshney,"This asset returns the clickable link of the source. This particular asset was used in a RAG use case with Milvus DB and Watson assistant. To get the source, first a similarity search  of answer is done with the  retrieved chunks. Whichever chunk has the highest similarity, we consider the source (stored in metadata) of that chunk. To make sure we have relevant source, we also provide the threshold score. The function ""get_source_link"" can be called through API to get the answer.",1,dkakkcnetw.py,local,,,0,0,0,0,0,1716314317012,1716314317012,181,456cfdc1-e400-4db8-9247-07f33244505d,,,13,Use-case,python
lldckajjpf,BGE Reranker using langchain,Shilpa Suresh,Program to demonstrate BGE reranker with langchain with a simple base bm25 retriever. The retriever can be modified according to needs (ES/Weaviate/Milvus). The program is ready to execute  with no inputs required.,1,lldckajjpf.py,local,,,1,0,0,0,0,1716386661905,1719491785737,117,313e8d03-91d1-4f32-98c0-394bcd9148ea,,,1,watsonx.ai,python
gjokjxofnz,Table Extraction and Summarization using unstructured.io,Shilpi Varshney,End-to-End RAG Pipeline with Unstructured.io ,1,gjokjxofnz.py,local,,,0,0,0,0,0,1716399758919,1716399758919,181,456cfdc1-e400-4db8-9247-07f33244505d,,,13,Use-case,python
ilmsfadycf,Folder Structure for Pilots,Akash Balakrishnan,This script maintains a folder structure for Pilots and creates a basic git ignore file and Readme file. This also has the provision to create a new virtual environment.,1,start.py,git,https://github.ibm.com/akashbalakrishnan/folder-structure,,0,0,0,0,0,1716441589643,1716441589643,460,f69a632d-878d-4709-9940-64b779e52373,,,13,Use-case,python
wfmzdbzcfs,Email Generation in different language,Akash Balakrishnan,This asset helps in creating different marketing email in different languages.,1,api/server.py,git,https://github.ibm.com/akashbalakrishnan/email-generation,,0,0,0,0,0,1716442503564,1716442503564,460,f69a632d-878d-4709-9940-64b779e52373,,,13,Use-case,python
kaytdeesrp,PDF Table Extraction,Soumya Agarwal,This python script will extract table data using unstructured library,1,kaytdeesrp.py,local,,,0,0,0,0,0,1716446251385,1716446251385,375,726c4d67-a696-48b7-8949-839f33dff9f7,,,13,Use-case,python
bcjhbafnzb,Table Extraction with Watson Discovery and NLQ on Tables with watsonx.ai,"Mula Ram Chamar, Prgya Gupta","This asset can be used for Table Extraction using Watson Discovery
And then answering questions based on those tables using Watson.ai",1,https://github.ibm.com/Client-Eng-EMEA-IN/Capability-Building-Wx-Discovery/blob/main/table_extraction/discovery_table_extraction.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Capability-Building-Wx-Discovery/tree/main/table_extraction,,0,0,0,0,0,1716448439250,1716448439250,245,6bbf5fdf-4dd8-44fe-9948-faf3e7232428,,,12,Watson,python
bosrrbstdn,Token Calculator,Akshay Patel,"This code can help you to calculate number tokens in input. You have to pass the project_id, url and api_key and the prompt. You can also specify model_id also.

Just run this command before running 
export IBM_API_KEY=api_key_here && export IBM_CLOUD_URL=cloud_url_here && export PROJECT_ID=project_id_here && ",1,bosrrbstdn.py,local,,,1,0,0,0,0,1716448651903,1716450791608,250,6b76acda-fb1f-4e5f-ac1f-82e0a3528332,,,1,watsonx.ai,python
qpghecahao,Image based PDF to text based PDF conversion,Mula Ram Chamar,"# This Asset contains code for
1. Converts all pages of pdf into images
2. Splits PDF into one page PDF documents or multipage pdf documents
3. Converts images to PDF
4. Covert image based PDF to text based PDF
",1,qpghecahao.py,local,,,0,0,0,0,0,1716448713405,1716448713405,245,6bbf5fdf-4dd8-44fe-9948-faf3e7232428,,,13,Use-case,python
cljeeycmng,Getting Started with Watson Document Understanding,Mula Ram Chamar,"Enterprise Business Documents are usually distributed in PDF/Word/Image formats for ease of document exchange, printing, human consumption and archival. While there have been significant advances in NLP/AI models for language understanding, applying these techniques over business documents faces a significant hurdle - the models work over text and not directly on PDF/Word/Image formats.

Document Conversion is the task of converting business documents into a ""rich-text"" format (JSON, HTML, etc.) for NLP/AI driven understanding of its contents. By retaining textual content and document structure such as sections and tables, document conversion standardizes business content into an intermediate format, opening up deeper understanding of the semantics for a variety of enterprise applications.

Watson Document Understanding is a standard embeddable library designed to be the primary delivery method for state-of-the-art document conversion in IBM products. It is an inner source library built on top of the best AI OSS enhanced with input from Research, Watson Discovery, Automation and GBS. Watson Document Understanding is a component of Watson Core, and it is developed under Watson Core’s inner source model.",1,,git,https://github.ibm.com/Mukesh-M2/getting-started-with-wdu,,0,0,0,0,0,1716449172764,1716449172764,245,6bbf5fdf-4dd8-44fe-9948-faf3e7232428,,,12,Watson,python
jrpffblcnm,Email Sending through Fast API,Soumya Agarwal,This python script will send email through SMTP by connection with Fast api.Here you can set your own format for mail body and also fill details for sender and recipient email.Through this you can also attach multiple attachments like PDF and JSON with mail.This script also help you to generate JSON factsheet.,1,jrpffblcnm.py,local,,,0,0,0,0,0,1716449906936,1716449906936,375,726c4d67-a696-48b7-8949-839f33dff9f7,,,13,Use-case,python
lxambpisrd,Video Highlight Extractor,Akshay Patel,"Video highlight extraction is the process of identifying and isolating key moments or segments from a longer video. This technique is commonly used in various fields such as sports, entertainment, and surveillance. Video highlight extraction enhances content consumption by providing viewers with quick access to the most engaging parts of a video, saving time and improving user experience. Upload you sample.mp4 in root directory and the script will load it automatically. 

Note:- This asset require ffmpeg and you need to pass below environment variables to run 
SERVICE_URL
API_KEY_S2T
IBM_CLOUD_API_KEY
IBM_CLOUD_URL
PROJECT_ID",1,run.py,git,https://github.ibm.com/client-engineering-japan/esports_video_highlights,,1,0,0,0,0,1716452964935,1716452964935,250,6b76acda-fb1f-4e5f-ac1f-82e0a3528332,,,13,Use-case,python
rlkqgrljkw,INCOSE Check for System Engineering Documents ,Aakriti Aggarwal,"INCOSE Checker Overview

What is INCOSE?
The International Council on Systems Engineering (INCOSE) is a global organization dedicated to advancing the field of systems engineering.

Why is the INCOSE check required and in which industry is it mainly used?
The INCOSE check ensures that need and requirement statements are clear, precise, and free from defects, which is essential for effective system lifecycle management. This check is crucial in industries like the automobile sector, where clear requirements help avoid costly rework and schedule delays.

How did we build the INCOSE checker?
We developed the INCOSE checker to cover all 42 rules dependent on Characteristics and Patterns by promptuning the Llama3 model using WatsonX AI. We used two columns—Unacceptable Statement and Acceptable Statement—to train the model, ensuring it can effectively validate need and requirement statements.",1,,git,https://github.ibm.com/aakriti-aggarwal13/INCOSE,,0,0,0,0,0,1716456684597,1716456684597,252,ad0909ac-79ab-4f83-b6e5-8a8d45268e31,,,13,Use-case,python
uplbbopkoe,Deploying a Python Function function using a Watson Machine Learning Deployment Space,Anshika Garg,"This asset is executable where you need to change python function only. Python function explore basic RAG implementation, and if you have backend file ready with you it would be easy to go for WML deployment. This asset contains step by step instruction and code instructions for deploying a python function using WML space.",1,https://github.ibm.com/Anshika-Garg/Deploy_Python_function/blob/main/query_llm().py,git,https://github.ibm.com/Anshika-Garg/Deploy_Python_function,,0,0,0,0,0,1716463432817,1716463432817,255,9cacecce-4c4b-4532-a11f-72b878926fe3,,,8,WML,python
fniewkovvb,Enhancing Search Efficiency:  Query Expansion,M T Geethanjaly,"This notebook gives you a hands-on for Query expansion that acts as a bridge between the user's intent and the relevant information by automatically expanding the query with semantically related terms, increasing the likelihood of retrieving documents.",1,fniewkovvb.py,local,,,0,0,0,0,0,1716469600891,1716469600891,237,8a3aadc9-fcd5-484c-aa92-00e047560c7d,,,1,watsonx.ai,python
fdwtsuurgv,LLM as a Judge - Custom Metric,Vishwajith C R,LLM as a Judge Custom metric used to Judge a RAG use case & evaluates the context used for the model and provides a score and reasoning for the score.,1,llm-judge/main.py,git,https://github.ibm.com/Client-Engineering-INDIA/HSBC.gov.git,,0,0,0,0,0,1716472491877,1716472491877,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,3,watsonx.governance,python
logpvagldr,Sentinel-2 Time Series ,Bharathi Chaudhury,"This code helps you with automated data from sentinel hub for the given time series data implemented for Geo spatial, for any location given the latitude and longitude coordinates for any given time series. It also preprocess the data and converts to the tiff file. ",1,logpvagldr.py,local,,,0,0,0,0,0,1716523328795,1716523328795,477,393bd77f-9fb6-4448-a41b-4de228dfb0b9,,,13,Use-case,python
dzarodxbra,Candidate Summary and Job Description Summary Using WatsonX.ai,Bharathi Chaudhury,This assets contains the fine-tuned prompt to extract candidate summary and job description summary from a given resume and job description in a json format. The code is implemented for Skill Radar project.,1,skillradar_asset/main.py,local,,,0,0,0,0,0,1716525544995,1716525544995,477,393bd77f-9fb6-4448-a41b-4de228dfb0b9,,,1,watsonx.ai,python
ujnrpeoeou,Gradio for Display and Analytics of Geospatial Type Data,Kanishka Reddy,Gradio for Display and Analytics of Geospatial Type Data,1,ujnrpeoeou.py,local,,,0,0,0,0,0,1716533637286,1716533637286,253,b96aeb4e-f407-437b-a925-438f7c533ed0,,,13,Use-case,python
gajvprvfxi,Get Asset Info from WKC,Gayathri E S,This Python script retrieves asset information from Watson Knowledge Catalog (WKC). The assets are sourced from files stored in IBM Cloud Storage through established connections. The credentials are given in the config.py file.,1,WKC/get_files.py,local,,,0,0,0,0,0,1716536061187,1717051482058,485,90efaf12-6a7d-4e37-84d7-cdb5e3c2faed,,,9,WKC,python
ngrdrakcvq,token counter,Aniket Mohan,"this script creates an api endpoint for token counting, you have to provide model id which you want to use from HuggingFace, your hf token and the text you want to tokenise",1,ngrdrakcvq.py,local,,,0,0,0,0,0,1716538580465,1716538580465,242,88e03bea-c65d-4ee7-9078-a9f0bf75fe96,,,1,watsonx.ai,python
ltbcigjtyt,Slack Conversation History Fetcher,Apeksha Choudhary,"This Python script interacts with the Slack API to fetch conversation history from a designated channel. Using the Slack SDK library, it authenticates via a provided token and retrieves the conversation records.




",1,ltbcigjtyt.py,local,,,0,0,0,0,0,1716539976283,1718115860473,137,29b8240c-4525-44f3-9def-f95361c81204,,,13,Use-case,python
nnvczkpmxb,File Info Extractor,Kanishk Saxena,"The FileInfoExtractor class is designed to extract information from various types of files, specifically DOCX and PPTX formats. This class provides methods to read the content of these files and return the extracted data in a structured format.

",1,nnvczkpmxb.py,local,,,0,0,0,0,0,1716546488052,1717142363572,249,1a7a7293-a439-416f-bc03-5a76ad9bf2f2,,,13,Use-case,python
accsmqfhjq,IBM COS Toolbox,Gautam Chutani,"A Python script for performing various operations on IBM Cloud Object Storage. The following operations have been added:

1. Retrieve an object from COS
2. Download a file from COS into local storage
3. List all objects in the bucket
4. Use the COS client to upload a file-like object to the specified bucket
5. Check if a filename exists in COS or not
6. Make a PUT request
7. Generate a temporary url for an object to embed into application

To run this application:

1. Provide your credentials as Input.
2. Create the object of COS Client and then call the desired method.",1,accsmqfhjq.py,local,,,0,0,0,0,0,1716576134102,1716576134102,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,2,watsonx.data,python
oprdktlckj,Speech Translation (STT+NMT+TTS),"Gautam Chutani , Aswini Yeddula","This code snippet involves automatic conversion of an English video into Spanish video using IBM Speech-to-Text (STT) model followed by Neural Machine Translation (NMT) with watsonx.ai LLM followed by IBM Text-to-Speech (TTS) model. As part of the demo, I have uploaded one MP4 file on Google Drive, which is downloaded using wget command and then speech translation happens. You can change the input and output language based on availability of models in IBM STT and TTS service.",1,oprdktlckj.py,local,,,0,0,0,0,0,1716581571026,1716892991913,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
gvujdkater,"Using ""Logprobs"" as LLM Confidence ",Gautam Chutani,"This code snippet demonstrates how we can make use of log probabilities (or logprobs parameter) in LLM API response for understanding the confidence level of generated text.
It includes code for both BAM and WatsonX.ai GA. 
Additionally, one can also get the input and output token count using this code.",1,gvujdkater.py,local,,,0,0,0,0,0,1716623575006,1716632471612,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
mvrgvdtnbm,Sentiment and Tone Analysis using IBM NLU,Gautam Chutani,"This code snippet performs sentiment analysis (positive, neutral or negative) and tone analysis (sad, frustrated, satisfied, excited, polite, impolite, and sympathetic) for a given text using pre-built classifications model in IBM Natural Language Understanding service. For list of languages supported, you can refer to documentation: https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-getting-started ",1,mvrgvdtnbm.py,local,,,0,0,0,0,0,1716630976175,1716630976175,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,12,Watson,python
hmluhcvwbg,RAG Evaluation using RAGAS and wx.ai,Gautam Chutani,This code snippet utilises the RAG triad of metrics for evaluating the RAG pipelines using RAGAS framework integrated with WatsonX.ai LLMs.,1,hmluhcvwbg.py,local,,,0,0,0,0,0,1716636468565,1716636468565,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
obdjytzvrs,Custom Office Add-in’s/plugin to create a custom GenAI solution using WatsonX,AKASH TOMER,Custom Office[Excel/Outlook/Word etc] Add-in’s/plugin to create a custom GenAI solution using WatsonX. ,1,__MACOSX/taskpane_files/._app.py,local,,,0,0,0,0,0,1716636969102,1716636969102,241,75a27976-7656-4183-b7d6-62ca2e5100ae,,,13,Use-case,python
nehtqhieem,FineTuning a large language model locally using InstructLab,AKASH TOMER,"InstructLab provides a command-line interface (CLI) that allows users to fine-tune pre-trained 
language models (LLMs) locally. ",4,Instructlab_fineTuning/ilab_setup.sh,local,,,0,0,0,0,0,1716646347297,1716646347297,241,75a27976-7656-4183-b7d6-62ca2e5100ae,,,13,Use-case,bash
avalkejazo,Asynchronous Information Retrieval,Kanishk Saxena,This asset can help when you have to parallely process between different vector embeddings to fetch stored embeddings in different db's along with caching capabilities when fetching a response from LLM,1,main.py,git,https://github.ibm.com/kanishk-saxena/kanishk-saxena-watsonx-rag-chromadb-mod.git,,0,0,0,0,0,1716660727823,1716660727823,249,1a7a7293-a439-416f-bc03-5a76ad9bf2f2,,,1,watsonx.ai,python
oydngiwkto,Speech Recognition with Speaker Diarization ,Gautam Chutani,This code snippet performs Automatic Speech Recognition using open-source Whisper model along with Speaker Diarization using pyannote library. Tune the parameters for optimal results. It also generates VTT and SRT files for captioning task.,1,oydngiwkto.py,local,,,0,0,0,0,0,1716664980049,1716669430534,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,13,Use-case,python
fqjsttsifj,RAG Fusion,Mahesh Prasad Mishra,"This project, named RAG Fusion, utilizes the Retrieval-Augmented Generation (RAG) approach for information retrieval. It leverages the strengths of Web-crawler, ChromaDB, Watson Discovery, and a Large Language Model (LLM) for comprehensive and relevant search results.
",1,RAG_Fusion/app.py,git,https://github.ibm.com/Mahesh-Prasad-Mishra/RAG_Fusion,,0,0,0,0,0,1716693138836,1716693138836,197,4acf9661-5a1a-4f86-8aec-c3686769cff8,,,13,Use-case,python
bykiqsxatq,Prompt Tuning via Python SDK,Gautam Chutani,The code snippet performs tuning of foundation model using the PEFT technique of Multi Task Prompt Tuning which is implemented in Tuning Studio of WatsonX.ai. Here we will use the Python SDK to tune flan-t5 model on summarization task using open-source dataset.,1,bykiqsxatq.py,local,,,0,0,0,0,0,1716722348374,1716722348374,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
iwuesvlxke,Ingestion & Extraction of data from watsonx.data (presto) to s3 filepath ,"Sriparna Banerjee, Raveena Khan",In this used case we are ingesting and extractiong the data from watsonx.data using presto and s3 filepath. One is using API and other is utilising AMAZON S3 filepath,1,iwuesvlxke.py,local,,,0,0,0,0,0,1716781031368,1717058727242,177,eeb64982-6e57-4789-8522-725436a3323b,,,2,watsonx.data,python
nxfurelhrq,Sentiment Score Analysis Using Natural Language Understanding,Kalpataru Dhakate ; Akshat Mahajan,"It provides real-time sentiment analysis of textual data using natural language understanding (NLU) techniques. Users can input text or upload documents to receive sentiment scores and detailed emotional insights, ideal for analyzing customer feedback, social media posts, and survey responses.",1,nxfurelhrq.py,local,,,0,0,0,0,0,1716793147823,1716793147823,214,da67d184-7606-44d0-a2f4-27f8ae7ca889,,,13,Use-case,python
wcdpmlpius,External model gov and Custom metrics,Deepak Nayak,This repo contains the notebook for governing external model and also deploying custom metrics functions to WML instance.,1,https://github.ibm.com/Deepak-Nayak2/watsonx_gov/blob/main/watsonx_gov.py,git,https://github.ibm.com/Deepak-Nayak2/watsonx_gov,,1,0,0,0,0,1716809552184,1716809552184,130,0cd3f594-4309-4acf-a8da-223923e96b30,,,3,watsonx.governance,python
hdhurvqmzm,Milvus with PyPDF,Sourabh Jha,"Features :
1. Extraction of data using pypdf
2. Updating data in milvus
3. Avoids of duplicate files by file name ",1,,git,https://github.ibm.com/Sourabh-Kumar10/Milvus-with-PyPDF.git,,1,0,0,0,0,1716813000262,1716813000262,195,de5b5281-49fd-4f69-ae84-97d9c688e187,,,2,watsonx.data,python
btmqwrsntq,Data Extraction with Deep Search,Sourabh Jha,"Features : 
1. Extracts text
2. Extracts tables
3. Update to Milvus
",1,,git,https://github.ibm.com/Sourabh-Kumar10/Data-Extraction-with-DeepSearch.git,,0,0,0,0,0,1716813133375,1716813133375,195,de5b5281-49fd-4f69-ae84-97d9c688e187,,,2,watsonx.data,python
tcawndbniu,Extract text without strikethrough from PDF's,Satprem Rath,"In PDF files, strikethrough text is typically represented by a line through the middle of the text. However, detecting this purely from text properties isn't straightforward. This Asset will help us to identify and filter out strikethrough texts so that we can get meaningful content for our RAG applications.",1,tcawndbniu.py,local,,,0,0,0,0,0,1716814214132,1716814214132,202,7f94c55e-62dd-48d2-9772-66505360580e,,,13,Use-case,python
mlairrvcja,Predication of Binary classification ,Sri Sai Swaroop Kaza,"Generic way for predicting binary classification using classical ML models like Random forest, SVM, Logistic regression, xgboost",1,https://github.ibm.com/Sri-Sai-Swaroop-Kaza/predict_binary_classification/blob/main/app.py,git,https://github.ibm.com/Sri-Sai-Swaroop-Kaza/predict_binary_classification,,0,0,0,0,0,1716824464837,1716824464837,98,75d3d3d8-55a6-478c-9d00-bb11c1f6a3ca,,,8,WML,python
jdubkpwtxu,Query from MilvusDB and Watson Discovery,Vikas Mani,The following Github code assist you with building an advanced RAG. It takes top_K context from Watson Discovery and Milvus DB and rerank them to increase the context precision for more accurate answers. Kindly read readme.md file for the step wise execution.,1,https://github.ibm.com/Vikas-Mani2/MilvusDB-with-Watson-Discovery/blob/main/app.py,git,https://github.ibm.com/Vikas-Mani2/MilvusDB-with-Watson-Discovery.git,,0,0,0,0,0,1716873012837,1716873012837,426,6f746bd8-8cce-45fe-80cc-421dee6e037d,,,2,watsonx.data,python
rrvzigkmfo,Text to Speech Conversion,Pinkal Patel,"This asset converts text to speech and saves it into a wav file. 

Environment:
wat_tts_key: # API KEY for Text to Speech Instance
wat_tts_url: # URL for text to Speech Instance
",1,rrvzigkmfo.py,local,,,1,0,0,0,0,1716880531200,1716895006726,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,12,Watson,python
odowdrqhdv,Japanese language detector,Phani Chodavarapu,"In a paragraph of length around [0:2500], this function can detect if the input paragraph consists Japanese. If the paragraph is not ocmpletely in Japanese , end to end, then using LLM , we can translate the paragraph to Japanese.  ",1,odowdrqhdv.py,local,,,0,0,0,0,0,1716887316362,1717135548956,257,37589b14-4ddb-45a5-9218-2cac3a4cd657,,,1,watsonx.ai,python
jevjbatntd,Text Summarizer,Ganesh Jathar,"Text Summarizer is a Gradio-powered application that allows users to input text and receive concise summaries, enhancing productivity and comprehension effortlessly.",1,jevjbatntd.py,local,,,0,0,0,0,0,1716888032306,1717483909990,260,c8f8103d-63cd-424f-be2d-ec66dee328c9,,,1,watsonx.ai,python
uvocjyqkzc,Text to SQL - Invoice QnA,Aman Sharma,"This asset, converts natural language to SQL queries for an invoice dataset. The dataset is represented by the following columns (Description and Column name):
Name of the article sold: ARTICLE_NAME
Amount at which article was bought: COST_INCURRED 
Amount at which article was sold: PRICE_SOLD
Date article was sold: DATE_SOLD 
City where sold: CITY 
Customer Name sold to: CUSTOMER_NAME

Using CodeLlama generative AI LLM, the natural text question asked by a user will be converted to an SQL query which can be used to fetch relevant data/information from a backend database with the above mentioned schema structure.",1,uvocjyqkzc.py,local,,,0,0,0,0,0,1716972295273,1716981153030,265,288f3b91-d244-4c03-8960-1ac292040633,,,1,watsonx.ai,python
aakbirjgjw,PDF data to tabular data,Diksha Chandra,This code extracts text from pdf using PyPdf and converts it into tabular format chapter wise on sub sub section level of the data.,1,aakbirjgjw.py,local,,,0,0,0,0,0,1716976552511,1716976617764,476,fb738b91-a711-4b7c-a2eb-cfb2ae56258b,,,13,Use-case,python
wgakvldqfb,LLM With Google Search API Demo,Durgesh Chalvadi,"This project combines IBM Watson's large language model (LLM) capabilities with Google Search results to provide comprehensive responses. The application is built using Streamlit, making it easy to deploy and use in a web interface.
",1,__MACOSX/LLM_WITH_GOOGLE_SEARCH_API/._app.py,local,,,0,0,0,0,0,1717046814110,1717046814110,478,96abcd86-1a69-4656-b4ab-4b3b17ad5fbd,,,1,watsonx.ai,python
wejencpfbl,CLI tool to get data from ICOS and analysis,RAKESH LINGUBARI,It is used to Extract the Logs of the application which is stored in ICOS and do analysis,3,wejencpfbl.js,local,,,0,0,0,0,0,1717066732765,1719730581578,447,725fb9bd-ba84-4e92-a9b2-b7e716ecd52c,,,13,Use-case,javascript
rxyzblwcdr,inactivity and refresh check in gradio,Phani Chodavarapu,"when a gradio page is refreshed, it catches it and gives the notification of refresh action. when the UI is inactive , the asset catches it and gives the notification of inactivity. we can extend it for doing other actions like , if the user is inactive then logout the user or any other action can be assigned. Please note that UI in the asset is only front end, their is no backend code.This code do not use gradio session manager.",1,rxyzblwcdr.py,local,,,0,0,0,0,0,1717068099167,1717147500919,257,37589b14-4ddb-45a5-9218-2cac3a4cd657,,,13,Use-case,python
oaqsndxqdx,Sentiment Analysis Streamlit,Rakhi Sharma,"This project is an interactive web application for sentiment analysis of customer conversation summaries using Streamlit and IBM Watson's AI capabilities. Users can input summaries and receive real-time sentiment categorization as either ""positive"" or ""negative.""",1,oaqsndxqdx.py,local,,,1,0,0,0,0,1717132780404,1717132780404,392,c77015c9-755d-4acf-b6e2-66a13a764c83,,,1,watsonx.ai,python
ddhscaeuug,informatica_xml_to_sql_conversion,Richa Chander,This is used to convert xml data pipeline files to sql file. This asset can be used for xml to sql code conversion,1,ddhscaeuug.py,local,,,0,0,0,0,0,1717135430698,1717166960001,76,e1fe551a-6384-410b-a1d9-17aee8274b5c,,,1,watsonx.ai,python
eajqakwsgy,Java code generation ,Anusha Garlapati,"This asset demonstrates Java code generation using user specifications like class name, function name, return type etc.",1,Java/code_gen_UI.py,git,https://github.ibm.com/Anusha-Garlapati/ts-codegen-main,,0,0,0,0,0,1717135528751,1717135528751,170,cd11b7c0-2e26-49cd-ae65-bb9ea0370fcf,,,1,watsonx.ai,python
rtttrnqumf,"Multi-Agent: Code Generation, Review, Execution, Test Case And Documentation",Pinkal Patel,"This Assest is describing usecase for code genration for complex problem using multi-agent with custome selection techinque and also collect final answer for user.
In this usecase, I have used 8 Agents.
Admin, Planner, Senior_Python_Engineer, Code_Executor, Code_Reviewer, Test_Cases_Writer, Code_Documentor, Society of Mind

Main Adavantage: Custome Agent Selection Technique and final answer collection

Step to Run:
Step 1: Run proxy_server.py  (command to run: python3 proxy_server.py --bearer_token {bam_apikey} --api_type bam --api_url https://bam-api.res.ibm.com/v2/text/generation)
Step 2: Run multi-agent.py

Note:
proxy_server.py file: Flask API to call Watsonx.AI Model. To use WatsonX.AI for llm model, one wrapper is written on top of this.

Library:
pip install pyautogen;
pip install flask",1,multi-agent.py,local,,,2,0,0,0,0,1717150336562,1717151058074,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,1,watsonx.ai,python
xttszkftjy,XML to SQL generation v1,Mohammed Ali Shaik,This is an streamlit app which needs required environmental variables related to watsonx and an xml file which has ETL for informatica as input to run the app.,4,bash.sh,local,,,0,0,0,0,0,1717150451859,1717150451859,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,bash
fjilppthkr,XML to SQL generation v2,Mohammed Ali Shaik,This is an streamlit app which needs required environmental variables related to watsonx and an xml file which has ETL for informatica as input to run the app.,4,bash.sh,local,,,0,0,0,0,0,1717158828401,1717158828401,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,bash
lovsxqnzpt,Implementing RAG with ChromaDB and IBM Watson for PDF Document QA,Prgya Gupta,This Python code demonstrates a pipeline for creating a Retrieval-Augmented Generation (RAG) system utilizing ChromaDB and IBM Watson Machine Learning (Watsonx.ai) to perform question answering (QA) on PDF documents.,1,lovsxqnzpt.py,local,,,0,0,0,0,0,1717171936280,1717171936280,263,fc6c8ada-87d2-40e4-8025-90a6c58389d4,,,1,watsonx.ai,python
sdofsmpenw,CP4D on PREM Installation,Aniket Mohan,This contains documentation to install CP4d and watsonx.gov on vpc cluster,4,,git,https://github.ibm.com/Client-Eng-EMEA-IN/CP4D-ON-PREM-INSTALLATION.git,,0,0,0,0,0,1717259110885,1717259110885,242,88e03bea-c65d-4ee7-9078-a9f0bf75fe96,,,5,CP4D,bash
acgvkobckk,test,Izzac Gonzalez,test,1,acgvkobckk.py,local,,,0,0,0,0,0,1717525428884,1717525428884,285,2a7acfc5-0bfa-48f9-a2ad-c2b84cd32026,,,7,FactSheet,python
jodihcbbet,test2,Izzac Gonzalez,test2,4,jodihcbbet.sh,local,,,0,0,0,0,0,1717526539280,1717526539280,285,2a7acfc5-0bfa-48f9-a2ad-c2b84cd32026,,,11,Data Stage,bash
tqygakoqbk,test3,Izzac Gonzalez,test3,1,tqygakoqbk.py,local,,,0,0,0,0,0,1717527352314,1717527352314,285,2a7acfc5-0bfa-48f9-a2ad-c2b84cd32026,,,6,Openshift,python
iwsgarpxki,Test4,Izzac Gonzalez,test4,1,iwsgarpxki.py,local,,,0,0,0,0,0,1717527565218,1717527565218,285,2a7acfc5-0bfa-48f9-a2ad-c2b84cd32026,,,6,Openshift,python
beuuloizss,test5,Izzac Gonzalez,test5,4,beuuloizss.sh,local,,,0,0,0,0,0,1717527972411,1717527972411,285,2a7acfc5-0bfa-48f9-a2ad-c2b84cd32026,,,6,Openshift,bash
qlqciyuksm,test5,Izzac Gonzalez,test5,4,qlqciyuksm.sh,local,,,0,0,0,0,0,1717528293402,1717528293402,285,2a7acfc5-0bfa-48f9-a2ad-c2b84cd32026,,,6,Openshift,bash
wujpccsmfn,Preprocessing of Sentinel-2 Geo spatial Prithvi Crop Classification Data,Arya Sukumar,This asset helps user to pre-process the extracted Sentinel-2 data for using as input to Geo Spatial Prithvi Crop Classification model. Three time steps data downloaded will be required as input and it will give one data of size 224x224x16. This can be used for the inference task of Prithvi Geo Spatial Crop Classification task.,1,src/Preprocess_Sentinel2ToPrithviCrop.py,git,https://github.com/Aryaibm/Sentinel2toGeoSpatialPrithvi,,0,0,0,0,0,1717568056108,1717648345000,247,e71332b1-4c46-42f3-81b4-894bf2b64143,,,13,Use-case,python
qsbkiqlejy,XML to SQL generation v3,Mohammed Ali Shaik,This is an streamlit app which needs required environmental variables related to watsonx and an xml file which has ETL for informatica as input to run the app.,4,bash.sh,local,,,0,0,0,0,0,1717577885139,1717577885139,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,bash
ckrevbsmrs,XML to SQL generation v4,Mohammed Ali Shaik,This is an streamlit app which needs required environmental variables related to watsonx and an xml file which has ETL for informatica as input to run the app.,4,bash.sh,local,,,0,0,0,0,0,1717581690288,1717581690288,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,bash
pbzadifjuu,XML to SQL generation v5,Mohammed Ali Shaik,This is an streamlit app which needs required environmental variables related to watsonx and an xml file which has ETL for informatica as input to run the app.,4,bash.sh,local,,,0,0,0,0,0,1717582300696,1717582842910,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,bash
ovwdorxpoy,Convert .m4a or .mp3 file  to .wav file,"Akshat Mahajan, Kalpataru Dhakate",This code will convert your audio file with .m4a or .mp3 extension to .wav audio file. ,1,ovwdorxpoy.py,local,,,0,0,0,0,0,1717664980880,1717664980880,290,759f0946-5866-442a-b2d9-9ccdf50c47e1,,,13,Use-case,python
pxvfsjibla,Generate transcript from audio file using watson speech to text.,"Akshat Mahajan, Kalpataru Dhakate","Given a audio file in .wav format convert it into a text transcript using watson speech to text. The code uses latest 'en-US_Telephony_LSM' speech model. 
The api response we get encrypts all the personal information using redaction parameter. ",1,pxvfsjibla.py,local,,,0,0,0,0,0,1717665690791,1717665690791,290,759f0946-5866-442a-b2d9-9ccdf50c47e1,,,13,Use-case,python
yiwdujwstj,Extract Speaker labels and Timestamps for each sentence in a transcript extracted from Watson Speech to text,"Akshat Mahajan, Kalpataru Dhakate",The code helps to extract speaker labels from the api response we get from watson speech to text. It also extracts the timestamps for each speaker during the conversation.,1,yiwdujwstj.py,local,,,1,0,0,0,0,1717665906928,1717665906928,290,759f0946-5866-442a-b2d9-9ccdf50c47e1,,,13,Use-case,python
dktxlfycvw,Useful output parser from LangChain,Girijesh Prasad,CSV and List output parser example for Watsonx LLM ,1,dktxlfycvw.py,local,,,0,0,0,0,0,1717939367033,1718008112868,293,8ef9f040-48f8-4b47-97cd-fa3936913510,,,1,watsonx.ai,python
lfkcnftrcd,Langchain Integration to WatsonX.ai,Dharmendra Sahani,"LangChain is an open-source development framework created to streamline the process of building applications with large language models (LLMs).

The fundamental concept of the library is the ability to ""chain"" together different components to develop more sophisticated use cases around LLMs. Here are the key components of LangChain:

Model: Interacts with various large language models.
Prompts: The text sent to the LLMs for processing.
Chains: Allow the combination of different LLM calls and actions automatically.
Embeddings and Vector Stores: Break large datasets into manageable chunks and store them for efficient querying when needed.
Agents: Enable the LLMs to dynamically choose the best tools to use in response to a given query.",1,lfkcnftrcd.py,local,,,0,0,0,0,0,1718001044378,1718001044378,190,2f6789f0-db3b-450a-9fd1-75c61c6d4453,,,1,watsonx.ai,python
rhhwqlrrlc,Summarization UI Boilerplate code,Prasath K,This is UI Boilerplate code for summarization,3,./hokoku-frontend/index.js,git,https://github.ibm.com/client-engineering-japan/Hokokku-Bank.git,,0,0,0,0,0,1718082275065,1718082275065,481,32135552-e1a9-4abe-bd01-3b27a8bcb6bd,,,13,Use-case,javascript
diovifptqs,Hybrid search using milvus,Amith Hooli,This demonstrate a simple use case of conducting a hybrid search with help of a notebook,1,,git,https://github.ibm.com/Amith-Hooli/Milvus_hybrid_search.git,,0,0,0,0,0,1718086912271,1718086912271,418,0f1faf20-300d-44ee-b5cb-593366a9d970,,,13,Use-case,python
pqlfmxfwlb,Extract Image and text from pdf,Mehul Joshi,"This code help us to extract the image , text and store that image to the dedicated path properly.",1,pqlfmxfwlb.py,local,,,0,0,0,0,0,1718096544879,1718097963848,186,e292202d-0d99-4ab1-82bc-34d06516f804,,,1,watsonx.ai,python
cybplqkpts,US stock market chatbot,"Niranjan Khedkar, Pavan Shiraguppi","A Stock Market Chatbot for the US Market leverages yfinance to extract and provide real-time stock data. It delivers up-to-the-minute market quotes, trends, and financial news, offering users quick and accurate information for informed decision-making. Simple and efficient, this chatbot ensures users have immediate access to essential stock market data around the clock.",1,cybplqkpts.py,local,,,0,0,0,0,0,1718096577262,1718097800025,172,e20a1777-4dec-4dad-815c-33eecb1360e8,,,13,Use-case,python
fcovkhdbrp,Finetune Models with custom dataset,"Pavan Shiraguppi, Akshay Patel, Anant Kumar, Tushar Tiwary",A server that finetunes LLMs with custom dataset and can be used to deploy to BYOM watsonx.ai,1,app/src/train_web.py,git,https://github.ibm.com/client-engineering-japan/toyota_codegen_phase3/tree/main/x86_64,,0,1,0,0,0,1718111513035,1718111513035,296,cec77fe4-751a-4d5e-8d07-9da70ec31363,,,13,Use-case,python
vzbugbmjhr,Text extraction of email files with .msg extension along with the attachments,Manjusha Tomar,"It will extract the text from the msg file along with the attachments using easyocr and will provide the resulted data in json format.
Note:Text extracted from attachments are added at the same place where the image is so the context is not affected.",1,msgtotxtupdated.py,git,https://github.com/ShallyManjusha/msgtojson,,0,0,0,0,0,1718112554831,1720484290102,354,af7b003b-00aa-480e-8de5-b31a829038eb,,,13,Use-case,python
nyoduyvacl,ImageTextEntityExtractor,Sourav Das,Here the use case is to extract text and identify the entities from text which is in image form and from screenshots. The .py file mentioned is used to extract text from the images and the .ipynb file consists the entity extraction part.,1,text_extraction.py,git,https://github.ibm.com/Sourav-Das16/ImageTextEntityExtractor.git,,0,0,0,0,0,1718113547502,1718113547502,421,c01e5096-146e-4756-abe3-aaf221081c21,,,13,Use-case,python
qnfqiksslb,Text extraction of .xps extension file.,Manjusha Tomar,.xps file is converted into an image and text is extracted from it using easyocr and then extracted text along with the filename will be provided a json output,1,xpstojson.py,git,https://github.com/ShallyManjusha/xpstojson,,0,0,0,0,0,1718129423044,1720484329689,354,af7b003b-00aa-480e-8de5-b31a829038eb,,,13,Use-case,python
naartjfgsv,Data Cleaning via LLM ,"Kanishk Saxena, Girijesh Prasad","This assets help when you have too many rows with uncleaned data. It takes in your uncleaned csv sends the data row wise to llm and llm fetches the core gist from it. 
Example: You have a question answer dataset and it is basically a transcript between user and customer care agent so it will contain unnecessary information like 'Thank you for calling', 'Let me redirect', 'Terminal Contact Nos.' which are not needed as they will reduce the accuracy.",1,naartjfgsv.py,local,,,0,0,0,0,0,1718181533636,1720010536920,249,1a7a7293-a439-416f-bc03-5a76ad9bf2f2,,,1,watsonx.ai,python
hogloidjtr,Large PDF (>100 MB) Summarization With Watsonx.AI,Pinkal Patel,"This Assest is summarization of large pdf using Watsonx.AI with controlled parallel call.

Library:
pip install ibm_watson_machine_learning==1.0.357;
pip install python-dotenv==1.0.0;
pip install langchain==0.2.1;
pip install ibm-watson==7.0.1;",1,large_pdf_summarization_with_wxai.py,local,,,0,0,0,0,0,1718188870724,1718188870724,75,7385f3d6-e16e-46b1-8d6f-db731c6f5e19,,,1,watsonx.ai,python
uxszqpbfdp,Minio Read Write,Munendra Singh,"This asset facilitates seamless reading and writing of files to and from a Minio object storage server, leveraging the Minio Python SDK for efficient data operations.",1,uxszqpbfdp.py,local,,,0,0,0,0,0,1718200417026,1718200417026,297,bf018fd4-17ff-4291-8c83-8dd155d8bcec,,,2,watsonx.data,python
uicchhfnrr,Utilising FAST API for DB2: Seamless Read and Update Operations,Nagaraju Kuruva,"Steps to Execute the Code:

1. Download and Extract:
   - Download the zip file, extract it, and import it into Visual Studio (or any other tool that supports Python).

2. Set Up Virtual Environment:
   - Create a virtual environment to install all dependencies:
     - `python3 -m venv env_name` (with Python 3.12)
     - `source env_name_location/bin/activate`
     - `pip3 install -r requirements.txt`
       - Note: Direct installation of `ibm-db` library on MAC ARM 64 machines is complex. It's easier to set this up on a Linux machine.

3. Start the FastAPI Server:
   - After setting up the environment, use the following command to start the FastAPI server on a Linux machine, or create a Docker image and deploy it using Podman or Docker Hub:
     - `uvicorn test_db2_connection:app --host 0.0.0.0 --port 8080`
       - Note: Port 8000 is usually blocked on Linux, so use port 8080 instead.

4. Verify Server is Running:
   - Once the server is running, open your browser and check the following URLs to ensure it is operational:
     - Fetch Data from DB2:
       - `http://linuxip:8080/query_db?dsn_database=""""&dsn_hostname=""""&dsn_port=""""&dsn_uid=""""&dsn_pwd=""""&sql_query=""""`
     - Update Data:
       - `http://linuxip:8080/update_date?dsn_database=""""&dsn_hostname=""""&dsn_port=""""&dsn_uid=""""&dsn_pwd=""""&sql_query=""""`

Note: Replace the empty strings in the sample URLs with actual values:
- `dsn_database` → DB2 Database name (available in the service credentials of the DB2 resource)
- `dsn_hostname` → DB2 hostname (available in the service credentials of the DB2 resource)
- `dsn_port` → DB2 port number (available in the service credentials of the DB2 resource)
- `dsn_uid` → DB2 User ID (available in the service credentials of the DB2 resource)
- `dsn_pwd` → DB2 Password (available in the service credentials of the DB2 resource)
- `sql_query` → SQL Query (Select or Update query)",1,db2_test-main/test_db2_connection.py,local,,,0,0,0,0,0,1718200830091,1718200998890,427,1925ef83-e37c-4930-8b19-422e55ccdfe9,,,2,watsonx.data,python
cgmdxgrcze,Hive table creation in Watsonx.dat,Munendra Singh,"This asset automates the creation of Hive tables in watsonx.data from CSV files stored in Minio object storage. It efficiently reads the files, defines schemas, and executes the necessary SQL commands to populate Hive tables with the data in Watsonx.data.",1,cgmdxgrcze.py,local,,,0,0,0,0,0,1718200868930,1718202730592,297,bf018fd4-17ff-4291-8c83-8dd155d8bcec,,,2,watsonx.data,python
csxwhijexo,Custom Extension for Retrieving/Updating Data in DB2,Nagaraju Kuruva,"1) Custom Extension for Retrieving/Updating Data in DB2:
   - This custom extension enables read and update operations on a DB2 database.
   - It can be integrated with WatsonX Assistance.

   Note: 
i) The package includes specification files for both Code Engine and Linux machine OpenAI. You can use either based on your requirements.
ii) I have added dummy python Test file as it was not taking extension(json) file directly.",1,db2_extension/Test.py,local,,,0,0,0,0,0,1718201811299,1718201811299,427,1925ef83-e37c-4930-8b19-422e55ccdfe9,,,12,Watson,python
qcuklsxkol,Iceberg table creation in watsonx.data,Munendra Singh,"This asset facilitates the creation of Iceberg tables in Watsonx.data from existing Hive tables. It seamlessly converts and migrates data, leveraging Watsonx.data's capabilities for enhanced data management and querying.",1,qcuklsxkol.py,local,,,0,0,0,0,0,1718202622785,1718202622785,297,bf018fd4-17ff-4291-8c83-8dd155d8bcec,,,2,watsonx.data,python
gfysdnpczp,HuggingFace Translator,"Lopamudra Tewari, Satyam Singh, Rishabh Chakrabarti",Gradio based app using huggingface translation models,1,src/hugging_face_translate/app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/hugging_face_translate,,0,1,0,0,0,1718209352425,1718209352425,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,13,Use-case,python
pnbbejemnb,Column mapping between source and target table,Munendra Singh,"This asset uses BERT embeddings and cosine similarity to accurately map columns between two different sets of tables. It leverages advanced natural language processing techniques to find the best matches, ensuring seamless data integration.",1,pnbbejemnb.py,local,,,0,0,0,0,0,1718261582298,1718261582298,297,bf018fd4-17ff-4291-8c83-8dd155d8bcec,,,2,watsonx.data,python
cfkqppcplq,address validation using google cloud services api,Satprem Rath and Munendra Singh,"This asset validates addresses using the Google Cloud Services API, ensuring accuracy and completeness. It leverages Google's robust geocoding capabilities to verify and standardize address data efficiently.",1,cfkqppcplq.py,local,,,0,0,0,0,0,1718263573161,1718263573161,297,bf018fd4-17ff-4291-8c83-8dd155d8bcec,,,2,watsonx.data,python
colytqrjos,Invoice Extraction,"Akhil Nair, Amogh Ranavade","Extracting Invoice Number,Invoice Total Amount,Purchase order Number,& Due date",1,colytqrjos.py,local,,,1,0,0,0,0,1718376484315,1718376484315,298,22a44671-af0e-4aba-9d49-97bb990561cc,,,1,watsonx.ai,python
zuvyldtswl,Deepeval evaluation using watsonx models,"Abhilash Saji, Ridha Juneja",DeepEval is an open-source evaluation framework for LLMs. Deepeval offers 14+ research backed default metrics covering a wide range of use-cases (such as RAG and fine-tuning) and it supports custom metrics as well. By default it uses OpenAI models to compute the metrics. This asset runs deepeval evaluations using watsonx models.,1,zuvyldtswl.py,local,,,0,0,0,0,0,1718610815770,1718610894837,210,b1c3f4f5-61d9-4c59-89c2-5c49a230ca90,,,1,watsonx.ai,python
ksmjpdannc,Agentic-Rag Router Engine using llama_index and BAM.,Raj Sharma,This notebook depicts how to create and use router engine for building an agentic-RAG pipeline for two use cases summarization and question answering. The integration involves llama_index library integrated with BAM.,1,ksmjpdannc.py,local,,,0,0,0,0,0,1718616713459,1718882315416,393,55fc13d8-a785-4fc1-b73d-004a79a2f997,,,13,Use-case,python
dhrbnbinmp,GA Models Response Comparator,Shivam Patel,"This application provides a streamlined experience for testing and comparing the responses of various Watson X.AI GA models concurrently. It allows you to input a prompt and set parameters, which are then sent to multiple models simultaneously, enabling you to evaluate and contrast their outputs side by side.",1,dhrbnbinmp.py,local,,,0,0,0,0,0,1718775760218,1718812069823,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,1,watsonx.ai,python
tpzbesgbbz,DynamicPrompting,Ridha Juneja,The script creates dynamic prompt based on entities to be extracted from the given document. The entities are extracted in parallel reducing the time. The script requires Watsonx.ai credentials and model card to run.,1,DynamicPrompting/Dynamic_prompt.py,local,,,0,0,0,0,0,1718778954273,1718778954273,271,bc1529c5-2c21-4575-ae33-0566f44258b5,,,1,watsonx.ai,python
acuztlhiuq,Google Latest articles summarisation,Shivam Patel,"This Streamlit application retrieves the most recent articles, up to a specified number, from Google. It then generates individual summaries for each article and compiles them into a comprehensive summary, providing users with a concise overview of the latest content.",1,acuztlhiuq.py,local,,,0,0,0,0,0,1718817091624,1718817091624,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,1,watsonx.ai,python
tevtzlnrxh,Web Article Summarization,Shivam Patel,"This FastAPI API generates summaries for any web article that can be scraped, given its URL.",1,tevtzlnrxh.py,local,,,0,0,0,0,0,1718820860113,1718820860113,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,1,watsonx.ai,python
usaitjbiey,agentic_rag use case,Raj Sharma,abc def gh,6,,,,,0,0,0,0,1,1718882538595,1718882538595,393,55fc13d8-a785-4fc1-b73d-004a79a2f997,,,13,Use-case,useCase
ufanhptdda,COBOL code compiler and Executor ,Shivam Patel,"This FastAPI application allows you to compile and execute COBOL code on your local machine.

Note: For macOS, use the command brew install gnu-cobol to install GnuCOBOL.",1,ufanhptdda.py,local,,,0,0,0,0,0,1718906490873,1718976856157,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,13,Use-case,python
bhjclnkjnr,JSON Parser and Corrector,Shivam Patel,"This FastAPI endpoint allows users to parse and correct JSON objects leveraging LLM. It accepts JSON strings as input, attempts to parse them, and if the JSON is invalid, it uses IBM Watson's LLM (Large Language Model) to correct the JSON structure. The endpoint returns the corrected JSON object, ensuring the data is properly formatted and valid.",1,bhjclnkjnr.py,local,,,0,0,0,0,0,1718976865064,1718976865064,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,1,watsonx.ai,python
iczifpfwvn,QnA with Pandas Dataframe,Shivam Patel,This Streamlit app allows you to perform question answering on a pandas DataFrame loaded from an Excel or CSV file.,1,iczifpfwvn.py,local,,,0,0,0,0,0,1718990245488,1718990245488,178,1721f05c-1f67-4a11-b007-e9f235401cab,,,1,watsonx.ai,python
jlupxyhfyb,Automate text datacheck,Lopamudra Tewari,"This script is designed to automate the initial steps of checking the adequacy of text data for Natural Language Processing (NLP) classification tasks. It performs several key functions, including loading the data, verifying and converting data types, cleaning the data, and providing an analysis of the dataset. The script uses popular Python libraries such as Pandas, Matplotlib, Seaborn, and NLTK.",1,jlupxyhfyb.py,local,,,0,0,0,0,0,1719201725434,1719201725434,256,80c89eae-3f47-4f51-a7dc-841abf6859f7,,,1,watsonx.ai,python
frfuilupha,Text_data_visualisation,Lopamudra Tewari,"This script automates the initial visualization steps for text data, including frequency analysis, similarity visualization, clustering, and more. It utilizes libraries such as Pandas, Matplotlib, WordCloud, NLTK, and Scikit-learn.",1,frfuilupha.py,local,,,0,0,0,0,0,1719202945458,1719202945458,256,80c89eae-3f47-4f51-a7dc-841abf6859f7,,,13,Use-case,python
wlawdogpas,Llama_index_elasticsearch,Vishwajith C R,Connect elastic search with Llama index,1,wlawdogpas.py,local,,,0,0,0,0,0,1719225514521,1719225514521,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,1,watsonx.ai,python
brdgitoout,Elasticsearch_SQL_Query,Vishwajith C R,Query SQL with ELasticsearch,1,brdgitoout.py,local,,,0,0,0,0,0,1719225578628,1719225578628,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,1,watsonx.ai,python
vpfhlinuiu,llama_index_milvus_ingestion,Vishwajith C R,Ingest files into Milvus using llama index,1,vpfhlinuiu.py,local,,,0,0,0,0,0,1719225658723,1719225658723,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,1,watsonx.ai,python
zjmvjamdyt,Audio Event Detection,Satyam Singh,"This Python project provides a class (AudioDetection) for detecting specific audio events within a larger audio file. It leverages the Short-Time Fourier Transform (STFT) to analyze the frequency content of the audio signals and a similarity-based matching algorithm to identify the occurrence of target events.

Provide BOX links for below inputs.

source_file: File where detection will happen
matching_file: File that is the event

If no files are available to you, use below links of sample files. Before using them in asset, have a listen.
source_file: https://ibm.box.com/s/fi6kslorej3z96nxazc0l4qds4ymju1x
matching_file: https://ibm.box.com/s/lgdyh9z5ae20ix0v06imn16bhicdfjhd",1,cookbook_audio_event_detection.py,git,https://github.ibm.com/Satyam-Singh3/audio_event_detection,,0,0,0,0,0,1719228786202,1719228786202,400,8def3b48-8757-4ecf-bd74-31be929c984f,,,13,Use-case,python
avdtowlqel,"Knowledge graph, Knowledge Triple Extraction from Unstructured Text",Shravani R,"Knowledge Triples are fundamental components of Knowledge Graphs. They consist of three parts: subject, predicate, and object. These triples encode factual information in a structured format, allowing for efficient storage, retrieval, and analysis of knowledge. Ontologies provide a formal representation of knowledge within a specific domain, typically organized hierarchically with defined relationships between concepts. Extracting triples from ontologies involves parsing the ontology's structure and identifying relationships between entities to form triples.",1,knowledge_triples_extraction.py,local,,,0,0,0,0,0,1719237783039,1719237783039,119,b3973f48-0acb-42b9-9372-f11dc4cc4f7c,,,13,Use-case,python
ojnnhfbhfw,Knowledge Triple Extraction from Unstructured Text ,Shravani R,Knowledge Triple Extraction from Unstructured Text ,6,,,,,0,0,0,0,1,1719240346939,1719240346939,119,b3973f48-0acb-42b9-9372-f11dc4cc4f7c,,,13,Use-case,useCase
upkgdykguq,Content Classification,Ridha Juneja,This script classifies the content using ensemble prompt technique. It's demonstrated on subset of data with few categories.,1,Assethub1 copy/Content_Classification.py,local,,,0,0,0,0,0,1719309559829,1719309559829,271,bc1529c5-2c21-4575-ae33-0566f44258b5,,,1,watsonx.ai,python
lvlyhljlfg,Watsonx-LLM-Agent,Charana H U,Langchain LLM Agent using watsonx foundation model,1,lvlyhljlfg.py,local,,,0,0,0,0,0,1719390322353,1719390322353,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
pmsrwvmglr,Streaming Text for Watsonx Foundation Model,Charana H U,Streaming Text for Watsonx Foundation Model,1,pmsrwvmglr.py,local,,,0,0,0,0,0,1719390477872,1719390477872,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
cwqfhhfxpo,Extract the Text from Image using pytesseract,Charana H U,Extract the Text from Image using pytesseract,1,cwqfhhfxpo.py,local,,,0,0,0,0,0,1719390582537,1719390582537,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,13,Use-case,python
tolrwheckj,Get LLM response in JSON format,Charana H U,Function that ensures the response from the large language model (LLM) is in JSON format,1,tolrwheckj.py,local,,,0,0,0,0,0,1719390997245,1719390997245,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,13,Use-case,python
hkcteyqjxm,Mutilabel classification using RAG injection,Ravi Gopalakrishnan,This asset will help you with multilabel classification using RAG combined with prompt. Developer need to modify their prompt accordingly and try to add their classes that they want to classify. Also need to provide appropriate file location mainly the text files that they want to classify,1,mutilable-classification/src/flask_app.py,local,,,0,0,0,0,0,1719395926875,1719396459122,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,1,watsonx.ai,python
wginwkqlon,Text extraction from PDF files,Ravi Gopalakrishnan,This script will help the user to extract textual information from PDF file,1,wginwkqlon.py,local,,,0,0,0,0,0,1719396116300,1719396116300,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,13,Use-case,python
kjhqboadkk,vector store tabular data processing utility kit,Ravi Gopalakrishnan,you can utilise this asset to process tabular dataset and connect with the vector store and save & manipulate the vectors. You can even change the embeddings here we have used the sentence transformers.,1,kjhqboadkk.py,local,,,0,0,0,0,0,1719397689587,1719397689587,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,13,Use-case,python
zlbgsnzfph,Extract text from image,Ravi Gopalakrishnan,You can use this asset to extract the text from the image,1,zlbgsnzfph.py,local,,,0,0,0,0,0,1719399684710,1719399684710,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,13,Use-case,python
abepfjstwz,Query engine support with Milvus,Ravi Gopalakrishnan,"Team, we shall utilize this asset to do top paragraph extract available within given file",1,abepfjstwz.py,local,,,0,0,0,0,0,1719400867593,1719400867593,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,13,Use-case,python
wzkmhqcyov,Agentic RAG with llama_index using WatsonX,Diptanshu Gautam,The asset aims to leverage the existing RAG and summarisation agents. I have created a wrapper class that uses WatsonX instead of OpenAI API for embedding as well as llm.,1,wzkmhqcyov.py,local,,,0,0,0,0,0,1719408625414,1719408625414,187,5dbe3932-c73f-4a34-bc70-a77a871596a0,,,1,watsonx.ai,python
qsftreixaw,Middleware for Watson Assistant,Aniket Mohan,It creates a middleware api to counter the Watson assistant 30 seconds custom extension response timeout,1,qsftreixaw.py,local,,,0,0,0,0,0,1719465749858,1719466455833,242,88e03bea-c65d-4ee7-9078-a9f0bf75fe96,,,12,Watson,python
kkhrbwrkjj,Code Conversion and Translation,Aniket Mohan,Code explanation and Code Conversion ( Informix to Java),1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/P7S1.git,,0,0,0,0,0,1719467029474,1719467029474,242,88e03bea-c65d-4ee7-9078-a9f0bf75fe96,,,1,watsonx.ai,python
otmccsaulq,Embedding Model Finetuning,Aniket Mohan,Finetune your embedding model on your custom dataset for Improving Embedding retrieval for RAG,1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/Embedding-Finetuning-RAG.git,,0,0,0,0,0,1719469322379,1719469322379,242,88e03bea-c65d-4ee7-9078-a9f0bf75fe96,,,1,watsonx.ai,python
bxkligolmy,Testing Bertopic,Ruhin Shaikh,Testing with file,6,,,,,0,0,0,0,1,1719478239918,1719478239918,122,a3f396d5-dc83-4058-a600-1a1412a0dfdf,,,13,Use-case,useCase
cjuucupska,Extract Images from PDF using pytesseract library,Aishwarya Raj,"This Python script converts pages from a PDF into JPEG images, performs Optical Character Recognition (OCR) using Tesseract on each image, and prints the extracted text predictions for each page.",1,main.py,git,https://github.ibm.com/aishwarya-raj1/ImageExtraction.git,,0,0,0,0,0,1719478851616,1719478851616,374,36c887f1-f8e4-4abd-884d-b75abc826a7d,,,13,Use-case,python
qosuosrifc,Agentic-RAG performance comparison with classical RAG,Ruman Shaikh,This asset contains the code to compare an implementation of Agentic-RAG system using llama-index with a classical RAG system. The comparison is done use a custom dataset of manually written ground truth with response from both the RAG system over 10 different matrices. ,1,run_analysis.py,git,https://github.ibm.com/Ruman-Shaikh/Agentic-RAG.git,,0,0,0,0,0,1719480327031,1719480327031,131,5378f5bf-dca3-4ed6-bcf1-c8b7d58f0f23,,,13,Use-case,python
thqdfqinpu,Visualise Knowledge graph created using structured data,Prerna Prem,This asset will be used to visualise knowledge graph created using ontology generated from structured data,1,visualizations_pyvis.py,git,https://github.ibm.com/Prerna-Prem/graph_visualisation.git,,0,0,0,0,0,1719481148950,1719481148950,353,1f9cc2a7-6dab-4a10-819d-2e7b489c0784,,,13,Use-case,python
tlrxjdwpoc,wget_testing,Natraj David Saldaña,testing,6,,,,,0,0,0,0,1,1719483042655,1719483042656,304,15e767a5-ed54-4a3f-a7dd-0218c6b31d48,,,13,Use-case,useCase
cdioogbbux,Enhanced Data Analysis using Wx.ai,Apeksha Choudhary,"This script uses IBM WatsonxLLM  and Pandas for data analysis. It reads a  CSV, converts queries into Pandas code, extracts insights, and synthesizes responses. This integration empowers dynamic querying and insightful data-driven responses from structured data.",1,cdioogbbux.py,local,,,0,0,0,0,0,1719483514726,1719483514726,137,29b8240c-4525-44f3-9def-f95361c81204,,,1,watsonx.ai,python
raeypyqbev,Sentiment and Intent Analysis,Shravani R,Performs sentiment and intent analysis,1,raeypyqbev.py,local,,,0,0,0,0,0,1719486647672,1719487153666,119,b3973f48-0acb-42b9-9372-f11dc4cc4f7c,,,13,Use-case,python
rhigstfrrd,Ansible/Python code generation using Watsonx.ai,Shilpa Suresh,"The program contains code to generate python or ansible code given natural language description  following standard practices using langchain integrated with Watsonx.ai . The models used here and other parameters can be changed as per need. The file is ready to execute.

How to execute:
Provide api_key, ibm_cloud_url, project_id, language(python/ansible) and task (Natural language description of code to be generated) in env variables specified as inputs and run the file",1,rhigstfrrd.py,local,,,1,0,0,0,0,1719489917457,1720518381596,117,313e8d03-91d1-4f32-98c0-394bcd9148ea,,,1,watsonx.ai,python
jahfvogrob,Assistant Looping and opening links in new tab,Amrita Rajput,This asset performs the looping of a step in assistant action and opening of a particular URL in a new tab.,4,assistant_looping/script.sh,local,,,0,0,0,0,0,1719494425637,1719495979158,269,df3f0373-9573-4d54-a70f-d5b920fe6b42,,,12,Watson,bash
fscygtacnq,Assistant Dynamic Button Creation,Amrita Rajput,"This asset facilitates the dynamic creation of buttons that open in new tabs, neatly spaced within the same line.",4,dynamic_buttons/script.sh,local,,,0,0,0,0,0,1719495869954,1719495869954,269,df3f0373-9573-4d54-a70f-d5b920fe6b42,,,12,Watson,bash
oaunljmgfw,HR JOB RECRUITMENT,"Aniket Mohan, Diksha Chandra, Sourabh Jha",This code builds the pipeline for Generating Job Description to Candidate Short Listing and Interview Question Generation,1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/HR-Recruitment.git,,0,0,0,0,0,1719498920613,1719498920613,242,88e03bea-c65d-4ee7-9078-a9f0bf75fe96,,,1,watsonx.ai,python
mrokozvywo,Advanced Text to SQL,Aniket Mohan,This asset helps you to route between table and generate SQL queries from a natural language queries,1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/Advanced-Text-to-SQL.git,,0,0,0,0,0,1719508845640,1719508845640,242,88e03bea-c65d-4ee7-9078-a9f0bf75fe96,,,1,watsonx.ai,python
wqwkdzhbfn,XML to SQL Conversion v6,Mohammed Ali Shaik,"This asset takes XML file used for informatica pipelines and converts it into SQL query.  
Requirements needed to run the code is the environment variables. 
command to execute this command is streamlit run app.py PROJECT_ID IBM_CLOUD_URL API_KEY IAM_URL SPACE_ID ENDPOINT_URL1 ENDPOINT_URL2
In the above command ENDPOINT_URL1 and ENDPOINT_URL2 are the deployed prompt template end point urls.",4,bash.sh,local,,,0,0,0,0,0,1719557766899,1719557766899,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,bash
ttgwomacwm,XML to SQL generation v7,Mohammed Ali Shaik,"This asset takes XML file used for informatica pipelines and converts it into SQL query.  
Requirements needed to run the code is the environment variables. 
command to execute this command is streamlit run app.py PROJECT_ID IBM_CLOUD_URL API_KEY IAM_URL SPACE_ID ENDPOINT_URL1 ENDPOINT_URL2
In the above command ENDPOINT_URL1 and ENDPOINT_URL2 are the deployed prompt template end point urls.",4,bash.sh,local,,,0,0,0,0,0,1719558686690,1719558686690,184,0f41e761-42a2-4c29-ac89-21bce9104036,,,13,Use-case,bash
posvxftvuq,Unique code extraction from hierarchical excel data,Priyanka Mohekar,"This asset will do the keyword extraction from a hierarchical excel data using WatsonX Discovery. 
Using Python each row of excel is converted into sentence and then using WatsonX.AI we can extract the information.
It will convert an nD array to 1D array.
It will create the embeddings and upload the file into WatsonX Discovery
Then we are searching the entity_term in WatsonX Discovery",1,posvxftvuq.py,local,,,1,0,0,0,0,1719565871461,1720516370858,196,3e391705-f457-4fcc-8dc6-7a02834890b7,,,13,Use-case,python
hwrwgmmpco,Excel Data : Keyword Extraction,Priyanka Mohekar,"You need to pass direct download link for your excel file and name the sheet as ""data"". To get the download link follow the steps: 1. upload file in your box folder 2. Inspect 3. Network 4. Click on Download 5. Copy the link",6,,,,,0,0,0,0,1,1719566236622,1719566236622,196,3e391705-f457-4fcc-8dc6-7a02834890b7,,,13,Use-case,useCase
iekqgwjkrh,Watsonx assistant compatible openapi json generator for fastapi apps,Abhilash Saji,"To call a python application from watsonx assistant, openapi json file corresponding to the application should be added as a custom extension. Some takes a common template of openapi json and edit the input and output parameters, which is manual. Another approach is to automatically generate openapi using fastapi itself, but it may not be completely accurate. Also it is noticed that sometimes these json versions or format may not be supported by watsonx assistant.
This asset generates Watsonx assistant compatible openapi json generator for fastapi apps. It takes a python files as input and generate json file using codellama which can be directly uploaded to assistant after changing the url.",1,iekqgwjkrh.py,local,,,0,0,0,0,0,1719663902801,1719663902801,210,b1c3f4f5-61d9-4c59-89c2-5c49a230ca90,,,1,watsonx.ai,python
mrngagseqb,Interactive Chatbot with Summary,Kanishk Saxena,"Used Langchain's memory module to create a chatbot that also summarize previous interactions and maintain context. This feature ensures seamless conversations, allowing the chatbot to recall past discussions and provide relevant responses, enhancing user experience and engagement.",1,mrngagseqb.py,local,,,0,0,0,0,0,1719677413137,1719682137641,249,1a7a7293-a439-416f-bc03-5a76ad9bf2f2,,,13,Use-case,python
wbdoexlcre,Gradio session management,RAKESH LINGUBARI,"It is used to get the log analysis of users in terminal. Currently i am using gradio user authentication with different user creditianls [(""user"", ""password""), (""user2"", ""password"") , (""user3"" , ""password"")]",1,wbdoexlcre.py,local,,,0,0,0,0,0,1719726414832,1719727679857,447,725fb9bd-ba84-4e92-a9b2-b7e716ecd52c,,,13,Use-case,python
dhgrhddohw,IBM TTS for Synthetic Audio,Gautam Chutani,IBM Text-to-Speech for generating synthetic audio samples using different languages and voices.,1,dhgrhddohw.py,local,,,0,0,0,0,0,1719755083786,1719758010027,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,12,Watson,python
iuxesfiawp,RAG with DSPy and LlamaIndex Frameworks,Gautam Chutani,This notebook shows how to write DSPy code to define Signatures for LLM inputs/outputs and to define DSPy Modules for RAG task using Chain-of-Thoughts (CoT). And then port over these components to overall workflows within LlamaIndex Query pipelines.,1,iuxesfiawp.py,local,,,0,0,0,0,0,1719773319811,1719775498797,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
bbxaaaetgp,Building a Conversational Agent with LangChain and WatsonX.ai,Sohan M,"In this code we will:

Set up the environment and import necessary libraries.
Define custom tools for word length calculation and arithmetic operations.
Configure the agent’s prompts and memory.
Integrate the LangChain client with WatsonX.ai.
Demonstrate the agent’s capabilities with example queries.",1,,git,https://github.ibm.com/Sohan-M1/Langchain_agents-WatsonX.ai,,0,0,0,0,0,1719817785072,1719817785072,201,c9f23abb-24a2-49d9-8ee6-799a166850e1,,,1,watsonx.ai,python
xaqtgggqtn,Whisper V3 large + WatsonX.ai Speech Transcription ,Sohan M,"This Python file utilises a French fine-tuned Whisper v3 large model for transcription. Manual diarization is performed, and the results are then passed to Watsonx for summary generation and entity extraction.
The Whisper model is sourced from Hugging Face. Please paste your Hugging Face API key.",1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/Speech-Service-Assets/tree/main/Whisper%20V3%2B%20Watsonx.ai,,0,0,0,0,0,1719818092596,1719818092596,201,c9f23abb-24a2-49d9-8ee6-799a166850e1,,,13,Use-case,python
agdajindil,Semantic caching with watson discovery,Charana H U,Semantic caching with watson discovery,1,https://github.ibm.com/Charana-H-U/World_Of_Tanks/blob/main/src/main.py,git,https://github.ibm.com/Charana-H-U/World_Of_Tanks,,0,0,0,0,0,1719818495353,1719818495353,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,13,Use-case,python
cksvctpnrd,Text anonymiser using synthetic data,"Ravi Gopalakrishnan, Akash Modi","Anonymiser application is part of synthetic  data generation(SDG) Capability building . This application will be used for anonymising the documents which has PIIs and other personal identifiable. This application has download functionality to download the anonymised documents once processed successfully. This is initial version of anonymisation, we will keep updating this asset as this has certain limitations for now, we will rectify in upcoming releases.",1,https://github.ibm.com/Client-Eng-EMEA-IN/text-anonymiser/tree/main/src/app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/text-anonymiser.git,,1,0,0,0,0,1719844781631,1719844781631,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,4,Data Generation,python
tneceygskr,crewAI Agent with Watsonx Foundation LLM and DuckDuckGo Search,"Charana H U, Sohan M","crewAI Agent integration with Watsonx Foundation LLM, and the use of DuckDuckGo Search to enhance information retrieval capabilities.",1,tneceygskr.py,local,,,0,0,0,0,0,1719909281202,1719912504949,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,13,Use-case,python
prsgcauldx,"Unified Metrics - Custom RAG Evaluation with and without Ground Truth, Summarisation Evaluation without Ground Truth,Metrics + score","Prajna Neerchal, Ragi Sharma, Satyam Singh, Soumyajit Bera","Unified Metrics - Evaluation of RAG, Summaries Generated.Here, we are having with reference and without reference .In case of RAG, we have evaluated based on both reference and Non - Reference. In case of Reference for RAG usecase, It is Bleu,Meteor,Rouge_l,Rouge_n,Jaccard Score. In case of non reference for RAG usecase,It is Context Relevance,Answer Relevance and Faithfulness.In case of summary, we have calculated without reference and the triad of metrics is coherence based.",1,Unified_Metrics/main.py,local,,,2,0,0,0,0,1719936380870,1720611507821,108,d0a56e85-71b0-402f-ba8f-3ffbee9d1581,,,13,Use-case,python
vlogreiiyt,Evaluate Detached Prompt with Custom Metrics in Watsonx Governance,"Varsha Kumari, Akash Modi","This asset helps you create a detached prompt to evaluate against an external model, evaluate it for default metrics as well as custom metrics in watsonx governance platform.",1,,git,https://github.ibm.com/Varsha-Kumari7/watsonx-governance,,1,0,0,0,0,1720024201463,1720024201463,306,df33165c-5523-49c7-a60e-4beecf7a6e95,,,3,watsonx.governance,python
utetntebjs,Integration of Watsonx Discovery with Watson Assistant for Original Passage Retrieval,Amrita Rajput,This asset facilitates the integration of Watsonx Discovery with Watson Assistant to retrieve original passages from documents related to a search query.,4,WxD+WA/script.sh,local,,,0,0,0,0,0,1720076303373,1720076303373,269,df3f0373-9573-4d54-a70f-d5b920fe6b42,,,12,Watson,bash
bhkjpfsapp,watsonx integration with Planning analytics(TM1),"Shaurya Sethi, Mounica Golkonda","By integrating watsonx.ai , the user input to the chatbot as a natural language query will get converted to TM1 query and the corresponding output as a view or in natural language will be given as a response to the user.",1,TM1_MDX.py,git,https://github.ibm.com/Shaurya-Sethi1/TM1_PA-and-WX,,0,0,0,0,0,1720076501001,1720076501001,261,52075189-5823-4cfb-9389-8dec89059a2e,,,1,watsonx.ai,python
ayaenefzrb,Metadata addition and Document Extraction Tool for Watson Discovery,Amrita Rajput,"Asset facilitates metadata addition during data ingestion in Watson Discovery, as well as extraction of the full document using Watson Discovery.
",1,WD Data extraction/Add_metadata_and_extract_document.py,local,,,1,0,0,0,0,1720087147013,1720105644786,269,df3f0373-9573-4d54-a70f-d5b920fe6b42,,,12,Watson,python
iuhvtaqphf,Analyzing Prediction Accuracy of LLM and Exporting False Predictions to Excel,Amrita Rajput,This asset facilitates to evaluate predictions made using LLM to get accuracy and save false predictions to Excel.,1,Evaluation/evaluation_app.py,local,,,0,0,0,0,0,1720104208136,1720104208136,269,df3f0373-9573-4d54-a70f-d5b920fe6b42,,,1,watsonx.ai,python
cwipsmqfus,Watsonx discovery hybrid search for hugging face,Mohsin Khan,This asset helps in performing hybrid (keyword + dense vector) search on watsonx discovery (elastic search) with hugging face,1,watsonx discovery hybrid search hf/elastic.py,local,,,0,0,0,0,0,1720106704158,1720106704158,180,95868aff-43ef-40b2-a30e-034ab610255a,,,12,Watson,python
oapqcdestn,Watsonx discovery hybrid search using elser model,Mohsin Khan,This asset helps in performing hybrid (keyword + sparse vector) search on watsonx discovery (elastic search) using elser model,1,watsonx_discovery_hybrid_search_elser/elastic.py,local,,,0,0,0,0,0,1720112113552,1720112113552,180,95868aff-43ef-40b2-a30e-034ab610255a,,,12,Watson,python
fqbyofciwv,AgentX - Add and Update Documents via API,Akash Balakrishnan,This asset is used to add/update documents to AgentX via API as there is no functionality to upload documents in the provided API docs of AgentX.,1,src/script.py,git,https://github.ibm.com/akashbalakrishnan/agentx-wrapper.git,,1,0,0,0,0,1720166484030,1720166484030,460,f69a632d-878d-4709-9940-64b779e52373,,,13,Use-case,python
satahkdxgv,Semantic Caching with Wx Discovery (ElasticSearch),"Gautam Chutani, Preeti Sajjan","This asset performs semantic caching with Watsonx Discovery (ElasticSearch). The code assumes you have the embedding model such as "".multilingual-e5-small_linux-x86_64"" already downloaded and deployed in Watsonx Discovery.",1,satahkdxgv.py,local,,,0,0,0,0,0,1720389800436,1720431198577,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
dfdvuzdvqq,Live transcribing for twilio call,Phani Chodavarapu,transcribe the twilio's call ,1,main.py,git,https://github.ibm.com/Phani-Chodavarapu/twilio_live_transcribe.git,,1,0,0,0,0,1720516898986,1720516898986,257,37589b14-4ddb-45a5-9218-2cac3a4cd657,,,13,Use-case,python
fnmgqageij,Code Outliner for COBOL,Pavan Shiraguppi,"Gives an outline and nested tree of the DIVISIONS, SECTIONS and FUNCTIONS from a cobol code.",1,fnmgqageij.py,local,,,1,0,0,0,0,1720620921741,1720621002085,296,cec77fe4-751a-4d5e-8d07-9da70ec31363,,,13,Use-case,python
bbgmelhxiw,Watsonx Discovery Integration for Passage Retrieval from multi-passage documents  in Watson Assistant,"Amrita Rajput, Mohsin Khan",This asset facilitates the integration of Watsonx Discovery with Watson Assistant to retrieve passages from multi-passage documents (keeping document structure intact) through a hybrid search query.,4,WxD(hybrid_search)+WA/script.sh,local,,,0,0,0,0,0,1720621028826,1720621542493,269,df3f0373-9573-4d54-a70f-d5b920fe6b42,,,12,Watson,bash
ledzigkhxs,Extraction of detail based on natural language spec query using Carbon Svelte,Muskan .,"In this code , we extract the details of the exact electrical component specified such as maker part number for different kinds of components of the electronics industry. We utilise LLM to get the results based on the natural language query that the user asks/mentions. We also have a chatbot in the UI built using Carbon Svelte framework.(Please keep in mind to follow the readme file)",1,,git,https://github.ibm.com/watsonx-apac/pilot-GCG-Qisda-BENQ/tree/main,,0,0,0,0,0,1720627257217,1720627257217,207,8e07ea79-62f1-4249-ac9f-21c42a230cfa,,,1,watsonx.ai,python
zlotuwrttz,Watsonx Discovery integration with Watson Assistant for multi-passage documents via semantic matching,"Mohsin Khan, Amrita Rajput","This asset integrates Watsonx Discovery with Watson Assistant for retrieving passages from multi-passage documents, maintaining document structure via Semantic matching search queries.",4,WxD(semantic_search)+WA/script.sh,local,,,0,0,0,0,0,1720691053568,1720691053568,180,95868aff-43ef-40b2-a30e-034ab610255a,,,12,Watson,bash
fehrmowfnt,Extract Multiple Tables from PDF using PyMuPDF package,Susmit Panda,"PDF Table Extraction
This repository contains Python code for extracting tables from PDF documents. The code can handle multiple tables on a single page and outputs the page number along with the table number.
Features:
Table Extraction: Extracts tables from PDF documents, handling multiple tables per page.
Output Format: Outputs page numbers and corresponding table numbers for each extracted table.
Dependencies: Requires only two libraries to be installed: pandas and PyMuPDF.
Input: Users need to provide the path to the PDF file (input_file) from which tables will be extracted.",1,table_pdf/extract_table.py,local,,,1,0,0,0,0,1720770366091,1720770366091,305,dcd7109c-d5ff-46f2-b418-7963c841e585,,,4,Data Generation,python
spgzzhpetb,Multithread Watsonx.ai API call,Aishwarya Raj,"Multithreading Watsonx API calls involves concurrently executing multiple requests to the Watsonx API endpoint using threads. This approach improves efficiency by allowing simultaneous handling of API requests, reducing overall processing time when compared to sequential execution. It's particularly useful for applications requiring parallel processing of API calls to enhance performance and responsiveness",1,main.py,git,https://github.ibm.com/aishwarya-raj1/AlbertProject.git,,0,0,0,0,0,1720770391365,1720770391365,374,36c887f1-f8e4-4abd-884d-b75abc826a7d,,,1,watsonx.ai,python
tupmkaueuw,Legal documents comparision ,SRIPRIYA ARABALA,Code to compare two legal documents and fetch the missing elements ,1,tupmkaueuw.py,local,,,0,0,0,0,0,1720781418412,1720781418412,215,aa3f26cc-8edf-4fbc-b154-a1ed394be762,,,1,watsonx.ai,python
tuaeqtbuue,XML log files comparison and insights,Ramananjali Mounica Golkonda,This app will help you in comparison of 2 different timestamp XML logs. The differences in both of the files will be presented in tabular format and followed by LLM generated analysis insights about the differences in log files.,1,watsonx-reusable-assets/XML log files comparison/streamlit_main_logscomparison.py,git,https://github.ibm.com/mounica-golkonda/watsonx-reusable-assets,,0,0,0,0,0,1720782031634,1720782031634,55,d46ed019-2d10-4d15-805e-773bb612f210,,,1,watsonx.ai,python
wumrhanhub,Entity Recognition Evaluation for key-value entities,Mohsin Khan,"This assets helps in evaluating the precision, recall, accuracy for key-value entity recognition/extraction use case.",1,Entity recognition asset/entity_extraction_evaluation.py,local,,,0,0,0,0,0,1720786103981,1720786103981,180,95868aff-43ef-40b2-a30e-034ab610255a,,,12,Watson,python
gegptihnph,Postgres Connection ,Shwetha BR,"This Python script provides functionality to manage tables in a PostgreSQL database. It allows you to:
1. Create a table from a CSV file.
2. List all tables in the database.
3. Delete a specified table from the database.",1,gegptihnph.py,local,,,0,0,0,0,0,1720932242351,1720932242351,218,ba5fd4b8-c7e2-4281-8222-b7ea20dc52bc,,,11,Data Stage,python
aqtbeeurjf,Multilingual RAG with Carbon UI for PDF Highlighter,"Akash Modi , Gautam Chutani , Safalta Suresh","This asset contains a RAG pipeline with WatsonX Disocvery with multi-lingual support to detect language of user query and respond in source language. There is added support for contextual/session history. Also it has a microservice for PDF Highlighting that highlights the chunks in source documents on Carbon Design based ReactJS UI integrated with WatsonX Assistant.

GitHub: https://github.ibm.com/Client-Eng-EMEA-IN/Multilingual-RAG",1,server.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Multilingual-RAG,,0,0,0,0,0,1721025281712,1721025281712,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
liflyozmrl,Assistant and Discovery Integration with login page,Anant Kumar,Adds a simple  customizable login page for adding additional security in Assistant and Discovert integration pilots,1,https://github.ibm.com/client-engineering-japan/colwide_demo/blob/main/app.py,git,https://github.ibm.com/client-engineering-japan/colwide_demo,,0,0,0,0,0,1721097433106,1721097433106,228,9576d2cd-8086-48e1-9478-7c0d6786790d,,,1,watsonx.ai,python
givecezlzi,Java Code Generator,Anant Kumar,Uses simple user query to generate Java code,1,https://github.ibm.com/t-squad-jp/ts-codegen/blob/main/Java/code_gen_UI.py,git,https://github.ibm.com/t-squad-jp/ts-codegen/blob/main/Java/,,0,0,0,0,0,1721097577173,1721097577173,228,9576d2cd-8086-48e1-9478-7c0d6786790d,,,1,watsonx.ai,python
reeqlfiack,SingleStore DB,Jayesh Ranjan,"This script defines the SingleStoreWrapper class, which facilitates interactions with a SingleStore database for storing and searching text data using embeddings. It leverages the SentenceTransformer model for generating embeddings from text and uses SQLAlchemy for database operations. The wrapper includes methods for adding objects to the database, performing similarity searches, and managing data collections.",1,reeqlfiack.py,local,,,0,0,0,0,0,1721102650813,1721102650813,324,3e533b68-f7bd-4e54-aff7-171c0393ff6c,,,1,watsonx.ai,python
ijtbbwsgin,Querying CSV Using Watsonx,Gayathri E S,Upload the CSV to a SQL database and translate natural language queries into SQL for database querying.,1,ijtbbwsgin.py,local,,,0,0,0,0,0,1721102937824,1721102937824,485,90efaf12-6a7d-4e37-84d7-cdb5e3c2faed,,,1,watsonx.ai,python
lopqmgswkq,Multi-processing Speech-to-text and Summarization,Rahul Chavan,In this asset we do parallel processing for speech to text after splitting the audio into 2 channels (left and right) and then we combine the transcript based on timestamp and do summarization,1,app.py,git,https://github.ibm.com/client-engineering-japan/Tokyo-Star-Bank---Summarization.git,,0,0,0,0,0,1721104382009,1721104382009,234,8f06e80d-32d2-4114-958d-29bda13a953c,,,1,watsonx.ai,python
rsbevqvwiu,Advanced RAG,Prasath K,Advanced RAG using Multi query expansion techniques,1,Advanced-RAG/utils/milvius.py,local,,,0,0,0,0,0,1721111206637,1721111206637,481,32135552-e1a9-4abe-bd01-3b27a8bcb6bd,,,1,watsonx.ai,python
rbvbwdrbsc,Answer Evaluation App,Durgesh Chalvadi,"This is a Streamlit web application for evaluating answers using various similarity metrics. The app allows users to upload a CSV file containing gold (reference) answers and corresponding model answers. It then computes and visualizes the similarity scores based on user-selected evaluation methods.

",1,app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/LLM_Response_Evalualtion_Asset_Building.git,,0,0,0,0,0,1721115144457,1721115144457,478,96abcd86-1a69-4656-b4ab-4b3b17ad5fbd,,,1,watsonx.ai,python
jmviqquheh,MS Word Plugin for Word Doc Summarizer using WX.ai,Durgesh Chalvadi,"The Yeoman Generator for Office Add-ins (also called ""Yo Office"") is an interactive Node.js-based command line tool that creates Office Add-in development projects",1,app2.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Wx_MS_Word_Plugin-WIP.git,,0,0,0,0,0,1721115549666,1721115549666,478,96abcd86-1a69-4656-b4ab-4b3b17ad5fbd,,,1,watsonx.ai,python
giibdnbiem,DeepCrawler for Dynamic Javascript Websites,Pavan Shiraguppi,Crawl the data from links and sublinks present in the webpage. Option to restrict crawling to a particular domain routes as well.,1,giibdnbiem.py,local,,,0,0,0,0,0,1721126306441,1721126306441,296,cec77fe4-751a-4d5e-8d07-9da70ec31363,,,4,Data Generation,python
kjykfrfdcz,Using deployed prompt template in watsonx.ai,Shilpi Varshney,This code can be used to get results from deployed prompt template,1,kjykfrfdcz.py,local,,,0,0,0,0,0,1721128106242,1721128106242,181,456cfdc1-e400-4db8-9247-07f33244505d,,,1,watsonx.ai,python
vvzdigdrer,Deploy discovery python function in watsonx.ai,Shilpi Varshney,This function can be used to deploy discovery python function in watsonx project,1,vvzdigdrer.py,local,,,0,0,0,0,0,1721128291431,1721128291431,181,456cfdc1-e400-4db8-9247-07f33244505d,,,8,WML,python
ghbrcacjtr,RAFT with watsonx ,Shilpi Varshney,"This asset is the watsonx-ized version of RAFT framework which used OPENAI. 
More details about RAG can be found here: https://techcommunity.microsoft.com/t5/ai-ai-platform-blog/raft-a-new-way-to-teach-llms-to-be-better-at-rag/ba-p/4084674",1,raft.py,git,https://github.ibm.com/Shilpi-Varshney/raft-watsonx/tree/main/raft,,0,0,0,0,0,1721129161111,1721129161111,181,456cfdc1-e400-4db8-9247-07f33244505d,,,1,watsonx.ai,python
eqnzcwlwgk,"Identify Checkboxes using openCV and ""linhdo/checkbox-detector""",Sohan M,"This code provides two methods for identifying checkboxes in images
OpenCV Library: This approach leverages OpenCV, a popular computer vision library, to detect and analyze checkboxes within images. Hugging Face : This method utilizes the capabilities of the Hugging Face library, a powerful ecosystem for machine learning, to potentially employ pre-trained models or custom-built solutions for checkbox detection. Hugging face = ""linhdo/checkbox-detector""",1,,git,https://github.ibm.com/Sohan-M1/Checkboxes,,0,0,0,0,0,1721620051746,1721620051746,201,c9f23abb-24a2-49d9-8ee6-799a166850e1,,,1,watsonx.ai,python
jsyshsjlud,Entitiy Extraction in Dataframe,Niranjan Khedkar,This is a tool which you can use to extract entities out of a dataframe it has both processing options i.e row by row or whole dataframe at once(for small dataframes),1,gradio-ui_jp.py,git,https://github.ibm.com/client-engineering-japan/ISUZU-SPSS,,0,0,0,0,0,1722924162782,1722924162782,348,6ca6058a-61a2-4f3a-90eb-2cad2df9c40b,,,1,watsonx.ai,python
jkyaouwyyq,Extract text from video/speech,Susmit Panda,"This code extracts text from a video by converting it into a transcript. The process involves uploading a video file, converting it to audio, and then extracting text from the audio. Follow the steps below to get the file path for your video:
Details:
Upload your .mp4 file to the Box folder.
Click on the file to open it.
Right-click on the file and select ""Inspect.""
In the Inspect panel, go to the Network tab (If not visible, click on the "">>"" symbol to find it).
Clear the Network Log for better visibility.
In the Box, click on Download.
In the Inspect panel, find and click on ""download"" to view the URL.
Copy the URL and provide it as input (file_path)
There are other two input we have to provide:
api_key, url =. when we have instance for speech to text in IBM Watson. we have api_key and url. That we have to paste.

File size should be < 100 MB.",1,jkyaouwyyq.py,local,,NA,0,0,0,0,0,1722935340615,1725352612393,332,c8015572-90a4-4553-8139-328bbdccfa17,,,1,watsonx.ai,python
uhivzqtygs,RAG - Elasticsearch + Reranker using ragatouille library,Yeddula Aswini,"Use case: Validation of financial documents/ Fund prospectus 
Objective: To detect possible non-compliance in documentation submitted to the Bank of Spain, thereby improving efficiency and accuracy in the supervisory process.
Solution: RAG Pipeline - to find and extract key information from the Fund prospectus, ensuring accurate validation.
Tech stack: 
watsonx.ai
Embedding model
Elasticsearch DB
langchain
pdfminer, ragatouille, unstructured
Challenges addressed: 
    - Handling broken words during chunking
    - Leveraging the latest ColBERT reranker algorithm (as of August 2024)
    - Producing clean chunks for further use - Removing white spaces, headers, and footers",1,uhivzqtygs.py,local,,,0,0,0,0,0,1723034595497,1723034595497,346,e55ef606-808c-4d6c-9239-93e4d32c01d1,,,1,watsonx.ai,python
thgvhhyvrk,Hello World (testing),AKIRA ONISHI,Hello World (testing),1,thgvhhyvrk.py,local,,,0,0,0,0,0,1723097962358,1723097962358,367,75c4b3a0-4423-47fd-8d1d-bfcda95a5d2f,,,1,watsonx.ai,python
igfikyfrfh,WatsonX governance Automatic upload data,Soumya Agarwal,This asset contains python function which is used for fetching latest csv file from COS(cloud object storage) and then uploading that data as payload and feedback data to governance without any manual effort.,1,igfikyfrfh.py,local,,,0,0,0,0,0,1723114120032,1723114120032,375,726c4d67-a696-48b7-8949-839f33dff9f7,,,3,watsonx.governance,python
isqvntlrbo,Hello from Node.js,Hirotaka Kojima,This helowrold,3,isqvntlrbo.js,local,,,1,0,0,0,0,1723166186674,1723166186674,369,25074f23-4fef-4832-b439-6d9b6049809c,,,1,watsonx.ai,javascript
girlnhwtze,Attach document stored in COS in Watsonx Assistant - Generate Pre-Signed URL using HMAC for IBM  Cloud Object Storage,Aishwarya Raj,"This Python function generates a pre-signed URL for an object stored in IBM Cloud Object Storage (COS). It allows users to access the object via a temporary URL without requiring authentication.
The function uses HMAC (Hash-based Message Authentication Code) credentials to authenticate with the IBM COS. The URL is valid for a specified duration (default is 604800 seconds, or 7 days).
You can use this asset to attach a document as a response in Watsonx Assistant.",1,girlnhwtze.py,local,,,1,0,0,0,0,1723195035520,1723195035520,374,36c887f1-f8e4-4abd-884d-b75abc826a7d,,,1,watsonx.ai,python
wpknnjytbm,Milvus Lexical search ,Ashwini Gadag,"Lexical search using Milvus Sparse vector embedding. In Milvus, the use of sparse vectors follows a similar workflow to that of dense vectors. It involves creating a collection with a sparse vector column, inserting data, creating an index, and conducting similarity searches and scalar queries.",1,wpknnjytbm.py,local,,The uploaded code uses Milvus credentials enabled from Techzone environment. ,0,0,0,0,0,1724144578528,1725362262881,339,9c7eeceb-35dd-454a-a248-d377cda68dcb,,,1,watsonx.ai,python
mbimxezzfs,Checkbox reader (PDFtoImageCheckBoxMarker),"Jayesh Ranjan, Shwetha BR","Converts PDF to images, identifies cross checkboxes and marks them with 'CHECK' in the images.",1,Checkbox_Reader/main.py,git,https://github.ibm.com/Jayesh-Ranjan/Checkbox_Reader-PDFtoImageCheckBoxMarker,https://github.ibm.com/Jayesh-Ranjan/Checkbox_Reader-PDFtoImageCheckBoxMarker/blob/main/Checkbox_Reader/readme.md,0,0,0,0,0,1724321694587,1724321694587,407,77bb9bee-677c-43ce-abc1-c9407b07fbde,,,11,Data Stage,python
gqmkvfqzps,Checkbox reader II (PDFInPlaceCheckBoxMarker),"Shwetha BR, Jayesh Ranjan","Converts PDF to images, Identifies the cross checkboxes in the images and marks them with 'CHECK' directly in the PDF. This tool maintains the original PDF format while enhancing the visibility of filled checkboxes.",1,CheckboxReader_II/main.py,git,https://github.ibm.com/Jayesh-Ranjan/CheckboxReader_II-PDFInPlaceCheckBoxMarker,https://github.ibm.com/Jayesh-Ranjan/CheckboxReader_II-PDFInPlaceCheckBoxMarker/blob/main/README.md,0,0,0,0,0,1724322565736,1724322728544,407,77bb9bee-677c-43ce-abc1-c9407b07fbde,,,11,Data Stage,python
maucpjfmsa,Perl Code Assistant,"Talib Ul Haq,  Ratna Kumari Chitturi, Goura Mohanty",This asset translates Perl syntax and constructs into Java. It helps developers by providing explanations for complex Perl code. The asset works on two levels: 1. **Subroutine Level**: Converts and explains individual Perl subroutines. 2. **Whole Script Level**: Translates the entire Perl script to Java with detailed explanations.,1,https://github.ibm.com/Client-Eng-EMEA-IN/perl_code_assistant/blob/main/custom-ui-perl-conversion/backend/app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/perl_code_assistant,https://github.ibm.com/Client-Eng-EMEA-IN/perl_code_assistant/blob/main/README.md,0,0,0,0,0,1724388625039,1726468430836,405,9293a2a5-e39a-4b30-8eae-1a82e8d29435,,,1,watsonx.ai,python
corhafglpz,Asynchronous Multi Channel Speech to Text,Abhijeet Gorai,Asynchronous Multi Channel Speech to Text,1,corhafglpz.py,local,,none,0,0,0,0,0,1724390665020,1724919600607,333,d6be855f-9ff8-4ad3-a044-d35fadf47980,,,12,Watson,python
crtvpchqjn,TMNF Business Usecase,"Anusha Garlapati, Kanishk Saxena","This project is designed to scrape articles from IT Media, extract relevant content and publication dates, and generate tags for the articles using a large language model. The tags are generated in Japanese and are meant to categorize the articles based on their content. And finally, a word cloud is generated from the tags.
",1,main.py,git,https://github.ibm.com/client-engineering-japan/TMNF-Business-Usecase/,https://github.ibm.com/client-engineering-japan/TMNF-Business-Usecase/Readme.md,0,0,0,0,0,1724745113679,1726041086457,419,14c55c34-e9ef-4a77-80d9-d2a495c58717,,,1,watsonx.ai,python
itbyicwhvv,Supervised Fine-tuning of IBM granite model using transformers,"Shilpa Hegde, Krish Hashia",This asset focuses on the method of fine tuning the IBM Granite LLM to create a specialised LLM using transformer technique - LORA. In order ease the process of fine-tuning there is an autotune function which will determine the best parameters for the provided dataset without the user performing a trial and error in choosing the best parameters. This also shows how to evaluate the results generated before and after fine-tuning the model using the BERT embeddings-based similarity metrics where the results can easily be downloaded on the local machine. ,1,,git,https://github.ibm.com/Shilpa-Hegde2/Supervised_finetuning/blob/4d7e7d5f7f172a1baae9f380c6cd9e5d4f4e3c13/finetuning_ibm_granite7B.ipynb,https://github.ibm.com/Shilpa-Hegde2/Supervised_finetuning/blob/main/README.md,1,0,0,0,0,1724827779386,1724827779386,429,7796dd6c-e3a6-4f46-a2bc-6292629199c0,,,8,WML,python
ageqbjqvvo,Milvus for hybrid search(keyword + semantic).,Amith Hooli,"This asset helps quickly implement a hybrid search using milvus reserved using techzone, Just provide the public IP as the input, and the collection is created using the existing pdf file, and output shown for different kinds of searches.",1,milvus_hybrid_search.py,git,https://github.ibm.com/Amith-Hooli/Milvus_hybrid_search/,Readme.md,0,0,0,0,0,1724837325629,1724871208096,418,0f1faf20-300d-44ee-b5cb-593366a9d970,,,1,watsonx.ai,python
dtodrnqvrs,WDU IOCR Container Asset,Vishwajith C R,"This asset is used for fast deployment of IOCR model as a container serving a fast api endpoint to deploy OCR service, 
All the guide required for the implementation is in the readme file in the git repo-- https://github.ibm.com/Client-Eng-EMEA-IN/IOCR_WDU_ASSET",1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/IOCR_WDU_ASSET,https://github.ibm.com/Client-Eng-EMEA-IN/IOCR_WDU_ASSET/blob/main/README.md,0,0,0,0,0,1724837424726,1724837424726,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,1,watsonx.ai,python
somjqovasm,Building a Simple UI with Carbon React Components for RAG and Other Applications,Aishwarya Raj,"Explore how to build an intuitive and effective user interface using Carbon React components, tailored for Retrieval-Augmented Generation (RAG) applications and adaptable to other use cases. This guide covers the essentials of leveraging Carbon React's design system to create clean, functional UIs that enhance user experience and streamline interaction with advanced technologies.

1. cd frontend          
2. Create .env file in path frontend/ where package.json is located.
    REACT_APP_API_URL=http://localhost:8500/query_vector_store?query=${query}
3. npm start
In your backend application:
Add these lines:

from fastapi.middleware.cors import CORSMiddleware

import os

app = FastAPI()

#Allow requests from your React frontend

origins = [ os.getenv(""react_url"")
]

where ""react_url"" = http://localhost:3000 (change this with your deployed url)

print(origins)

app.add_middleware(

CORSMiddleware,
allow_origins=origins,
allow_credentials=True,
allow_methods=[""*""],
allow_headers=[""*""],
)",3,src/index.js,git,https://github.ibm.com/aishwarya-raj1/UI-Asset.git,https://github.ibm.com/aishwarya-raj1/RAG-UI/blob/main/README.md,0,0,0,0,0,1724845026189,1724847375971,374,36c887f1-f8e4-4abd-884d-b75abc826a7d,,,1,watsonx.ai,javascript
vgpqlmyehl,Instruct Lab Asset: QnA File Generator,"Ratna Kumari Chitturi, Vishwajith C R, Megha Goriya","Instruct Lab Asset: QnA File Generator
This asset generates a qna.yaml file based on the provided inputs. The qna.yaml file is structured to be compatible with SDG and includes key information necessary for knowledge documentation.

",1,https://github.ibm.com/Client-Eng-EMEA-IN/Instruct-Lab-Asset-QnA-File-Generator/blob/main/instructlab_asset/app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Instruct-Lab-Asset-QnA-File-Generator,https://github.ibm.com/Client-Eng-EMEA-IN/Instruct-Lab-Asset-QnA-File-Generator/blob/main/instructlab_asset/readme.md,0,0,0,0,0,1724912218214,1724912218214,345,cb40471d-3f4a-4957-8447-484ac8c260a5,,,1,watsonx.ai,python
qlbvzutpfd,Text2Graph,M N  V satya sai muni Parmesh,"We have developed a tool that converts unstructured data into a NetworkX graph, transforming how the data is visualized and analyzed.",1,text2graph.py,git,https://github.ibm.com/munagalaparmesh/text2graph,https://github.ibm.com/munagalaparmesh/text2graph/blob/main/README.md,0,0,0,0,0,1724939282153,1724939282153,428,91eec83d-ab02-433e-9f2a-0696b7ba31b9,,,1,watsonx.ai,python
odjxbfyjmi,Semantic Caching with ElasticSearch and Milvus,"Partha Pratim Neog, Vishwajith C R, Preeti Sajjan, Gautam Chutani","This repository contains a generic Python class designed to quickly integrate Semantic Caching into your applications and enable plug-and-play usage. The class abstracts the underlying implementation, allowing you to seamlessly switch between WatsonX Discovery (Elasticsearch) and Milvus for your caching needs.",1,main.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/semantic-caching,https://github.ibm.com/Client-Eng-EMEA-IN/semantic-caching/blob/main/readme.md,1,0,0,0,0,1724996791210,1724996791210,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,2,watsonx.data,python
maipnsrbhb,Watsonx Discovery with Keyword_Elastic_Hybrid Search,Sourav Das,"Setting up Wx Discovery, ingesting local document and retrieving results through different types of search . Search includes Hybrid , Elastic and Keyword search.",1,https://github.ibm.com/Client-Eng-EMEA-IN/WxDiscovery_search/blob/main/dataingestion_with_search.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/WxDiscovery_search.git,https://github.ibm.com/Client-Eng-EMEA-IN/WxDiscovery_search/blob/main/README.md,0,0,0,0,0,1725006050808,1725006141091,421,c01e5096-146e-4756-abe3-aaf221081c21,,,12,Watson,python
cotttwuvpf,WatsonX Discovery parallel bulk upload and hybrid semantic search,Gopagoni Jyothika,"This asset leverages the capability of WatsonX Discovery to upload and index large volumes of documents simultaneously in parallel using the parallel version of the bulk helper, running multiple threads at once. Additionally, the search method combines the strengths of both text expansion (via ELSER) and dense vector search (via kNN).",1,WXD_Hybrid_Search.py,local,,.,0,0,0,0,0,1725204252971,1725204252971,388,3def69ec-7d6d-4bde-b8ca-eca8b7e50b08,,,12,Watson,python
zulbzfkaov,GLPI integration for raising a ticket as an anonymous user (using email id),Manjusha Tomar,"GLPI is ticketing tool we are raising a ticket as an anonymous user (using email id)
",1,https://github.com/ShallyManjusha/Github/blob/main/app.py,git,https://github.com/ShallyManjusha/Github.git,https://github.com/ShallyManjusha/Github/blob/main/README.md,0,0,0,0,0,1725205418619,1725354570816,354,af7b003b-00aa-480e-8de5-b31a829038eb,,,4,Data Generation,python
dcfxhvmtms,Gitlab API Call in local,Sohan M,"This script automates the creation and setup of a GitLab project using the GitLab API. It performs the following tasks:
1. Loads configuration from environment variables.
2. Defines file contents and CI/CD variables to be added to the project.
3. Provides a function to make GitLab API requests.
4. Includes functions to:
   - Create a new project
   - Add predefined files to the project
   - Set CI/CD variables
   - Trigger an initial pipeline
5. The main function orchestrates these tasks in sequence.
",1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/DT-Tardis,https://github.ibm.com/Client-Eng-EMEA-IN/DT-Tardis,0,0,0,0,0,1725265367733,1725265367733,435,01be3e93-406e-45bb-a636-fda316be7272,,,12,Watson,python
dlhfndngbh,GLPI integration for raising a ticket as an authorised user (using authorised name),Manjusha Tomar,GLPI is ticketing tool we are raising a ticket as an authorised user (using authorised name),1,https://github.com/ShallyManjusha/GLPI/blob/main/app.py,git,https://github.com/ShallyManjusha/GLPI.git,https://github.com/ShallyManjusha/GLPI/blob/main/README.md,0,0,0,0,0,1725354921201,1725354921201,354,af7b003b-00aa-480e-8de5-b31a829038eb,,,4,Data Generation,python
wvbmjjzvsj,Otafuku Summariser,Anusha Garlapati Niranjan Khedkar,"The goal of the project is to have the employees experience and recognise the enhancement of work efficiency through generative AI, such as automatic meeting memorandum summarisation.",1,app.py,git,https://github.ibm.com/client-engineering-japan/Otafuku-Summariser/,https://github.ibm.com/client-engineering-japan/Otafuku-Summariser/blob/anusha/README.md,1,0,0,0,0,1725356457652,1726121589384,419,14c55c34-e9ef-4a77-80d9-d2a495c58717,,,1,watsonx.ai,python
gcunmjefkm,RAGAS evaluation using watsonx,Tiyasa Mukherjee,"This asset evaluates RAG output with ragas metrics using watsonx LLM. It takes the input file path, watsonx project id, api key, and output folder path from user. In the input file, it expects 4 columns - 'questions', 'context', 'ground_truth', 'answers'. The 'context' column is a list of top chunks extracted by the RAG pipeline wrt the question to come up with the answer. It evaluates Faithfulness, Answer Relevancy, Answer Correctness, Context Precision, and Context Recall, and stores the metrics values in the Output folder path in xlsx file format.",1,,git,https://github.ibm.com/tiyasa-mukherjee/Asset-Ragas-with-watsonx.ai.git,NA,0,0,0,0,0,1725434407402,1725434407402,340,bf29c7b3-f178-4d14-90dd-71894f48632e,,,3,watsonx.governance,python
irkixozhnd,Java Code Generation and Updation,Paarttipaabhalaji Manohar ; M N V satya sai muni Parmesh,"With the help of this asset we can generate the java code specifically by configuring the embedded condition, variable data types and code specific conditions. Suited well for Japanese language pseudocode.",1,irkixozhnd.py,local,,https://github.ibm.com/client-engineering-japan/SompoJavaCodeGenAnalysis_PhaseII#readme,0,0,0,0,0,1725439002151,1725441441696,431,bae57203-55e1-441b-a2b8-3b80eb303704,,,1,watsonx.ai,python
jfsuuqepyc,CodeEngine DOC2PDF Converter,"Jayesh Rajan, Shwetha BR","The solution is capable of converting DOC or DOCX formats to PDF through a headless operation on a server environment, such as IBM Code Engine.",1,jfsuuqepyc.py,local,,https://github.ibm.com/br-shwetha/Doc2PDF,0,0,0,0,0,1725514224335,1725514224335,386,18b47166-cbd6-4641-b67f-92086f1825e1,,,11,Data Stage,python
atjfvztaer,"Multilingual, Multimodal, Multi-interface RAG Chatbot with LLM as a judge for governance","Piyush Aneja , Aravind Krishnan B , Abhishek Singh, Sripriya Arabala","Products used-
1)watsonX assistant
2)watsonX.ai
3)watsonX discovery

Models used-
-English speech support: https://huggingface.co/openai/whisper-small 
-Hindi speech support: https://huggingface.co/vasista22/whisper-hindi-small
-LLM for generation and translation: meta-llama/llama-3-70b-instruct

Description-
-A versatile RAG chatbot built using Watsonx.Ai, watsonx Discovery and huggingface library for speech support. The UI is built using javascript.
-The web interface supports multiple languages (Hindi/English), input types (speech and text), designed to deliver context-aware responses across platforms while displaying source attribution on the UI for enhanced transparency and user trust.
-The android application currently has a support of speech input and speech output.",1,backend/main.py,git,https://github.ibm.com/Piyush-Aneja/multilingual-multimodal-rag,https://github.ibm.com/Piyush-Aneja/multilingual-multimodal-rag/blob/main/README.md,3,0,0,0,0,1725536450352,1725537323777,385,35483289-279c-474d-a88a-d56f13f34539,,,1,watsonx.ai,python
tprltbrqaq,Watsonx Assistant Time Out WorkAround (using poling) ,"Safalta Suresh, Aniket Mohan",This asset provides a workaround for addressing the 30-second timeout issue of Watsonx Assistant by leveraging IBM COS (Cloud Object Storage).,1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/WA_Middleware/tree/rag_cos,https://github.ibm.com/Client-Eng-EMEA-IN/WA_Middleware/blob/rag_cos/README.md,0,0,0,0,0,1725859092164,1725859092164,456,314d15d5-166c-4e11-a8d8-d265c8c894cb,,,1,watsonx.ai,python
volojldtbi,Finetuning Granite 7b model using Instructlab and LORA,"Shilpa Hegde, Krish Hashia","This asset demostrates the method of finetuning IBM granite model using Instructlab and LORA on custom dataset.It also involves inferencing on finetuned model along with evaluation of results. As this needs GPU support, please download the repo to run.",1,,git,https://github.ibm.com/Shilpa-Hegde2/Instructlab_finetuning_granite.git,https://github.ibm.com/Shilpa-Hegde2/Instructlab_finetuning_granite/blob/main/README.md,1,0,0,0,0,1725862407441,1725862407441,429,7796dd6c-e3a6-4f46-a2bc-6292629199c0,,,8,WML,python
dohpauapid,VRC SQL Query Generator,"Akshay Kalane, Karthik Vullam, Sriparna Banerjee",VRC SQL Query Generator,1,frontend.py,git,https://github.ibm.com/client-engineering-japan/vrc-media.git,README.md,0,0,0,0,0,1725863831463,1725872208929,436,6bbf2189-645a-4c18-a40b-f0f22abe91d5,,,1,watsonx.ai,python
hhzyutyelz,Text streaming with watsonx LLMs,"Naveen Narayan, Aravind Krishnan B","Text streaming with watsonx LLMs

This allows real-time streaming of LLM outputs as they are generated, eliminating the need to wait for the entire content to be produced. ",1,wx_output_streaming_backend.py,git,https://github.ibm.com/Naveen-Narayan1/text-streaming-wx,https://ibm.box.com/s/lue49aerkaps3l7pkhlypcwfiitdizrf,1,0,0,0,0,1725871917267,1725871917267,455,a2f5de35-6631-46c6-8ac3-2b385aa48170,,,1,watsonx.ai,python
rdbhmycweh,Chroma_db_Collection,Amiyay K Sinha,This Task will create Chroma db collection,1,rdbhmycweh.py,local,,,0,0,0,0,0,1725875449899,1725875449899,364,8e0bdc53-dc3d-44f5-a69d-0b686e49597f,,,4,Data Generation,python
mhknuuxrtr,VRC SQL Generator v2,"Akshay Kalane, Karthik Vullam, Sriparna Banerjee",NLQ to SQL query generator.,1,frontend.py,git,https://github.ibm.com/client-engineering-japan/vrc-media.git,README.md,1,0,0,0,0,1725886493420,1726721559668,436,6bbf2189-645a-4c18-a40b-f0f22abe91d5,,,1,watsonx.ai,python
fbfdmkikox,SWOT analysis Prompt template,Ganesh Jathar,This prompt template enables the extraction of accurate and relevant SWOT analysis from a business document.,1,fbfdmkikox.py,local,,https://github.ibm.com/client-engineering-japan/asset-wizard/blob/main/README.md,0,0,0,0,0,1725962171708,1727253863300,470,c5ce41df-6cd2-4e4b-bec7-92574eafd85f,,,1,watsonx.ai,python
eyhjdezwpt,Deepsearch- Excel Conversion(Table Q&A),Sourav Das,"This asset is used for data ingestion and querying from excel file using the DeepSearch platform.
",1,https://github.ibm.com/Client-Eng-EMEA-IN/Deepsearch_excel_conversion/blob/main/table_qa.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Deepsearch_excel_conversion,https://github.ibm.com/Client-Eng-EMEA-IN/Deepsearch_excel_conversion/blob/main/README.md,0,0,0,0,0,1726044852844,1726044852844,421,c01e5096-146e-4756-abe3-aaf221081c21,,,12,Watson,python
usnmdkbwtq,Java Unit test code generation ,"M N  V satya sai muni Parmesh, Akshay Kalane,Paarttipaabhalaji Manohar",We will create unit test cases for the provided code using Java,1,https://github.ibm.com/munagalaparmesh/Java_unit_test_code_generation/blob/main/main.py,git,https://github.ibm.com/munagalaparmesh/Java_unit_test_code_generation,https://github.ibm.com/munagalaparmesh/Java_unit_test_code_generation/blob/main/readme.md,1,0,0,0,0,1726044903711,1726044903711,428,91eec83d-ab02-433e-9f2a-0696b7ba31b9,,,1,watsonx.ai,python
lfvpgwudub,Text Processing and Sentence Chunking,M N  V satya sai muni Parmesh,"This project processes a text file by splitting it into sentences, combining neighboring sentences into chunks, calculating cosine distances between sentence embeddings, and visualizing these distances to identify chunks of related sentences. The code uses various Python libraries, including numpy, matplotlib, sentence-transformers, and scikit-learn.",1,https://github.ibm.com/munagalaparmesh/Semantic_chunking/blob/main/semantic_chunking.py,git,https://github.ibm.com/munagalaparmesh/Semantic_chunking,https://github.ibm.com/munagalaparmesh/Semantic_chunking/blob/main/Readme.md,1,0,0,0,0,1726045113592,1726045113592,428,91eec83d-ab02-433e-9f2a-0696b7ba31b9,,,4,Data Generation,python
hrckeohfql,A complete script for MilvusDB,Vikas Mani,"A asset that comprise of all the useful functionalities of Milvus from creating a collection or partition, inserting data and querying from a collection or partition.",1,hrckeohfql.py,local,,https://github.ibm.com/client-engineering-japan/asset-wizard/blob/main/scripts/readme.md,1,0,0,0,0,1726047405528,1726047405528,426,6f746bd8-8cce-45fe-80cc-421dee6e037d,,,2,watsonx.data,python
dtorrtchqe,Twilio call transcriber,"Phani Chodavarapu , Raveena Khan",connected the call between agent and customer. Agent handles the call via web and customer handles through personal mobile. This application take care of audio from and to agent. Audio is captured via websocket and transcribed through IBM LSM models.,1,Twilio_call_transcriber/main.py,git,https://github.ibm.com/client-engineering-japan/asset-wizard.git,readme included in the data,1,0,0,0,0,1726117487057,1726206009272,458,df9375da-049b-4124-a58c-abbc42aaaaeb,,,12,Watson,python
cntuyfxuwl,GEval metric using Watsonx.ai,Akash Balakrishnan,This asset is used to  evaluate Entity Extraction use cases using DeepEval library powered by watsonx.ai,1,src/evaluate.py,git,https://github.ibm.com/akashbalakrishnan/deepeval-watsonx,https://github.ibm.com/akashbalakrishnan/deepeval-watsonx/blob/main/README.md,0,0,0,0,0,1726140801871,1726140801871,460,f69a632d-878d-4709-9940-64b779e52373,,,1,watsonx.ai,python
dlfpdfiqwr,ColBERT Reranker,Abhijeet Gorai,"This Python class, ColbertReranker, leverages the ColBERT model for reranking documents based on their relevance to a query. Using Huggingface's AutoTokenizer and AutoModel, the class tokenizes and encodes both queries and document texts, calculating similarity scores via cosine similarity between embeddings. The rerank method processes a list of documents, computes relevance scores, and returns the documents sorted by relevance. Ideal for information retrieval tasks requiring fine-grained reranking of documents.",1,dlfpdfiqwr.py,local,,none,0,0,0,0,0,1726219337321,1726219337321,333,d6be855f-9ff8-4ad3-a044-d35fadf47980,,,12,Watson,python
oladpcuugx,CrossEncoder Reranker,Abhijeet Gorai,"The CrossEncoderReranker class utilizes a cross-encoder model, such as cross-encoder/ms-marco-MiniLM-L-6-v2, to rerank documents based on their similarity to a query. It employs SentenceTransformers' CrossEncoder to evaluate query-document pairs, generating relevance scores for each document. The rerank method returns a sorted list of documents based on their computed relevance scores, making it highly suitable for tasks involving precise document ranking and information retrieval.",1,oladpcuugx.py,local,,none,0,0,0,0,0,1726219485717,1726219485717,333,d6be855f-9ff8-4ad3-a044-d35fadf47980,,,12,Watson,python
vxsrqnsewd,IBM Watson Discovery Client for Collection and Document Management,Abhijeet Gorai,"The DiscoveryClient class provides a comprehensive interface for interacting with IBM Watson Discovery V2, offering capabilities such as creating collections, uploading PDF documents, querying collections, and managing documents. It supports authentication through IBM's IAMAuthenticator, reading credentials from environment variables, and uploading files either as paths or in-memory streams. Key functions include transferring documents between collections, deleting documents, listing collections, and checking document processing status. This class is tailored for document ingestion, processing, and retrieval in large-scale information management systems using IBM Watson Discovery.",1,vxsrqnsewd.py,local,,none,0,0,0,0,0,1726219793873,1726219793873,333,d6be855f-9ff8-4ad3-a044-d35fadf47980,,,12,Watson,python
cqjfrmawgo,Use Milvus as Vector DB for Document Similarity Search with Hugging Face Embeddings,Abhijeet Gorai,"The MilvusRetriever class provides an interface to perform similarity-based document retrieval using the Milvus vector database and Hugging Face embeddings. It connects to a Milvus instance using provided connection credentials and supports adding documents and performing both synchronous and asynchronous similarity searches. The retriever utilizes the mixedbread-ai/mxbai-embed-large-v1 model from Hugging Face by default to generate embeddings. Key features include document retrieval filtered by filename and customizable search result count, making it ideal for vector-based search systems in NLP and information retrieval tasks.",1,cqjfrmawgo.py,local,,none,0,0,0,0,0,1726220408592,1726220408592,333,d6be855f-9ff8-4ad3-a044-d35fadf47980,,,12,Watson,python
opqlcgqscu,TesseractParsrePDF and UploadToCos,Satyam Singh,"If you have a zip file you need to do the OCR then You can Upload the Zip file on COS Bucket then Get the Object Key, This Asset focus on Downloading the Zip File Available at COS  (better approach to use for POC when accessing same data by multiple user) Then Extracting and Doing OCR on Pdfs and Then Upload all files on the COS Bucket (Pdfs + OCR ) you can figure if you only want OCR to be Uploaded and Optionally Read the OCR files using OCRTextReader (For AI Usecase.",1,app.py,git,https://github.ibm.com/singh-satyam/AssetTesseractOCR.git,https://github.ibm.com/singh-satyam/AssetTesseractOCR/blob/main/readme.md,1,0,0,0,0,1726390047989,1726390189388,400,8def3b48-8757-4ecf-bd74-31be929c984f,,,12,Watson,python
hwlbkoicgb,LLM-Enriched Metadata Storage in Milvus from Watsonx Data,"Gopagoni Jyothika, Nagaraju Kuruva","This asset provides an automated pipeline for seamless metadata management, combining structured data extraction, AI-driven enhancement, and vector-based storage for optimal performance in future queries.This FastAPI application performs a complete workflow of fetching metadata from  watsonx.data, enriching the metadata using  watsonx.ai, and storing the enriched data into a Milvus vector database for further use.The application leverages the power of AI to enhance the quality and value of metadata, making it more useful for advanced search and retrieval operations. ",1,fetch_and_enrich_and_ingest.py,local,,FastAPI Application for Metadata Enhancement and Storage Using IBM watsonx.ai and Milvus,0,0,0,0,0,1726423933090,1726423933090,388,3def69ec-7d6d-4bde-b8ca-eca8b7e50b08,,,2,watsonx.data,python
dvckamuadn,IBM Custom Speech-to-Text (STT) model development  ,Yeddula Aswini,This asset is to develop a custom Speech-to-Text (STT) model tailored to a specialized vocabulary for a particular task.,1,dvckamuadn.py,local,,Included the comments in the scripts,1,0,0,0,0,1726475931365,1726475931365,346,e55ef606-808c-4d6c-9239-93e4d32c01d1,,,12,Watson,python
kppbbusaah,CodeInsight++_v2,Ashutosh Khuntia,"This script automates the process of static code analysis for C++ projects hosted in Git repositories.
it provides a convenient way to:

Analyze all C++ files in a repository for potential errors.
Collect and parse the analysis results.
Store the results in a structured JSON format.
Optionally upload the results to IBM Cloud for further processing or storage.",1,kppbbusaah.py,local,,NA,0,0,0,0,0,1726512935270,1726512935270,396,6a5cc849-47ab-4a32-a565-006c7a9c1cdc,,,1,watsonx.ai,python
rrdktbtipy,Call Summary - Generic Prompt,"Raveena Khan, Sriparna Banerjee ","Call Summary - Generic
This is a generic prompt adaptable with any LLM that provides crisp & accurate summary of the conversation between customer & operator. ReAct style of prompting is used that provides summary with all the important information intact and removing redundant information & filler words. This prompt can be used to generate summary for any kind of information.",1,rrdktbtipy.py,local,,https://github.ibm.com/client-engineering-japan/asset-wizard/blob/main/README.md,0,0,0,0,0,1726538288116,1727714021092,446,65ec6185-f092-4f3f-a6b7-9b5a11797192,,,1,watsonx.ai,python
gbwcflhixa,ICOS- Asset,RAKESH LINGUBARI,"upload, download and get all files from icos",1,gbwcflhixa.py,local,,,1,0,0,0,0,1726550559303,1726550559303,447,725fb9bd-ba84-4e92-a9b2-b7e716ecd52c,,,2,watsonx.data,python
carsvetann,Branched Rag,Raj Sharma,This asset breaks down a query into multiple sub queries by usage of llama_index module of subquestion query generator. It will fetch you the list of sub questions and sub answers generated for that particular query.,1,carsvetann.py,local,,https://github.ibm.com/aditi-ibm/Branch_RAG/blob/main/README.md,0,0,0,0,0,1726563956485,1726563956485,393,55fc13d8-a785-4fc1-b73d-004a79a2f997,,,1,watsonx.ai,python
nbgsjvohkh,Branched_Rag ,Raj Sharma,"Branched RAG (Retrieval-Augmented Generation) is an enhancement of the standard RAG approach, designed to improve information retrieval and response generation in complex knowledge domains. This asset outlines the key features, benefits, and applications of Branched RAG.

Traditional RAG Pipelines often struggle 
with complex queries that involve multiple 
aspects or layers of information.
For example, a query like ""What is the 
impact of machine learning on healthcare 
and finance?"" involves two distinct sectors 
(healthcare and finance), each requiring 
specific information. 
To better answer such queries, Branched 
RAG decomposes these complex queries 
into simpler sub-questions, allowing for a 
more precise and relevant response.",6,,,,,0,0,0,0,1,1726564211613,1726564211613,393,55fc13d8-a785-4fc1-b73d-004a79a2f997,,,13,Use-case,useCase
ekkvpybqrn,LLM Oversampling -  Synthetically Generate Data,Bhavishya Pandit,Using LLM to synthetically generate data and improve the accuracy of classical ML models for classification-related problems.,1,ekkvpybqrn.py,local,,https://github.ibm.com/client-engineering-japan/toyota-iqas/tree/main/LLM%20Oversampling,0,0,0,0,0,1726568620730,1728281546174,462,ec67b728-dc5d-4cfd-9d27-0b1df7ae0881,,,1,watsonx.ai,python
aeucicfmkc,Integrating Third-Party Embedding  Models with Watsonx Discovery: Data Ingestion and Search ,"Abhilash Saji, Gopagoni Jyothika, Vishwajith C R","The asset helps in importing a third party embedding model from huggingface to elasticsearch, and then do the indexing and perform keyword/ dense vector search/ hybrid search using the third party model",1,app.py,git,https://github.ibm.com/Abhilash-Saji/wx-discovery-utils,https://github.ibm.com/Abhilash-Saji/wx-discovery-utils/blob/main/README.md,0,0,0,0,0,1726581446290,1726581446290,336,c84d3150-560a-44dd-a009-2307a80649b2,,,1,watsonx.ai,python
lnwomiecyu,CSV File Upload and Validation | Data Description Creation,"Charana H U, RAKESH LINGUBARI","This code provides an API for uploading CSV files, validating their content, and generating column descriptions in JSON format.",1,lnwomiecyu.py,local,,,1,0,0,0,0,1726726188287,1726726188287,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
dayzyhlziu,PDF Text Image Identifier,Susmit Panda,"It is a utility designed to analyse PDF files and identify whether they contain text, images, or both. It efficiently scans PDFs to distinguish between text-based content and embedded images.
Details:
Upload your .pdf file to the Box folder.
Click on the file to open it.
Right-click on the file and select ""Inspect.""
In the Inspect panel, go to the Network tab (If not visible, click on the "">>"" symbol to find it).
Clear the Network Log for better visibility.
In the Box, click on Download.
In the Inspect panel, find and click on ""download"" to view the URL.
Copy the URL and provide it as input (file_path)",1,dayzyhlziu.py,local,,NA,0,0,0,0,0,1726726440618,1726727184406,332,c8015572-90a4-4553-8139-328bbdccfa17,,,1,watsonx.ai,python
mtpbbesoxp,Q&A Over Google BigQuery and generate relavant Graphs,Charana H U,Q&A Over Google BigQuery and generate relavant Graphs,1,https://github.ibm.com/Charana-H-U/baloise_analytics/blob/185fc7e5f24e34090e45d0769d5a4c5a29981c75/src-sql-bot/main.py,git,https://github.ibm.com/Charana-H-U/baloise_analytics/commit/185fc7e5f24e34090e45d0769d5a4c5a29981c75,,0,0,0,0,0,1726726505442,1726726505442,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
svlvvqjysv,Survey using Orchestrate,Diwakar Kumar,"This asset utilizes the Concurrent.futures module to manage a pool of threads, facilitating non-blocking API calls.
Offers the fastest response times with a straightforward configuration process.
Basic, but highly effective for the tasks at hand.",1,svlvvqjysv.py,local,,Test,2,0,0,0,0,1726752073607,1726752073607,389,52a214e7-b813-4ec9-a083-f1b191b33f0a,,,12,Watson,python
gvrazfcvnl,Orchestrate to Automate Form Processes ,Diwakar Kumar,"Automation tool designed to simplify and optimize the creation, distribution, and management of forms. Whether you need to collect feedback, conduct assessments, or gather any kind of data, this tool automates the entire process, allowing you to save time and reduce manual effort.",1,gvrazfcvnl.py,local,,Test,1,0,0,0,0,1726753748380,1726754198334,389,52a214e7-b813-4ec9-a083-f1b191b33f0a,,,12,Watson,python
xinbxzkgzk,Orchestrate for Data Collection and Workflow Automation,Diwakar Kumar,"Automate data collection and streamline workflows with minimal effort. From gathering user inputs to generating reports, AutoCollect integrates effortlessly into your existing systems, enhancing productivity and ensuring that all processes run smoothly.",1,xinbxzkgzk.py,local,,Test,1,0,0,0,0,1726753856633,1726754237924,389,52a214e7-b813-4ec9-a083-f1b191b33f0a,,,12,Watson,python
wjnjuvcgwj,Live Speech to Text | STT | Live Transcript | Watson STT,Satyam Singh,This project provides a live spech-to-text application using your system's microphone. This project laverages the IBM Watson Speech to Text.,1,main_sounddevice.py,git,https://github.ibm.com/Satyam-Singh3/Realtime_STT,https://github.ibm.com/Satyam-Singh3/Realtime_STT/blob/main/README.md,0,0,0,0,0,1726811043708,1726814422110,400,8def3b48-8757-4ecf-bd74-31be929c984f,,,12,Watson,python
mrjgfivmsu,Soul Machine integration with Watson Assisant,Megha Goriya,"Action file of watson assistant to display image , video and dynamic variable in Soul machine .",1,https://github.ibm.com/Client-Eng-EMEA-IN/Soul-machine-integrantion-with-WA/blob/main/demo.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Soul-machine-integrantion-with-WA,https://github.ibm.com/Client-Eng-EMEA-IN/Soul-machine-integrantion-with-WA/blob/main/README.md,0,0,0,0,0,1726823649272,1726823649272,425,2df9fe6c-d4b9-43ed-a6cd-55966ed87ac6,,,12,Watson,python
jbmwotgcky,ProtoDash for Source Attribution in RAG,Gautam Chutani,Uses ProtoDash algorithm for understanding the relative attribution of context supplied to generated LLM answer in RAG applications.,1,jbmwotgcky.py,local,,https://github.ibm.com/Gautam-Chutani/Assets/tree/main/SourceAttribution,0,0,0,0,0,1727015723237,1727015723237,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,3,watsonx.governance,python
iwuuldsqse,vLLM for serving LLMs on CPU,Gautam Chutani,This script shows how to run multimodal models like LLaVA using vLLM on VM as standalone server with CPU-only machine.,1,main.py,git,https://github.ibm.com/Gautam-Chutani/LLM-Serving-Engines/tree/main/vLLM,https://github.ibm.com/Gautam-Chutani/LLM-Serving-Engines/tree/main/vLLM,0,0,0,0,0,1727016899363,1727016899363,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
uaikozkmxf,SAS-to-Python Code Assistant,"Mohita Ajmera, Gautam Chutani","This repository contains code for following tasks - SAS2Python Code Conversion, Chunk SAS Code based on macros, Python Code Documentation along with explainability, Python Code Risk Analysis, Generation of comparable SAS and Python unit tests in CSV format. Integrated watsonx.ai based solution into VS Code editor using Continue Extension. Along with basic UI to showcase different functionalities.",1,main.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/sas-to-python-asset,https://github.ibm.com/Client-Eng-EMEA-IN/sas-to-python-asset/blob/main/README.md,0,0,0,0,0,1727021268287,1727021930603,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
hebtpckuas,LLM Finetuner Pro,"Shilpa Hegde, Krish Hashia","Utility to finetune IBM granite model either using instructlab or supervised finetuning approach using custom dataset from hugging face on QnA task. As this needs GPU access, please export it to run the codebase.",1,,git,https://github.ibm.com/Shilpa-Hegde2/LLM-Finetuner-Pro.git,https://github.ibm.com/Shilpa-Hegde2/LLM-Finetuner-Pro/blob/main/README.md,0,0,0,0,0,1727086041941,1727086041941,429,7796dd6c-e3a6-4f46-a2bc-6292629199c0,,,8,WML,python
bgpexezenh,CSVQAChatbot,Charana H U,CSVQAChatbot,1,bgpexezenh.py,local,,https://github.ibm.com/Charana-H-U/csv_qa_chatbot/blob/main/CSVQAChatbot.ipynb,0,0,0,0,0,1727088587568,1727088659488,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
oeoqobzezp,Sample FastAPI Application with Watsonx.ai Integration and Dockerfile for IBM Code Engine deployment,Aishwarya Raj,"This provides demo for creating a FastAPI application that integrates with Watsonx.ai, containerizing it with Docker, and deploying it on IBM Code Engine.",1,src/app.py,git,https://github.ibm.com/aishwarya-raj1/FastAPI.git,https://github.ibm.com/aishwarya-raj1/FastAPI/blob/main/README.md,0,0,0,0,0,1727099005549,1727099998700,374,36c887f1-f8e4-4abd-884d-b75abc826a7d,,,1,watsonx.ai,python
zbcbbmzfit,RAG Chunking Methods,Gautam Chutani,"The repository explores various chunking strategies to determine the best way to split documents for storage, including Sentence aware Chunking, Semantic Splitter with watsonx.ai embedding models and LLM based Agentic Chunking.",1,main.py,git,https://github.ibm.com/Gautam-Chutani/Assets/tree/main/Text-Splitters,https://github.ibm.com/Gautam-Chutani/Assets/blob/main/Text-Splitters/README.md,2,0,0,0,0,1727120493180,1727120493180,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
horcgxqqsp,MultiModal RAG with LLaVA VLMs,"Gautam Chutani, Shilpi Varshney","This repository contains how to setup basic MultiModal RAG and other use-cases with LLaVa via vLLM on CPU and LLaVa-Next Vision Language Model available on watsonx.ai.
It also contains useful functions for image base64 format conversion, setup vLLM HTTP server and script to prompt 'llava-hf/llama3-llava-next-8b-hf' model on watsonx.ai. ",1,main.py,git,https://github.ibm.com/Gautam-Chutani/MultiModal-RAG,https://github.ibm.com/Gautam-Chutani/MultiModal-RAG,1,0,0,0,0,1727126970282,1727127778442,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,1,watsonx.ai,python
ghsaqmnzli,Chat with Documents: Reusable LLM Query Processor for PDF Q&A using RAG with Elastic Search,Aishwarya Raj,"Chat with Documents: Reusable LLM Query Processor for PDF Q&A using RAG with Elasticsearch"" is a Python-based solution designed to enable users to interact with PDF documents through a conversational, question-answering interface. By integrating RAG with Elasticsearch for semantic search and Watsonx.ai for language model responses, this system retrieves the most relevant sections from documents and generates answers based on user queries.",1,ghsaqmnzli.py,local,,NA,0,0,0,0,0,1727159966038,1727159966038,374,36c887f1-f8e4-4abd-884d-b75abc826a7d,,,1,watsonx.ai,python
kbpzfxzkct,Email Notifier & Trigger for WX Assistant,Ravi Gopalakrishnan,Email trigger re-usable code for (i) SMTP (ii) Microsoft 365 (iii) SendGrid,1,email.py,git,https://github.ibm.com/Felix-Augenstein/hfts-backend/blob/main/src/api/email.py,https://github.ibm.com/Felix-Augenstein/hfts-backend#readme,0,0,0,0,0,1727164063850,1727164063850,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,1,watsonx.ai,python
rnrxozcfwk,ImagePdf_conversion_asset,Vishwajith C R,"This project processes PDF files which are exported from PowerPoint slides, and converts text into structured formats using Watsonx AI and OCR APIs. The main functionality includes converting PDF slides to images, extracting text from these images, and then summarizing the extracted information using AI models.",1,https://github.ibm.com/Client-Eng-EMEA-IN/ImagePdf_conversion_asset/blob/main/asset_ocr_llm.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/ImagePdf_conversion_asset,https://github.ibm.com/Client-Eng-EMEA-IN/ImagePdf_conversion_asset#readme,0,0,0,0,0,1727164497824,1727164497824,414,7504de58-c35d-43f1-adbc-e218d74d1800,,,1,watsonx.ai,python
ivgnpbpvnz,Loading Embeddings from Elastic Search for Inferencing,Prerna Prem,Store Embeddings in Elastic Search and load the embeddings from the Elastic Search,1,embeddinggenerator_es_indexing.py,git,https://github.ibm.com/Prerna-Prem/Elastic-search/,https://github.ibm.com/Prerna-Prem/Elastic-search/blob/main/README.md,0,0,0,0,0,1727165720706,1727191427121,353,1f9cc2a7-6dab-4a10-819d-2e7b489c0784,,,12,Watson,python
hvrhqklozr,Web scraper to crawl websites,Ravi Gopalakrishnan,Web scraper to crawl websites using scrappy framework,1,scraper.py,local,,https://github.ibm.com/Client-Eng-EMEA-IN/AIMI-WIELAND/blob/main/ReadMe.md,0,0,0,0,0,1727166519805,1727166519805,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,2,watsonx.data,python
njbprajeuc,Watsonx governance azure metrics publisher,Ravi Gopalakrishnan,Watsonx governance azure based metrics publisher from llm tracking based on GPT LLM models,1,sanpaolo_openai_evaluation.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/sanpaolo/blob/main/sanpaolo_openai_evaluation.ipynb,https://github.ibm.com/Client-Eng-EMEA-IN/sanpaolo#readme,0,0,0,0,0,1727166824043,1727166824043,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,3,watsonx.governance,python
gpqkxzrtrc,Watsonx AI based governance tracker re-usable code,Ravi Gopalakrishnan,Re-usable code for Watsonx AI based governance tracker,1,sanpaolo_watsonx_evaluation.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/sanpaolo/blob/main/sanpaolo_watsonx_evaluation.ipynb,https://github.ibm.com/Client-Eng-EMEA-IN/sanpaolo#readme,0,0,0,0,0,1727166999763,1727166999763,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,3,watsonx.governance,python
zivlolbshx,Prompt optimiser for token length reduction,Ravi Gopalakrishnan,This asset will help the user to reduce the prompt based on the token size and try to reduce the intended prompt to certain length,1,src/app.py,git,https://github.ibm.com/Sohan-M1/Bytec/tree/main/bytec_optimization,https://github.ibm.com/Sohan-M1/Bytec/tree/main/bytec_optimization#readme,0,0,0,0,0,1727167402320,1727167402320,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,1,watsonx.ai,python
ucnivtuazd,GenerateHTMLResponse,Satyam Singh,"If you have a Template /Boiler plate HTML then you can embbed /add your LLM Response and generate a New HTML. In this asset instead on LLM response I have read text from a .txt file, you can replace that with your LLM response",1,,git,https://github.ibm.com/singh-satyam/GenerateResponseHTML.git,https://github.ibm.com/singh-satyam/GenerateResponseHTML/blob/main/README.md,1,0,0,0,0,1727193316737,1727193316737,400,8def3b48-8757-4ecf-bd74-31be929c984f,,,1,watsonx.ai,python
bmhxvpwqgy,PDF Viewer for watsonx Assistant semantic search sources,Diksha Chandra,"Access to PDF URLs from Cloud Object Storage is only valid for 7200 seconds. To extend the visibility of these PDFs, you can use this PDF viewer. Deploy it on Code Engine to create persistent URLs for your Cloud Object Storage PDFs. This app provides the UI and backend for a PDF Viewer that can be used in combination with watsonx Assistant.",3,,git,https://github.ibm.com/dikshachandra-18/viewerx-code.git,This app provides the UI and backend for a PDF Viewer that can be used in combination with watsonx Assistant.,0,0,0,0,0,1727204765817,1727204765817,476,fb738b91-a711-4b7c-a2eb-cfb2ae56258b,,,12,Watson,javascript
upmhtkckri,Use Milvus Vector DB for Multi-Vector-Multi-Modal Hybrid Search,Bharathi Chaudhury,"The query_milvus_multimodal function performs a multimodal, multi-vector search in a Milvus database. It combines embeddings from both text and image data, enabling hybrid searches based on a user-provided query. 
Function: query_milvus_multimodal
Parameters

    query: (str) The input text for search queries.
    sub_product_group: (str) The specific subcategory of products to narrow down search results. Example: ""Armchair"", ""Beds"".
    num_results: (int) The number of results to return.
    img_weight: (float, optional) Weight applied to image similarity during search ranking. Default is 0.2.
    desc_weight: (float, optional) Weight applied to description similarity during search ranking. Default is 0.1.
    generated_query_weight: (float, optional) Weight for generated query similarity during search ranking. Default is 0.7.
    milvus_creds:(dictionary) Milvus credentials with host, port and password

    The function returns a ranked list of search results (hybrid_res), combining image, description, and generated query similarity according to the provided weights.",1,upmhtkckri.py,local,,https://ibm.box.com/s/efzyyllwa1olta4bxd4pe6wg3bfxfwtn,0,0,0,0,0,1727241164256,1727241580544,477,393bd77f-9fb6-4448-a41b-4de228dfb0b9,,,2,watsonx.data,python
bkxivvmsrx,Multilingual_RAG_with_Feedback_Loop_Asset,Durgesh Chalvadi,"AIgentX - RAG Backend API:
Unlocking Powerful Multilingual Question Answering with WatsonX Discovery

This repository contains a robust FastAPI-based backend for a Retrieval Augmented Generation (RAG) pipeline, designed to deliver exceptional multilingual question answering capabilities.

At its core:

WatsonX Discovery: Searches and retrieves relevant information from your knowledge base.
Large Language Models (LLMs): Generates comprehensive answers based on retrieved context, supporting multiple languages.
User Feedback Integration: Continuously learns and improves by incorporating user feedback, regardless of the language used.
Streaming Response in Wx Assistant: Processes user queries and provides responses from the RAG pipeline in stream format, supporting multiple languages for real-time interactions.
🚀 Key Features
Multilingual Question Answering: Engage in natural language conversations with your knowledge base in various languages, receiving accurate and insightful answers.
Semantic Search: Leverage WatsonX Discovery's powerful semantic search capabilities, going beyond simple keyword matching.
Dynamic Context Retrieval: Retrieve relevant information dynamically based on your queries, ensuring context aligns with the language of the question.
User Feedback Loop: Enhance system accuracy and relevance by incorporating user feedback across all supported languages.",1,https://github.ibm.com/Client-Eng-EMEA-IN/Multilingual_RAG_with_Feedback_Loop_Asset/blob/main/AIgentX-RAG/server.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Multilingual_RAG_with_Feedback_Loop_Asset,https://github.ibm.com/Client-Eng-EMEA-IN/Multilingual_RAG_with_Feedback_Loop_Asset/blob/main/AIgentX-RAG/README.md,2,0,0,0,0,1727242824434,1727242824434,478,96abcd86-1a69-4656-b4ab-4b3b17ad5fbd,,,1,watsonx.ai,python
tresimfsrd,Semantic chunking,Soumya Sv,This Python script provides an automated solution for performing semantic chunking on large text documents and saving the resulting chunks into a CSV file. The asset utilizes a multilingual tokenizer and a semantic text splitter to divide the input text into chunks based on a token limit defined by the user or configuration,1,tresimfsrd.py,local,,readme.md,0,0,0,0,0,1727245690330,1727245690330,451,b7fcb093-5d84-4181-9215-79957ccfa128,,,1,watsonx.ai,python
qeulqgkvlh,Multi-Language PDF to Text Extraction,Prasath K,"A Comparative Study of Libraries and Tools,"" examines various libraries across languages like Japanese, Korean, and Chinese for extracting text from PDF documents. We evaluate popular libraries such as EasyOCR, PaddleOCR and Tesseract based on usability, extraction accuracy, and processing speed.",1,./TextUnleashed/main.py,git,https://github.ibm.com/Prasath-K/TextUnleashed,https://github.ibm.com/Prasath-K/TextUnleashed#readme,0,0,0,0,0,1727254243045,1727254243045,481,32135552-e1a9-4abe-bd01-3b27a8bcb6bd,,,1,watsonx.ai,python
kckbpcgwkj,watsonx table parser,"Ashish Singh, Ramananjali Mounica Golkonda","Complex table parsing made easy with watsonx!
We leverage watsonx.ai capabilities to parse complex tables for efficient information retrieval ",1,,git,https://github.ibm.com/Ashish-Singh03/Watsonx_Table_RAG,https://github.ibm.com/Ashish-Singh03/Watsonx_Table_RAG/blob/main/README.md,0,0,0,0,0,1727254483370,1727254483370,480,bd97abdf-5383-4a0d-b905-a2d39c8e9338,,,1,watsonx.ai,python
ddzorgivjn,Synthetic Data Q&A Generation using InstructLab,"Bharathi Chaudhury, Akash Modi",This project is built for generating synthetic Question and Answer pairs from uploaded PDF documents by using instructlab. The generated question and answer pairs are then evaluated with the ragas metrics.,1,https://github.ibm.com/Client-Eng-EMEA-IN/instructlab_qna_generation_asset/blob/main/ilab_streamline.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/instructlab_qna_generation_asset,https://github.ibm.com/Client-Eng-EMEA-IN/instructlab_qna_generation_asset/blob/main/README.md,0,0,0,0,0,1727257311651,1727257353727,477,393bd77f-9fb6-4448-a41b-4de228dfb0b9,,,4,Data Generation,python
sliieqcmpb,Detached prompt notebook for CP4D,Varsha Kumari,This notebook contains end to end python script to create and evaluate detached prompt in CP4D environment. The notebook is tested on CP4D 5.0.0,1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/Capability-Building-Wx-Governance/tree/main/DetachedPrompt-EndToEnd-Notebook,https://github.ibm.com/Client-Eng-EMEA-IN/Capability-Building-Wx-Governance/blob/main/DetachedPrompt-EndToEnd-Notebook/README.md,0,0,0,0,0,1727260973752,1727260973752,468,95466e2c-8136-4414-97fb-2884d9aecd7d,,,3,watsonx.governance,python
namxtwielu,Text Anonymiser - Version II,"Ravi Gopalakrishnan, Akash Modi","Anonymizer is an application based on LLM to anonymize the provided confidential data thereby fetching related entities from the documents and generated imaginary data to replace and create set of requested anonymized data.

Objective:

In lot of the pilots, we are given only few protected/private document to work with. Example of such documents are legal document & Financial documents. We cannot use these documents to showcase the completed pilot to other customers. Sometimes the onsite team don’t even  share these documents to us due to NDAs. But we need these documents to build and showcase the pilot. Hence we are implementing this anonymiser tool.",1,src/app.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/text-anonymiser,https://github.ibm.com/Client-Eng-EMEA-IN/text-anonymiser/blob/main/README.md,0,0,0,0,0,1727261158427,1727261180975,475,81cfb3ce-d3a5-4685-84c4-5dc68279ca73,,,4,Data Generation,python
isbbcxkyog,MEETING TRANSCRIBER & TRANSLATOR,Raveena Khan,"This asset with a Gradio UI with IBM STT that can capture voice from microphone and transcribe it in real time in Korean, Japanese, French & Hindi. This setup also provides the English language translation of the audio captured in the above mentioned languages.",1,cookbook/Meeting Transcriber & Translator/main.py,git,git@github.ibm.com:client-engineering-japan/asset-wizard.git,https://github.ibm.com/client-engineering-japan/asset-wizard/blob/main/cookbook/Meeting%20Transcriber%20%26%20Translator/README.md,0,0,0,0,0,1727262559469,1727262985844,446,65ec6185-f092-4f3f-a6b7-9b5a11797192,,,1,watsonx.ai,python
bhaskuppom,"Build Skills, Automations and Skill flows with WatsonX Orchestrate",Varsha Kumari,"It creates skills, automations and skill flows in WatsonX Orchestrate",1,https://github.ibm.com/Client-Eng-EMEA-IN/WatsonX-Orchestrate/blob/main/Create-Skills-and-SkillFlows/FastAPI%20Code/FastAPI.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/WatsonX-Orchestrate/tree/main/Create-Skills-and-SkillFlows,https://github.ibm.com/Client-Eng-EMEA-IN/WatsonX-Orchestrate/blob/main/Create-Skills-and-SkillFlows/README.md,0,0,0,0,0,1727299180067,1727299448398,468,95466e2c-8136-4414-97fb-2884d9aecd7d,,,12,Watson,python
hkhslvkjov,Graph RAG an Agricultural Usecase ,"Sonali Kumari, Bharathi Chaudhury","This project implements a GraphRAG (Retrieval-Augmented Generation) system that combines vector-based and knowledge graph-based retrieval techniques. It leverages IBM's Watsonx LLM for natural language processing and HuggingFace's MiniLM for text embeddings. The system is designed to index and query agricultural data stored in JSON format, with knowledge graph storage handled by Neo4j.",1,https://github.ibm.com/Client-Eng-EMEA-IN/graph-rag-agriculture-usecase/blob/main/server.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/graph-rag-agriculture-usecase,https://github.ibm.com/Client-Eng-EMEA-IN/graph-rag-agriculture-usecase/blob/main/README.md,0,0,0,0,0,1727330350444,1727330537527,477,393bd77f-9fb6-4448-a41b-4de228dfb0b9,,,1,watsonx.ai,python
bsiquvrsro,Python Script to create PDF,Vikas Mani,"This script will help you to create a pdf file via python code using reportlab library. You can manipulate the fontsize, the structure of the PDF, colouring the texts, and create a table with ease.",1,bsiquvrsro.py,local,,run the python script to see a sample created PDF file.,0,0,0,0,0,1727374821683,1727374821683,426,6f746bd8-8cce-45fe-80cc-421dee6e037d,,,4,Data Generation,python
yrjflqubok,PDF Generation,Gayathri E S,Extracting contents from a pdf to generate test case pdf documents,1,./MHI_usecase2_UI.py,git,https://github.ibm.com/client-engineering-japan/MHI.git,https://github.ibm.com/client-engineering-japan/MHI/blob/MHI-Usecase2-V2/README.md,0,0,0,0,0,1727416825772,1727416825772,485,90efaf12-6a7d-4e37-84d7-cdb5e3c2faed,,,1,watsonx.ai,python
dahzdvqlgq,WatsonX AI Image and Text Interaction,Soumyajit Bera,"Welcome to LLaVA-Testing, where we leverage IBM WatsonX's capabilities to interact with images and text input dynamically. This project utilizes LLaVA (Local Large Vision Assistant) for image and text-based responses using IBM Watson models. Enter text prompts and image inputs at runtime to generate detailed responses. Let’s dive into how to set up and use this project!

Featuresl:-

Dynamic Input Handling: Input your API Key, Project ID, Text Description, and Image URL or Path directly at runtime—no need for hardcoded configurations.
Auto Image Processing: Automatically resize and encode images to base64 format, whether from a URL or local path.
Interactive Image Display: Visualize your images directly within the output for easy reference.
Customizable Prompts: Tailor the interaction with both images and text input, and receive rich responses from WatsonX’s advanced LLaVA model.",1,dahzdvqlgq.py,local,,https://github.ibm.com/Soumyajit-Bera/Mutlimodal-Testing,0,0,0,0,0,1727420291877,1727420291877,349,8a5ede2a-2e2a-4f3c-a3de-48a9190f37be,,,1,watsonx.ai,python
fubhlgynrl,pdf table extraction using pymupdf,Rakhi Sharma,Extracts tables from a PDF over the specified page ranges.,1,fubhlgynrl.py,local,,Extracts tables from a PDF over the specified page ranges.,1,0,0,0,0,1727424055003,1727424055003,392,c77015c9-755d-4acf-b6e2-66a13a764c83,,,1,watsonx.ai,python
opguczpocr,Resume Matching with Job Descriptions Using FAISS and Sentence Embeddings,Rakhi Sharma,"This Python script leverages FAISS and SentenceTransformer to match resumes against a job description based on similarity scores. It generates embeddings for both resumes and the job description, indexes them using FAISS, and retrieves the most relevant resumes by calculating Euclidean distance between their embeddings. The results are exported in JSON or CSV format, displaying names and similarity scores for easy analysis. The script is modular, allowing for flexible input and model configurations.",1,opguczpocr.py,local,,"please input job description (required_skills,Years_of_Experience), resumes (name, technical skills, years of experience)",0,0,0,0,0,1727425585680,1727425585680,392,c77015c9-755d-4acf-b6e2-66a13a764c83,,,1,watsonx.ai,python
cuqoboqosv,Split PDF files into sections/headers based on headers,harikrishnan venkatesh,This is first version of an asset that will allow you to split a pdf's text into various sections based on the color of certain headers/drawings which are usually present in some pdfs. This is just the first version and a later version will allow you to split it based on font etc.,1,cuqoboqosv.py,local,,Not available at the moment,0,0,0,0,0,1727433882670,1727433882670,350,8c14e6b0-879b-49f0-b937-4f7c507f0ae8,,,1,watsonx.ai,python
ulvbtljcdt,Shell script for Instructlab,Vikas Mani,"An end-to-end guide for setting up the instruct lab.Use the shell script to automate the instructlab installation, synthetic data generation and training.",4,,git,https://github.ibm.com/Vikas-Mani2/instruct-lab-script,https://github.ibm.com/Vikas-Mani2/instruct-lab-script/blob/main/README.md,0,0,0,0,0,1727438645975,1727438645975,426,6f746bd8-8cce-45fe-80cc-421dee6e037d,,,4,Data Generation,bash
vdniidcnuf,Audio Transcription and Ambient Documentation Notebook using Watson Speech-to-Text and LLM,Ayushi Parida,"This notebook facilitates the transcription of audio files using IBM Watson Speech-to-Text and enhances the output with Large Language Model (LLM) capabilities. It processes audio files in various formats (e.g., wav, mp3, flac, ogg), chunks large files for transcription, and uses a specified speech model to generate transcripts with speaker labels. The transcriptions are then saved and uploaded to the IBM Watson Studio project. Additionally, the notebook integrates an LLM for advanced language processing tasks, offering flexibility in model configuration and parameter tuning.",1,https://github.ibm.com/Ayushi-Parida/Audio-Transcription-and-Ambient-Documentation-using-IBM-Watson-Speech-to-Text-and-LLM/blob/main/audio_transcription_notebook.py,git,https://github.ibm.com/Ayushi-Parida/Audio-Transcription-and-Ambient-Documentation-using-IBM-Watson-Speech-to-Text-and-LLM,https://github.ibm.com/Ayushi-Parida/Audio-Transcription-and-Ambient-Documentation-using-IBM-Watson-Speech-to-Text-and-LLM/blob/main/README.md,0,0,0,0,0,1727534013054,1727534013054,487,73dad5ee-eb6e-4a1a-8356-6cffefa8c855,,,1,watsonx.ai,python
xauxskdyhf,IndexTransferEmbed,Soumyajit Bera,"This script demonstrates how to transfer documents from an existing Elasticsearch index to a new index while applying embeddings using a pipeline powered by WatsonX Discovery and Elasticsearch. The code performs the following tasks:

Environment Setup: It loads the necessary credentials for WatsonX Discovery from environment variables and sets up the Elasticsearch client for connecting to the instance.

Ingest Pipeline Creation: An ingest pipeline (elser-ingest-pipeline) is created, which utilizes the ELSER model for embedding text data (using a specific field body_content_field). The embedding results are stored in the ml.tokens field.

New Index Creation: A new index is created using the previously defined ingest pipeline, with mappings configured to handle text fields and embedding tokens.

Document Validation and Transfer: The code reads documents from a source index, validates their structure, and transfers them one by one to the new index. It ensures each document is properly formatted and applies retry logic for indexing in case of connection failures.

Efficient Data Scrolling: The script implements a scroll API to fetch large volumes of data from the source index in manageable batches, allowing for efficient transfer without overwhelming memory or causing timeouts.

Error Handling: The script incorporates error handling for connection issues and invalid document structures, ensuring that the transfer process can recover from minor disruptions.

Logging and Progress Monitoring: Progress is printed out as documents are successfully processed and indexed, giving the user visibility into the operation.

The code can be used for general document migration scenarios where embedding and indexing of text content in Elasticsearch are required, making it suitable for a variety of data ingestion and search enhancement use cases.
",1,https://github.ibm.com/Soumyajit-Bera/WXD-and-assistant/blob/main/crawl_embedding.py,git,https://github.ibm.com/Soumyajit-Bera/WXD-and-assistant,https://github.ibm.com/Soumyajit-Bera/WXD-and-assistant/blob/main/README.md,0,0,0,0,0,1727677954361,1727677954361,349,8a5ede2a-2e2a-4f3c-a3de-48a9190f37be,,,1,watsonx.ai,python
ddaetsqijd,Parallel Milvus Extraction and Summarization,Rahul Chavan,"This code allows you to search multiple Milvus collections in parallel, combine the results, and then generate multiple summaries of the combined data in parallel. It first extracts data from three Milvus collections simultaneously, then uses the aggregated results to create three different types of summaries concurrently.

The Milvus extraction is parallel across collections.
The summarization is parallel across different summary types.
These two parallel operations happen sequentially (first extraction, then summarization), not simultaneously.",1,ddaetsqijd.py,local,,"This code allows you to search multiple Milvus collections in parallel, combine the results, and then generate multiple summaries of the combined data in parallel. It first extracts data from three Milvus collections simultaneously, then uses the aggregated results to create three different types of summaries concurrently.  The Milvus extraction is parallel across collections. The summarization is parallel across different summary types. These two parallel operations happen sequentially (first extraction, then summarization), not simultaneously.",0,0,0,0,0,1727680999983,1727680999983,234,8f06e80d-32d2-4114-958d-29bda13a953c,,,12,Watson,python
nobhzsibaz,Data Ingestion into Watsonx.Data through DataStage Tool and CSV File,Jathin R,"This code was utilized for a pilot use case to demonstrate data insertion from DataStage to Watsonx.data, as well as the import of a CSV file into Iceberg format within Watsonx.data.",1,data_ingestion_datastage_spark.py,local,,None,0,0,0,0,0,1727682800827,1727682800827,409,832a2a7b-94f7-4295-9e65-eaa89cb0f8cd,,,2,watsonx.data,python
urcvnywqrp,Tririga Schema Descriptor,Tiyasa Mukherjee,Automates the generation of human-readable column descriptions for Tririga database tables using IBM WatsonX.ai.,1,https://github.ibm.com/tiyasa-mukherjee/tririga_col_desc_generation/blob/main/ttable_tririga_col_desc_generation.py,git,https://github.ibm.com/tiyasa-mukherjee/tririga_col_desc_generation,https://github.ibm.com/tiyasa-mukherjee/tririga_col_desc_generation/blob/main/README.md,0,0,0,0,0,1727685385532,1727685385532,340,bf29c7b3-f178-4d14-90dd-71894f48632e,,,2,watsonx.data,python
zhvaggkkyl,"Intelligent Asset Retrieval System Using Milvus, FastAPI and watsonx.ai integration",S Siva Santosh,"This project integrates Milvus, a highly efficient vector database, with FastAPI, a modern web framework, to create an intelligent search application. It leverages state-of-the-art natural language processing models, such as sentence-transformers, to handle search queries for asset retrieval, focusing on metadata like authors, descriptions, and technical keywords. The search system also supports entity extraction and searches for AWS-specific assets like S3-compliant buckets, enhancing the relevance of search results. Additionally, the project uses IBM Watson Machine Learning for enhanced search capabilities.",1,https://github.ibm.com/Siva-Santosh-S/assethub/blob/milvus-enhancements-v4/app/main.py,git,https://github.ibm.com/Siva-Santosh-S/assethub/tree/milvus-enhancements-v4,https://github.ibm.com/Siva-Santosh-S/assethub/blob/milvus-enhancements-v4/README.md,0,0,0,0,0,1727700447330,1727700447330,492,716a1d9c-165d-44a8-9038-971813a3b281,,,12,Watson,python
ojcicjhqwg,Automated Table Generation in Word from Excel using Python,Divya Jadon,"This script demonstrates how to automatically generate a table in a Word document from data stored in an Excel file using Python. It reads data from two Excel files, processes the information, and dynamically creates a formatted table in a Word document. 
",1,excel_docx.py,git,https://github.ibm.com/Divya-Jadon/excel_to_docx.git,README.md,0,0,0,0,0,1727702300562,1727710686897,490,d4c4614a-f103-4ea2-a6fe-bb8387475b43,,,4,Data Generation,python
iokjededjm,Scrape data from sub-reddit and store data in the database,Surya P V,"The code will scrape the data from reddit and store the user reviews to backend database. Sub-reddit handle name needs to be passed as user parameter. The following passwords needs to be included in the config file:
REDDIT_CLIENT_ID, REDDIT_CLIENT_SECRET, REDDIT_USER_AGENT
DB_HOST, DB_NAME, DB_USER, DB_PASS, DB_PORT",1,iokjededjm.py,local,,https://github.ibm.com/Surya-PV/vz_ibmc_ui/tree/product_idea_generation,0,0,0,0,0,1727707394612,1727707394612,432,f6c1b936-1ab0-4bad-b251-d14db62c6144,,,4,Data Generation,python
bcccbxsefi,React integration with assistant,Surya P V,This code enables the integration of React UI with wx assistant. You will have an assistant build in your react UI,3,,git,https://github.ibm.com/Surya-PV/react_wxo_integration/blob/main/src/Home.js,https://github.ibm.com/Surya-PV/react_wxo_integration/blob/main/src/Home.js,0,0,0,0,0,1727707798633,1727707798633,432,f6c1b936-1ab0-4bad-b251-d14db62c6144,,,4,Data Generation,javascript
mcozeidckm,Complaint Extraction & Classification - Generic Prompt,"Raveena Khan, Sriparna Banerjee ","Complaint Extraction & Classification:
This is a generic prompt adaptable with any LLM that extracts complaints from the summary generated by the Summary prompt and classifies the complaints based on the categories provided in the prompt. The prompt is written in ReAct style with examples for few shot learning which has proven to provide both classification accuracy and F-score to be above 90%. ",1,mcozeidckm.py,local,,https://github.ibm.com/client-engineering-japan/asset-wizard/blob/main/README.md,0,0,0,0,0,1727714149464,1727714149464,446,65ec6185-f092-4f3f-a6b7-9b5a11797192,,,1,watsonx.ai,python
igqyouuwms,Customizing IBM TTS Service,Gautam Chutani,"This notebook explores different ways of customizing the IBM Text-to-Speech Service to improve the pronunciation of specific words and control speech attributes such as rate, pitch, emphasis.",1,main.py,git,https://github.ibm.com/Gautam-Chutani/Assets/tree/main/Customizing-TTS,https://github.ibm.com/Gautam-Chutani/Assets/blob/main/Customizing-TTS/README.md,0,0,0,0,0,1727731788695,1727731829209,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,12,Watson,python
guyscbfnow,BYOM with watsonx.ai SaaS,"Anupam Chakraborty, Gautam Chutani, Shilpa Hegde",This repository contains steps for deploying Custom Foundation Model using BYOM feature with watsonx.ai SaaS,1,main.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/BYOM-watsonx-SaaS,https://github.ibm.com/Client-Eng-EMEA-IN/BYOM-watsonx-SaaS/blob/main/README.md,0,0,0,0,0,1727931352709,1727931352709,338,3d9ff218-681e-4508-ac2e-9d2be7a8c35d,,,8,WML,python
sakugdkqso,Automated PDF Section Extraction Based on Numbered Headings,Rakhi Sharma,"This Python utility automates the extraction of numbered sections from a PDF document. It allows users to specify a range of pages from which the text is extracted and then automatically detects and splits the content based on numbered headings (e.g., ""1."", ""2."", etc.). The extracted sections are cleaned and organized into a dictionary for easy access and analysis.

This tool is perfect for anyone working with structured documents, such as reports or contracts, where numbered sections need to be identified and extracted quickly. It simplifies the process of analyzing large documents by isolating relevant sections without manual effort.

 **Use Case**:
- Extract specific sections from legal documents, reports, or academic papers.
- Automate the breakdown of large, structured PDFs for easier analysis.
- Ideal for professionals who work with structured documents and need quick, automated section extraction.",1,sakugdkqso.py,local,,please replace example.pdf with your pdf file.,0,0,0,0,0,1727932544112,1727932544112,392,c77015c9-755d-4acf-b6e2-66a13a764c83,,,1,watsonx.ai,python
ijveaqsvpd,Indexing PDFs in Watsonx Discovery,Rachiyta Singh,"This asset has the code to Uniquely map each pdf in a directory to an index in elastic search,and then get results for search queries.

I am using Watsonx Discovery in local for this.",1,,git,https://github.ibm.com/Client-Eng-EMEA-IN/WxDisc,https://github.ibm.com/Client-Eng-EMEA-IN/WxDisc/blob/main/README.md,0,0,0,0,0,1727939017103,1727939017103,503,99f51a7c-d8f9-43a5-a2e7-2a9b439543ed,,,12,Watson,python
uvccmttnkv,"Evaluating the Effectiveness of LLaMA 3-2 in a FastAPI based Retrieval-Augmented Generation using Meeting Transcription with Whisper: A Study Using RAG and Metrics (Precision@K, Recall@K, MRR, nDCG, BLEU, ROUGE-1)",Devi Parvathy Nair,"This project is a FastAPI service that transcribes audio files into text using OpenAI's Whisper model, beautifies the transcribed text using a LLaMA model, and computes various metrics for the generated text.

## Features

- Upload and transcribe audio files in various formats (mp3, wav, ogg, mp4)
- Generate a beautified response from the transcription based on a given query using a LLaMA model
- Calculate evaluation metrics for the transcription and generation process, including BLEU, ROUGE, Precision@k, Recall@k, Mean Reciprocal Rank (MRR), and Normalized Discounted Cumulative Gain (nDCG)",1,RAG_Meeting_Metrics/ragmetricswhisper.py,local,,.,0,0,0,0,0,1727950365173,1727950365173,489,19b4bfd8-10fb-4b05-8c4b-9c966b8cfc3c,,,1,watsonx.ai,python
zaentmmrso,Data Integration and Search in WatsonX Discovery using FAST API,Nagaraju Kuruva,This asset enables data loading into WatsonX Discovery and allows data searching from WatsonX Discovery using FAST API.,1,zaentmmrso.py,local,,same,0,0,0,0,0,1727955270432,1727955270432,427,1925ef83-e37c-4930-8b19-422e55ccdfe9,,,2,watsonx.data,python
ivcstqiyii,Enhance Data Search with Synonym Creation in WatsonX Discovery,Nagaraju Kuruva,This asset enables the creation of synonyms in WatsonX Discovery and facilitates data searches from WatsonX Discovery.,1,ivcstqiyii.py,local,,same,0,0,0,0,0,1727956215386,1727956215386,427,1925ef83-e37c-4930-8b19-422e55ccdfe9,,,2,watsonx.data,python
rvanbhhhvl,Voice RAG ,Sri Sai Swaroop Kaza,"RAG by uploading a document, voice chat about document ",1,https://github.ibm.com/Sri-Sai-Swaroop-Kaza/voice_rag/blob/main/Notebooks/voice_rag.py,git,https://github.ibm.com/Sri-Sai-Swaroop-Kaza/voice_rag,https://github.ibm.com/Sri-Sai-Swaroop-Kaza/voice_rag/blob/main/README.md,0,0,0,0,0,1728021700781,1728021700781,504,d8d8abb7-6950-4758-9890-1cb4cf6be5c6,,,1,watsonx.ai,python
ckahlssljw,"JD Generator, Resume Shortlisting Asset",Naveen Narayan,"JD Generator, Resume Shortlisting Asset",1,src/rbi_hr_pipeline.py,git,https://github.ibm.com/watsonx-apac/watsonx_genai_pipelines/tree/rbi-hr-flow-updated/src,https://ibm.box.com/s/01gmitcv9dptciytc1yjyuqohhhmokwj,1,0,0,0,0,1728022900764,1728022900764,455,a2f5de35-6631-46c6-8ac3-2b385aa48170,,,1,watsonx.ai,python
uqmrqaxfmk,Db2 Handling,M N Navneeth,The asset deals with working with Db2 locally.,1,https://github.ibm.com/M-N-Navneeth/Db2Handling/blob/main/Db2_service.py,git,https://github.ibm.com/M-N-Navneeth/Db2Handling.git,https://github.ibm.com/M-N-Navneeth/Db2Handling/blob/main/README.md,0,0,0,0,0,1728024308121,1728024308121,506,a9fd85df-5ad6-41eb-a60f-dbbd161ee787,,,11,Data Stage,python
etbgpfeayk,Information extraction from PDF/Word/Image documents,M N Navneeth,This asset deals with extraction of information from documents.,1,,git,https://github.ibm.com/M-N-Navneeth/Document-Information-extraction.git,https://github.ibm.com/M-N-Navneeth/Document-Information-extraction/blob/main/README.md,0,0,0,0,0,1728025306861,1728025306861,506,a9fd85df-5ad6-41eb-a60f-dbbd161ee787,,,4,Data Generation,python
nzvgqhkmeq,Streaming Watsonx.ai in FASTAPI,M N Navneeth,This asset deals with streaming of Watsonx.ai output in FASTAPI applications,1,https://github.ibm.com/M-N-Navneeth/Watsonx.ai-FASTAPI-Streaming/blob/main/app/main.py,git,https://github.ibm.com/M-N-Navneeth/Watsonx.ai-FASTAPI-Streaming.git,https://github.ibm.com/M-N-Navneeth/Watsonx.ai-FASTAPI-Streaming/blob/main/README.md,0,0,0,0,0,1728032885442,1728032885442,506,a9fd85df-5ad6-41eb-a60f-dbbd161ee787,,,1,watsonx.ai,python
oreayksemv,Image Geospatial Data Management with watsonx.data ,Rahul Kumar,"The asset allows you to search your image data using various parameters that can be present in the image metadata. It also supports geospatial distance calculations in the backend, enabling users to search for images based on a reference point (city/latitude/longitude) provided by the user. Additionally, it involves image metadata management in Watsonx.data.",1,watsonx_data_image_search.py,git,https://github.ibm.com/RAHUL-KUMAR141/imagery-geospatial-search-watsonx.data.git,https://github.ibm.com/RAHUL-KUMAR141/imagery-geospatial-search-watsonx.data/blob/main/README.md,0,0,0,0,0,1728130694978,1728201438929,498,035e027c-1aea-4463-994d-259c3ae397b5,,,2,watsonx.data,python
lifxyanhbd,Conversational Systems Testing - s2t2s,Rahul Kumar,"This asset automates the processing of conversation paths across multiple dialects by leveraging IBM Watson services. 
Useful for testing and validating conversational AI systems, where the input and output can be analyzed in both text and audio formats.",1,s2t2s_with_conversation_path.py,git,https://github.ibm.com/RAHUL-KUMAR141/s2t2s.git,https://github.ibm.com/RAHUL-KUMAR141/s2t2s/blob/main/README.md,0,0,0,0,0,1728131456309,1728201372595,498,035e027c-1aea-4463-994d-259c3ae397b5,,,12,Watson,python
yrihdgqxis,Language Detection and Translation using LLMs,Bhavishya Pandit,Detect and Translate text using LLMs,1,yrihdgqxis.py,local,,https://github.ibm.com/Bhavishya-Pandit/llm_language_translation/blob/main/README.md,0,0,0,0,0,1728166395597,1728546385592,462,ec67b728-dc5d-4cfd-9d27-0b1df7ae0881,,,1,watsonx.ai,python
gzcsitpgoj,Health Conversation Agent API,"Charana H U, Pavan Purohit, Mohit Sharma","A FastAPI-based application that provides AI-generated responses for health-related conversations using IBM WatsonX AI and Milvus vector database. This API allows clients to send participant data and receive personalized responses generated by AI models. 
1. AI-Powered Responses: Generate personalized health advice using IBM WatsonX AI models.
2. Vector Database Integration: Efficient strategy data retrieval using Milvus vector database.
3. Conversation History: Maintain conversation history for each user.
4. RESTful API: Easy-to-use API endpoints for integration with other services.",1,https://github.ibm.com/Client-Eng-EMEA-IN/Pathmate_CoachAI/blob/main/src/main.py,git,https://github.ibm.com/Client-Eng-EMEA-IN/Pathmate_CoachAI,https://github.ibm.com/Client-Eng-EMEA-IN/Pathmate_CoachAI/blob/main/README.md,0,0,0,0,0,1728293451926,1728293451926,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
auvgkbjxpp,Custom LLM Agent for WatsonX Models,Charana H U,LLM agent from scratch,1,https://github.ibm.com/Charana-H-U/custom-llm-agent/blob/main/agent.py,git,https://github.ibm.com/Charana-H-U/custom-llm-agent,,0,0,0,0,0,1728293713247,1728293713247,467,4b70501e-f457-4a62-b6e4-b94916c09dd0,,,1,watsonx.ai,python
dqecqaorpy,Governance with Streamlit App,Anupam Shah,"This Streamlit application incorporates Watsonx.governance capabilities, offering features such as payload data submission, feedback data handling, and triggering monitoring processes through custom functions directly within the app.",1,https://github.ibm.com/Anupam-Shah/WxGovWithStreamlitApp/blob/main/app.py,git,https://github.ibm.com/Anupam-Shah/WxGovWithStreamlitApp,https://github.ibm.com/Anupam-Shah/WxGovWithStreamlitApp/blob/main/README.md,0,0,0,0,0,1728301861663,1728301861663,363,6c3ed14e-2e1b-4b96-8896-731ddb418337,,,3,watsonx.governance,python
xehqkgiwpc,Parallel Multiple model Calling,M N Navneeth,This asset deals with calling multiple models in parallel.,1,https://github.ibm.com/M-N-Navneeth/Parallel-Multi-Model/blob/main/main.py,git,https://github.ibm.com/M-N-Navneeth/Parallel-Multi-Model.git,https://github.ibm.com/M-N-Navneeth/Parallel-Multi-Model/blob/main/README.md,0,0,0,0,0,1728453559537,1728453559537,506,a9fd85df-5ad6-41eb-a60f-dbbd161ee787,,,1,watsonx.ai,python
zlalknhvmx,Custom Embedding model in WX Discovery,M N Navneeth,This asset deals with uploading a custom embedding model into ElasticSearch and deploying it.,1,https://github.ibm.com/M-N-Navneeth/WX-Discovery-Custom-Embedding-model/blob/main/main.py,git,https://github.ibm.com/M-N-Navneeth/WX-Discovery-Custom-Embedding-model.git,https://github.ibm.com/M-N-Navneeth/WX-Discovery-Custom-Embedding-model/blob/main/README.md,0,0,0,0,0,1728455070741,1728455070741,506,a9fd85df-5ad6-41eb-a60f-dbbd161ee787,,,12,Watson,python
ibotcvupns,Minio Handling,M N Navneeth,"This asset deals with uploading files and retrieving it from Minio Object storage. Currently it supports PDF, WORD and EXCEL files",1,https://github.ibm.com/M-N-Navneeth/Minio-Handling/blob/main/main.py,git,https://github.ibm.com/M-N-Navneeth/Minio-Handling.git,https://github.ibm.com/M-N-Navneeth/Minio-Handling/blob/main/README.md,0,0,0,0,0,1728456215957,1728456215957,506,a9fd85df-5ad6-41eb-a60f-dbbd161ee787,,,12,Watson,python
fuhalbtmzv,Watson Speech to Text,M N Navneeth,This asset deals with using the Watson Speech to Text service in python,1,https://github.ibm.com/M-N-Navneeth/Watson-Seech-to-Text/blob/main/main.py,git,https://github.ibm.com/M-N-Navneeth/Watson-Seech-to-Text.git,https://github.ibm.com/M-N-Navneeth/Watson-Seech-to-Text/blob/main/README.md,0,0,0,0,0,1728456949453,1728456949453,506,a9fd85df-5ad6-41eb-a60f-dbbd161ee787,,,12,Watson,python
yejsdhdfeh,PDF Highlighter,"Mehul Joshi, Harikrishana ",it will highlight any part of pdf,1,yejsdhdfeh.py,local,,This asset will help you to highlight the text that it has been passed,0,0,0,0,0,1728464593999,1728464742052,444,91ae8435-98d7-4fce-a3e3-71ff28e5c5da,,,1,watsonx.ai,python
kbdljqtjau,Setup poetry,Tatsuya Naito,Install and setup poetry which is python package manager,4,./scripts/setup_poetry.sh,git,https://github.ibm.com/ASSETS-HUB-JP-RESOURCES/env_setup,https://github.ibm.com/ASSETS-HUB-JP-RESOURCES/env_setup/README.md,0,0,0,0,0,1728523220041,1728524165060,379,95348ab3-fe8c-4226-b4b1-62755274cd0a,,,1,watsonx.ai,bash
umkotbshfm,List available models,Tatsuya Naito,List all available models on watsonx.ai service instance.,4,scripts/list_models.sh,git,https://github.ibm.com/ASSETS-HUB-JP-RESOURCES/watsonx-utils,https://github.ibm.com/ASSETS-HUB-JP-RESOURCES/watsonx-utils/README.md,0,0,0,0,0,1728527465918,1728527686441,379,95348ab3-fe8c-4226-b4b1-62755274cd0a,,,1,watsonx.ai,bash
krddkbwnkq,List watsonx.ai available models,Tatsuya Naito,List watsonx.ai available models,6,,,,,0,0,0,0,1,1728528997653,1728528997653,379,95348ab3-fe8c-4226-b4b1-62755274cd0a,,,13,Use-case,useCase
jdpjobxzzs,contract entity extraction,Prem Khemani,extract important entities from legal documents with the help of langchain,1,jdpjobxzzs.py,local,,dg,0,0,0,0,0,1728541847925,1728541847925,515,dfade748-6cb7-402b-8b9d-42149e9e7a26,,,1,watsonx.ai,python
